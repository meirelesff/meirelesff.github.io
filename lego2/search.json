[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lego II",
    "section": "",
    "text": "Este é o website da disciplina de Lego II do IESP-UERJ. Particularmente, alguns recursos e códigos que usaremos nas nossas aulas estarão aqui. Ementa, textos e outros materiais estão nesta pasta no Google Drive."
  },
  {
    "objectID": "index.html#sobre",
    "href": "index.html#sobre",
    "title": "Lego II",
    "section": "",
    "text": "Este é o website da disciplina de Lego II do IESP-UERJ. Particularmente, alguns recursos e códigos que usaremos nas nossas aulas estarão aqui. Ementa, textos e outros materiais estão nesta pasta no Google Drive."
  },
  {
    "objectID": "topicos/topico4.html",
    "href": "topicos/topico4.html",
    "title": "Experimentos",
    "section": "",
    "text": "Estas notas introduzem análise de experimentos em R, o que cobrirá como usar dois estimadores comuns para analisar este tipo de desenho: estimador de diferença de médias e regressão linear por MQO.\nUsaremos como exemplo os dados de LaLonde (1986), usados em seu paper clássico comparando os resultados de um randomized controlled trial (i.e., um experimento de campo) de treinamento profissional para homens desempregados sobre suas rendas futuras com os resultados de um estudo observacional. Trata-se de um estudo clássico na Economia, e nas Ciências Sociais, de forma geral, por ser um dos primeiros a mostrar que os resultados de um experimento podem ser muito diferentes dos resultados de um estudo observacional, utilizando modelos de regressão saturados.\nAntes de avançar, precisaremos carregar as duas bases, a com dados experimentais e a com dados observacionais. Para isso, usaremos o pacote haven:\n\nlibrary(tidyverse)\nlibrary(haven)\n\nnsw_exp &lt;- read_dta(\"nsw_exp.dta\")\nnsw_obs &lt;- read_dta(\"nsw_obs.dta\")\n\nAs variáveis que temos nas duas bases são:\n\nVariáveis nas bases de dados de LaLonde (1986)\n\n\n\n\n\n\nNome\nVariável\n\n\n\n\nnsw\nDummy para participantes do NSW\n\n\nage\nIdade (em anos)\n\n\neduc\nAnos de escolaridade\n\n\nblack\nDummy para afro-americanos\n\n\nhispanic\nDummy para hispânicos\n\n\nmarried\nDummy para casados\n\n\nre74\nGanhos reais (corrigidos pela inflação) para 1974\n\n\nre75\nGanhos reais (corrigidos pela inflação) para 1975\n\n\nre78\nGanhos reais (corrigidos pela inflação) para 1978\n\n\nu74\nDummy para desempregados em 1974\n\n\nu75\nDummy para desempregados em 1975\n\n\nu78\nDummy para desempregados em 1978\n\n\n\nAo final, também analisaremos uma pequena base de survey retirada de Ballard-Rosa, Martin, e Scheve (2017), sobre as preferências em relação a diferentes regimes de taxação nos EUA usando um conjoint experiment."
  },
  {
    "objectID": "topicos/topico4.html#introdução",
    "href": "topicos/topico4.html#introdução",
    "title": "Experimentos",
    "section": "",
    "text": "Estas notas introduzem análise de experimentos em R, o que cobrirá como usar dois estimadores comuns para analisar este tipo de desenho: estimador de diferença de médias e regressão linear por MQO.\nUsaremos como exemplo os dados de LaLonde (1986), usados em seu paper clássico comparando os resultados de um randomized controlled trial (i.e., um experimento de campo) de treinamento profissional para homens desempregados sobre suas rendas futuras com os resultados de um estudo observacional. Trata-se de um estudo clássico na Economia, e nas Ciências Sociais, de forma geral, por ser um dos primeiros a mostrar que os resultados de um experimento podem ser muito diferentes dos resultados de um estudo observacional, utilizando modelos de regressão saturados.\nAntes de avançar, precisaremos carregar as duas bases, a com dados experimentais e a com dados observacionais. Para isso, usaremos o pacote haven:\n\nlibrary(tidyverse)\nlibrary(haven)\n\nnsw_exp &lt;- read_dta(\"nsw_exp.dta\")\nnsw_obs &lt;- read_dta(\"nsw_obs.dta\")\n\nAs variáveis que temos nas duas bases são:\n\nVariáveis nas bases de dados de LaLonde (1986)\n\n\n\n\n\n\nNome\nVariável\n\n\n\n\nnsw\nDummy para participantes do NSW\n\n\nage\nIdade (em anos)\n\n\neduc\nAnos de escolaridade\n\n\nblack\nDummy para afro-americanos\n\n\nhispanic\nDummy para hispânicos\n\n\nmarried\nDummy para casados\n\n\nre74\nGanhos reais (corrigidos pela inflação) para 1974\n\n\nre75\nGanhos reais (corrigidos pela inflação) para 1975\n\n\nre78\nGanhos reais (corrigidos pela inflação) para 1978\n\n\nu74\nDummy para desempregados em 1974\n\n\nu75\nDummy para desempregados em 1975\n\n\nu78\nDummy para desempregados em 1978\n\n\n\nAo final, também analisaremos uma pequena base de survey retirada de Ballard-Rosa, Martin, e Scheve (2017), sobre as preferências em relação a diferentes regimes de taxação nos EUA usando um conjoint experiment."
  },
  {
    "objectID": "topicos/topico4.html#estimador-de-diferença-de-médias",
    "href": "topicos/topico4.html#estimador-de-diferença-de-médias",
    "title": "Experimentos",
    "section": "Estimador de diferença de médias",
    "text": "Estimador de diferença de médias\nO primeiro estimador que aplicaremos é o estimador de diferença de médias. Seja \\(Y_i\\) o valor observado da variável dependente para o indivíduo \\(i\\), \\(D_i \\in \\{1, 0\\}\\) o seu status de tratamento, \\(N_1\\) e \\(N_0\\) o número de unidades tratadas e não-tradas, o estimador de diferença de médias é:1\n\\[\n\\hat{\\tau} = \\left(\\frac{1}{N_1} \\sum_{i:D_i=1} Y_i\\right) - \\left(\\frac{1}{N_0} \\sum_{i:D_i=0} Y_i\\right)\n\\]\nEm termos de implementação, portanto, ele é simples: basta calcular a diferença entre a média da variável dependente para os grupos de tratamento e controle. Podemos fazer isso em R em duas etapas:\n\n# Calcula a média de renda futura e erro-padrao\nmedias &lt;- nsw_exp %&gt;%\n    group_by(nsw) %&gt;%\n    summarise(media = mean(re78))\n\nmedias\n\n# A tibble: 2 × 2\n    nsw media\n  &lt;dbl&gt; &lt;dbl&gt;\n1     0 4555.\n2     1 6349.\n\n\nComo dá para ver, a média do grupo tratado é maior do que a média do grupo de controle. Para calcular a diferença, podemos usar agora:\n\n# Calcula a diferenca de médias\nmedias %&gt;%\n    summarise(diff = diff(media))\n\n# A tibble: 1 × 1\n   diff\n  &lt;dbl&gt;\n1 1794.\n\n\nOu, de forma mais direta usando apenas R-base e um teste T:\n\n# Calcula a diferenca de médias\nt.test(re78 ~ nsw, data = nsw_exp)\n\n\n    Welch Two Sample t-test\n\ndata:  re78 by nsw\nt = -2.6741, df = 307.13, p-value = 0.007893\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -3114.6754  -474.0108\nsample estimates:\nmean in group 0 mean in group 1 \n       4554.802        6349.145 \n\n\n\nTeste de diferença de médias\nNo mais das vezes, estamos interessados em usar o estimador de diferença de médias para inferência e teste de hipóteses – o que significa que precisaremos calcular medidas de incerteza de estimativas e, também, P-valores. Dados que média é um estimador simples, também é simples fazer esses cálculos adicionais diretamente, sem a necessidade de funções prontas ou pacotes. Como visto em Lego I, variância nada mais é do que uma espécie de média dos desvios quadrados de cada valor \\(Y_i\\) em relação à média \\(\\bar{Y}\\). Para o grupo de tratamento, isto é o mesmo que:\n\\[\ns_1^2 = \\frac{1}{N_1 - 1} \\sum_{i:D_i = 1} ​(Y_i - \\bar{Y}_1)^2\n\\]\nTendo esse número para os dois grupos, basta dividir cada um por \\(N_1\\) e \\(N_0\\), somar o resultado e tirar a sua raiz (cobriremos isso em aula, mas Gerber e Green (2012) detalha o procedimento no capítulo 3):\n\\[\n\\hat{\\sigma} = \\sqrt{\\frac{s_1^2}{N_1} + \\frac{s_0^2}{N_0}}\n\\]\nDe forma geral, portanto, precisamos realizar os seguintes procedimentos para calcular estatísticas de interesse e testar a hipótese de que a média dos grupos de tratamento e controle são iguais (a nossa hipótese nula):\n\nCalculamos a média de cada grupo\nCalculamos a variância de cada grupo\nDividimos a variância de cada grupo pelo tamanho do grupo\nCalculamos o erro-padrão da estimativa como a raiz da soma dos resultados do passo 3\nUsamos o erro-padrão para calcular T-valor, intervalos de confiança e P-valor\n\nO passo 2, a variância, nada mais é do que uma média dos desvios quadrados de cada valor \\(Y_{i:D_i=d}\\) em relação à média do grupo \\(d\\). Em termos de implementação, podemos fazer isso em R da seguinte forma:2\n\n# Calcula a variacia do grupo de tratamento\nvar1 &lt;- nsw_exp$re78[nsw_exp$nsw == 1] - mean(nsw_exp$re78[nsw_exp$nsw == 1])\nvar1 &lt;- sum(var1^2) / (length(var1) - 1)\n\n# Calcula a variacia do grupo de controle\nvar0 &lt;- nsw_exp$re78[nsw_exp$nsw == 0] - mean(nsw_exp$re78[nsw_exp$nsw == 0])\nvar0 &lt;- sum(var0^2) / (length(var0) - 1)\n\nvar1\n\n[1] 61896056\n\nvar0\n\n[1] 30072467\n\n\nO passo 3, a divisão da variância pelo tamanho do grupo, é simples:\n\n# Divide a variância pelo tamanho do grupo\nvar1 &lt;- var1 / length(nsw_exp$re78[nsw_exp$nsw == 1])\nvar0 &lt;- var0 / length(nsw_exp$re78[nsw_exp$nsw == 0])\n\nIsso feito, podemos calcular o erro-padrão da estimativa somando var1 e var0 e tirando a sua raiz quadrada:3\n\n# Calcula o erro-padrão\nerro &lt;- sqrt(var1 + var0)\nerro\n\n[1] 670.9967\n\n\nO erro-padrão é, portanto, de aproximadamente 671. Com isso, podemos calcular o T-valor, intervalos de confiança e P-valor:\n\n# Calcula o t-valor\ndiferenca &lt;- mean(nsw_exp$re78[nsw_exp$nsw == 1]) - mean(nsw_exp$re78[nsw_exp$nsw == 0])\nt &lt;- diferenca / erro\nt\n\n[1] 2.674146\n\n\nDe cara, dado que \\(t &gt; 1.96\\), fica patente que o efeito não parece ser um que ocorreria por acaso, em função da aleatoriedade do Processo Gerador de Dados. Mas podemos calcular o intervalo de confiança e o P-valor para ter um número mais formal:4\n\n# Calcula o p-valor\n2 * pt(-abs(t), df = nrow(nsw_exp) - 2)\n\n[1] 0.007769016\n\n\nO cálculo acima é mais complicado (dado que envolve a distribuição cumulativa de uma distribuição \\(t\\)), mas o intervalo de confiança é simples:\n\n# Calcula o IC\ndiferenca + c(-1, 1) * qt(0.975, df = nrow(nsw_exp) - 2) * erro\n\n[1]  475.6108 3113.0754\n\n\nComo é possível ver, o resultado é o mesmo que o obtido com t.test anteriormente (embora com os sinais trocados por conta da ordem em que consideramos os grupos)."
  },
  {
    "objectID": "topicos/topico4.html#estimador-de-regressão-linear",
    "href": "topicos/topico4.html#estimador-de-regressão-linear",
    "title": "Experimentos",
    "section": "Estimador de regressão linear",
    "text": "Estimador de regressão linear\nPodemos realizar o mesmo teste com modelos de regressão linear – o que, adicionalmente, nos dá a vantagem de termos maior controle sobre o tipo de erro-padrão, se é necessário controlar alguma variável para assumir que \\((Y_i(1), Y_i(0)) \\not\\!\\!\\perp\\!\\!\\!\\perp D_i\\), etc. Para facilitar as coisas, usaremos o pacote fixest para reestimar o efeito do programa de treinamento profissional sobre a renda futura dos participantes:\n\nlibrary(fixest)\n\n# Estima o efeito do programa\nm1 &lt;- feols(re78 ~ nsw, data = nsw_exp)\nsummary(m1)\n\nOLS estimation, Dep. Var.: re78\nObservations: 445 \nStandard-errors: IID \n            Estimate Std. Error  t value  Pr(&gt;|t|)    \n(Intercept)  4554.80    408.046 11.16247 &lt; 2.2e-16 ***\nnsw          1794.34    632.854  2.83532 0.0047875 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 6,564.7   Adj. R2: 0.015606\n\n\nO resulta dispensa muitos comentários. O principal aqui é que o coeficiente de nsw retornou o mesmo que um estimador de diferença de médias, a estimativa de erro-padrão é similar e, da mesma forma, a estatística T e o P-valor. Podemos ir além e incluir, agora, variáveis de controle:\n\n# Estima o efeito do programa\nm2 &lt;- feols(re78 ~ nsw + age + educ + black + hisp + married + u74, data = nsw_exp)\nsummary(m2)\n\nOLS estimation, Dep. Var.: re78\nObservations: 445 \nStandard-errors: IID \n              Estimate Std. Error   t value  Pr(&gt;|t|)    \n(Intercept)  1293.8046  2518.6714  0.513685 0.6077316    \nnsw          1660.4761   632.8607  2.623762 0.0090008 ** \nage            57.4934    45.1431  1.273579 0.2034895    \neduc          400.6857   176.6569  2.268158 0.0238068 *  \nblack       -2248.5264  1159.4094 -1.939372 0.0530993 .  \nhisp           21.1637  1548.1689  0.013670 0.9890994    \nmarried        95.9200   852.7368  0.112485 0.9104906    \nu74          -505.8836   710.1823 -0.712329 0.4766411    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 6,459.8   Adj. R2: 0.033726\n\n\nComo é possível ver, o efeito do programa continua similar, mesmo com a inclusão de variáveis de controle – o que é um resultado da aleatorização do tratamento, que é independente de outras variáveis. Inversamente, o tratamento não deve ter efeito sobre variáveis pré-tratamento, isto é, variáveis que ocorreram antes da administração do programa de treinamento. Podemos checar isso com dois modelos, a título de exemplo:\n\n# Estima o efeito do programa\npre1 &lt;- feols(age ~ nsw + educ + black + hisp + married + u74, data = nsw_exp)\npre2 &lt;- feols(educ ~ nsw + age + black + hisp + married + u74, data = nsw_exp)\n\netable(pre1, pre2)\n\n                             pre1               pre2\nDependent Var.:               age               educ\n                                                    \nConstant         22.40*** (2.442)  10.87*** (0.4409)\nnsw               0.6137 (0.6692)    0.1696 (0.1710)\neduc              0.0135 (0.1870)                   \nblack              0.7374 (1.227)  -0.5187. (0.3126)\nhisp               -1.397 (1.637) -1.395*** (0.4134)\nmarried         4.110*** (0.8810)    0.3628 (0.2300)\nu74               1.899* (0.7462)  -0.3714. (0.1913)\nage                                  0.0009 (0.0122)\n_______________ _________________ __________________\nS.E. type                     IID                IID\nObservations                  445                445\nR2                        0.06845            0.04513\nAdj. R2                   0.05569            0.03205\n---\nSignif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNesse caso, nsw não tem efeito nem substantivo e nem significativo, o que sugere, realmente, que nenhuma das duas variáveis que analisamos podem ser preditas pelo tratamento.\n\nEstimativa com dados observacionais\nPara fechar esta parte, vamos estimar o mesmo efeito com dados observacionais, usando o mesmo modelo de regressão linear. Para isso, usaremos a base nsw_obs:\n\n# Estima o efeito do programa\nm3 &lt;- feols(re78 ~ nsw + age + educ + black + hisp + married + u74, data = nsw_obs)\nsummary(m3)\n\nOLS estimation, Dep. Var.: re78\nObservations: 2,675 \nStandard-errors: IID \n              Estimate Std. Error    t value   Pr(&gt;|t|)    \n(Intercept)  -9119.878  1785.5512  -5.107598 3.4930e-07 ***\nnsw           3132.613  1319.5522   2.373997 1.7667e-02 *  \nage            233.467    26.8101   8.708176  &lt; 2.2e-16 ***\neduc          1747.710    93.6906  18.654072  &lt; 2.2e-16 ***\nblack        -3299.049   651.8200  -5.061288 4.4477e-07 ***\nhisp           704.549  1442.7266   0.488346 6.2535e-01    \nmarried       3873.129   770.2923   5.028129 5.2812e-07 ***\nu74         -13790.664   883.3935 -15.611009  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 13,296.2   Adj. R2: 0.274401\n\n\nEm relação ao efeito estimado usando um desenho experimental, os dados observacionais inflam o impacto do programa de treinamento profissional – indicando que provavelmente quem procurou o programa já ganharia mais dinheiro de toda forma."
  },
  {
    "objectID": "topicos/topico4.html#estimatr",
    "href": "topicos/topico4.html#estimatr",
    "title": "Experimentos",
    "section": "estimatr",
    "text": "estimatr\nPara facilitar a aplicação de estimadores para desenhos experimentais, podemos usar o pacote estimatr, criado por um grupo de cientistas políticos e documentado neste link. Podemos instalá-lo com:\n\n# Instala e carrega o pacote\ninstall.packages(\"estimatr\")\nlibrary(estimatr)\n\nPara o uso documentado acima, as principais funções do pacote são lm_robust, para estimar modelos lineares por MQO com erros-padrão robustos5; e difference_in_means, para estimar diferenças de médias. Ambas as funções são simples de usar, e retornam objetos que podem ser usados com summary e tidy:\n\n# Estima o efeito do programa\nest_medias &lt;- difference_in_means(re78 ~ nsw, data = nsw_exp)\nest_modelo &lt;- lm_robust(re78 ~ nsw + age + educ + black + hisp + married + u74, data = nsw_exp)\nsummary(est_medias)\n\n$coefficients\n    Estimate Std. Error  t value    Pr(&gt;|t|) CI Lower CI Upper       DF\nnsw 1794.343   670.9967 2.674146 0.007892971 474.0108 3114.675 307.1325\n\n$design\n[1] \"Standard\"\n\nsummary(est_modelo)\n\n\nCall:\nlm_robust(formula = re78 ~ nsw + age + educ + black + hisp + \n    married + u74, data = nsw_exp)\n\nStandard error type:  HC2 \n\nCoefficients:\n            Estimate Std. Error  t value Pr(&gt;|t|) CI Lower CI Upper  DF\n(Intercept)  1293.80    2451.86  0.52768  0.59799 -3525.09   6112.7 437\nnsw          1660.48     665.45  2.49525  0.01295   352.59   2968.4 437\nage            57.49      39.91  1.44065  0.15040   -20.94    135.9 437\neduc          400.69     161.41  2.48242  0.01342    83.45    717.9 437\nblack       -2248.53    1004.58 -2.23827  0.02571 -4222.94   -274.1 437\nhisp           21.16    1367.87  0.01547  0.98766 -2667.26   2709.6 437\nmarried        95.92     880.27  0.10897  0.91328 -1634.17   1826.0 437\nu74          -505.88     733.95 -0.68926  0.49102 -1948.39    936.6 437\n\nMultiple R-squared:  0.04896 ,  Adjusted R-squared:  0.03373 \nF-statistic: 3.475 on 7 and 437 DF,  p-value: 0.001234\n\n\nComo outra vantagem, podemo usar a função tidy para obter um tibble com os resultados:\n\ntidy(est_medias)\n\n  term estimate std.error statistic     p.value conf.low conf.high       df\n1  nsw 1794.343  670.9967  2.674146 0.007892971 474.0108  3114.675 307.1325\n  outcome\n1    re78\n\n\nCom isso, podemos, por exemplo, fazer um gráfico dos coeficientes para facilitar a visualização – de um modelo linear, digamos:\n\nest_modelo %&gt;% \n  tidy() %&gt;% \n  filter(term != \"(Intercept)\") %&gt;% # Sem intercep\n  ggplot(aes(y = term, x = estimate, xmin = conf.low, xmax = conf.high)) + \n  geom_vline(xintercept = 0, linetype = 2) + \n  geom_pointrange() + \n  theme_minimal() +\n  labs(x = \"Estimativa\", y = \"Coeficiente\")\n\n\n\n\nMais útil, podemos testar o efeito do tratamento em variáveis pré-tratamento para visualizar os resultados com um gráfico (alerta: o código depende de um conhecimento maior do tidyverse):\n\n# Estima o efeito do programa\npre1 &lt;- lm_robust(age ~ nsw + educ + black + hisp + married + u74, data = nsw_exp) %&gt;%\n    tidy() %&gt;%\n    filter(term == \"nsw\") %&gt;%\n    mutate(var = \"Idade\")\n\npre2 &lt;- lm_robust(educ ~ nsw + age + black + hisp + married + u74, data = nsw_exp) %&gt;%\n    tidy() %&gt;%\n    filter(term == \"nsw\") %&gt;%\n    mutate(var = \"Escolaridade\")\n\npre3 &lt;- lm_robust(black ~ nsw + age + educ + hisp + married + u74, data = nsw_exp) %&gt;%\n    tidy() %&gt;%\n    filter(term == \"nsw\") %&gt;%\n    mutate(var = \"Afro-americano\")\n\nbind_rows(pre1, pre2, pre3) %&gt;%\n    ggplot(aes(y = var, x = estimate, xmin = conf.low, xmax = conf.high)) +\n    geom_vline(xintercept = 0, linetype = 2) +\n    geom_pointrange() +\n    theme_minimal() +\n    labs(x = \"Estimativa\", y = \"Coeficiente\",\n    title = \"Efeito do tratamento em variáveis pré-tratamento\")\n\n\n\n\nCom a ajuda de outros pacotes, também é fácil exportar os resultados de estimatr para tabelas. Por exemplo, podemos usar o pacote modelsummary, que já vimos:\n\nlibrary(modelsummary)\n\nest_modelo_simples &lt;- lm_robust(re78 ~ nsw, data = nsw_exp)\nmodelsummary(list(est_modelo_simples, est_modelo), \n             stars = TRUE, \n             statistic = \"p.value\", output = \"markdown\",\n             coef_map = c(\"(Intercept)\" = \"Constante\", \"nsw\" = \"Tratamento\"))\n\n\n\n\n\n(1)\n(2)\n\n\n\n\nConstante\n4554.802***\n1293.805\n\n\n\n(&lt;0.001)\n(0.598)\n\n\nTratamento\n1794.343**\n1660.476*\n\n\n\n(0.008)\n(0.013)\n\n\n:———–\n————:\n———-:\n\n\nNum.Obs.\n445\n445\n\n\nR2\n0.018\n0.049\n\n\nR2 Adj.\n0.016\n0.034\n\n\nAIC\n9091.5\n9089.1\n\n\nBIC\n9103.8\n9126.0\n\n\nRMSE\n6564.74\n6459.85\n\n\n\nNote: ^^ + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001"
  },
  {
    "objectID": "topicos/topico4.html#efeito-marginal-do-componente-amce",
    "href": "topicos/topico4.html#efeito-marginal-do-componente-amce",
    "title": "Experimentos",
    "section": "Efeito marginal do componente (AMCE)",
    "text": "Efeito marginal do componente (AMCE)\nNesta última seção, veremos rapidamente como aplicar regressão linear para estimar o efeito marginal do componente (AMCE) de um tratamento. Para isso, usaremos uma base de dados retirada de Ballard-Rosa, Martin, e Scheve (2017), disponível aqui, que contém as preferências de indivíduos em relação a diferentes regimes de taxação nos EUA. A base contém poucas variáveis, mas é para ilustrar o estimador. Começamos carregando os dados que estão em CSV:\n\n# Carrega os dados\ntaxes &lt;- read_csv(\"taxes.csv\")\n\nPodemos ver a estrutura da base com:\n\n# Mostra a estrutura da base\nglimpse(taxes)\n\nRows: 32,000\nColumns: 13\n$ chose_plan          &lt;dbl&gt; 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,…\n$ taxrate1            &lt;chr&gt; \"&lt;10k: 5%\", \"&lt;10k: 0%\", \"&lt;10k: 15%\", \"&lt;10k: 15%\", …\n$ taxrate2            &lt;chr&gt; \"10-35k: 25%\", \"10-35k: 35%\", \"10-35k: 25%\", \"10-3…\n$ taxrate3            &lt;chr&gt; \"35-85k: 35%\", \"35-85k: 5%\", \"35-85k: 5%\", \"35-85k…\n$ taxrate4            &lt;chr&gt; \"85-175k: 25%\", \"85-175k: 15%\", \"85-175k: 25%\", \"8…\n$ taxrate5            &lt;chr&gt; \"175-375k: 15%\", \"175-375k: 5%\", \"175-375k: 25%\", …\n$ taxrate6            &lt;chr&gt; \"&gt;375k: 5%\", \"&gt;375k: 45%\", \"&gt;375k: 25%\", \"&gt;375k: 5…\n$ taxrev              &lt;chr&gt; \"95-105%\", \"105-125%\", \"95-105%\", \"75-95%\", \"105-1…\n$ inequality_aversion &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,…\n$ taxes_harm_economy  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,…\n$ partyid             &lt;chr&gt; \"Republican\", \"Republican\", \"Republican\", \"Republi…\n$ ID                  &lt;dbl&gt; 177191531, 177191531, 177191531, 177191531, 177191…\n$ weight              &lt;dbl&gt; 6.828660, 6.828660, 6.828660, 6.828660, 6.828660, …\n\n\nComo dá para ver, temos como variável dependente choose_plan, que indica se um perfil hipotético de política de taxação foi (1) ou não (0) selecionado. Os perfis são definidos por seis componentes iniciados tax (e.g., taxrate1, taxrate2), que indicam a alíquota sugerida para cada faixa de renda anual.\nIsso feito, o estimador do AMCE é apenas uma variação do que já vimos: estimamos um modelo de regressão linear com os diferentes atributos aleatorizados como tratamento. Por exemplo, para estimar o AMCE do componente tax (que é a taxa de imposto), usamos:\n\ncj &lt;- lm_robust(chose_plan ~ taxrate1 + taxrate2 + taxrate3 + taxrate4 + taxrate5 + taxrate6, \n                clusters = ID, data = taxes)\ncj\n\n                          Estimate  Std. Error     t value      Pr(&gt;|t|)\n(Intercept)            0.621875367 0.013123197  47.3874914 1.722575e-315\ntaxrate1&lt;10k: 15%     -0.073108439 0.008459878  -8.6417841  1.159886e-17\ntaxrate1&lt;10k: 25%     -0.193712404 0.008835955 -21.9231989  4.624763e-95\ntaxrate1&lt;10k: 5%      -0.008562999 0.008175335  -1.0474188  2.950413e-01\ntaxrate210-35k: 25%   -0.043072217 0.007985812  -5.3935926  7.780535e-08\ntaxrate210-35k: 35%   -0.123779054 0.008544427 -14.4865247  3.583595e-45\ntaxrate210-35k: 5%    -0.002254620 0.007803330  -0.2889305  7.726663e-01\ntaxrate335-85k: 25%   -0.044727169 0.007693865  -5.8133547  7.172618e-09\ntaxrate335-85k: 35%   -0.090762797 0.008169538 -11.1099062  8.043787e-28\ntaxrate335-85k: 5%    -0.009194678 0.007836756  -1.1732760  2.408336e-01\ntaxrate485-175k: 25%  -0.005424936 0.007891790  -0.6874152  4.919060e-01\ntaxrate485-175k: 35%  -0.015025665 0.008002930  -1.8775204  6.060145e-02\ntaxrate485-175k: 5%   -0.022240453 0.007672150  -2.8988554  3.788648e-03\ntaxrate5175-375k: 25%  0.014401264 0.008604154   1.6737571  9.434932e-02\ntaxrate5175-375k: 35%  0.038231552 0.008857437   4.3163222  1.671375e-05\ntaxrate5175-375k: 45%  0.013157327 0.009096260   1.4464547  1.482212e-01\ntaxrate5175-375k: 5%  -0.040737725 0.008604726  -4.7343429  2.366839e-06\ntaxrate6&gt;375k: 25%     0.034774843 0.009517663   3.6537164  2.659657e-04\ntaxrate6&gt;375k: 35%     0.071922962 0.009670997   7.4369749  1.595445e-13\ntaxrate6&gt;375k: 45%     0.088864878 0.010306640   8.6220996  1.425409e-17\ntaxrate6&gt;375k: 5%     -0.077717384 0.009479144  -8.1987770  4.601144e-16\ntaxrate6&gt;375k: 55%     0.067500551 0.010689116   6.3148864  3.406463e-10\n                          CI Lower      CI Upper       DF\n(Intercept)            0.596136474  0.6476142598 1740.356\ntaxrate1&lt;10k: 15%     -0.089700148 -0.0565167299 1885.128\ntaxrate1&lt;10k: 25%     -0.211041707 -0.1763831017 1881.361\ntaxrate1&lt;10k: 5%      -0.024596696  0.0074706979 1877.659\ntaxrate210-35k: 25%   -0.058734224 -0.0274102098 1876.297\ntaxrate210-35k: 35%   -0.140536583 -0.1070215244 1884.963\ntaxrate210-35k: 5%    -0.017558684  0.0130494438 1886.499\ntaxrate335-85k: 25%   -0.059816538 -0.0296377991 1888.578\ntaxrate335-85k: 35%   -0.106785090 -0.0747405034 1883.958\ntaxrate335-85k: 5%    -0.024564318  0.0061749624 1882.795\ntaxrate485-175k: 25%  -0.020902535  0.0100526622 1877.969\ntaxrate485-175k: 35%  -0.030721220  0.0006698906 1880.876\ntaxrate485-175k: 5%   -0.037287267 -0.0071936401 1882.228\ntaxrate5175-375k: 25% -0.002473734  0.0312762613 1829.204\ntaxrate5175-375k: 35%  0.020859795  0.0556033096 1828.391\ntaxrate5175-375k: 45% -0.004682828  0.0309974829 1827.676\ntaxrate5175-375k: 5%  -0.057613856 -0.0238615944 1827.547\ntaxrate6&gt;375k: 25%     0.016107861  0.0534418250 1778.383\ntaxrate6&gt;375k: 35%     0.052955219  0.0908907050 1774.569\ntaxrate6&gt;375k: 45%     0.068650519  0.1090792373 1783.809\ntaxrate6&gt;375k: 5%     -0.096308837 -0.0591259307 1775.553\ntaxrate6&gt;375k: 55%     0.046536010  0.0884650917 1779.517\n\n\nVale notar que, como os diferentes tratamentos são independentes uns dos outros, estimar apenas uma versão reduzida do experimento resulta em estimativas similares:\n\ncj2 &lt;- lm_robust(chose_plan ~ taxrate1, clusters = ID, data = taxes)\ncj2\n\n                      Estimate  Std. Error     t value     Pr(&gt;|t|)    CI Lower\n(Intercept)        0.568902362 0.005405219 105.2505573 0.000000e+00  0.55830072\ntaxrate1&lt;10k: 15% -0.073439341 0.008580787  -8.5585788 2.329752e-17 -0.09026818\ntaxrate1&lt;10k: 25% -0.194073702 0.008921331 -21.7538954 8.858244e-94 -0.21157044\ntaxrate1&lt;10k: 5%  -0.007065347 0.008268703  -0.8544686 3.929544e-01 -0.02328216\n                      CI Upper       DF\n(Intercept)        0.579504005 1686.775\ntaxrate1&lt;10k: 15% -0.056610506 1885.640\ntaxrate1&lt;10k: 25% -0.176576959 1881.638\ntaxrate1&lt;10k: 5%   0.009151463 1878.486\n\n\nNovamente, podemos fazer um gráfico dos resultados para simplificar a visualização6:\n\ncj %&gt;% \n  tidy() %&gt;% \n  filter(term != \"(Intercept)\") %&gt;%\n  mutate(term = str_replace(term, \" 5%\", \" 05%\")) %&gt;%\n  ggplot(aes(y = term, x = estimate, xmin = conf.low, xmax = conf.high)) + \n  geom_vline(xintercept = 0, linetype = 2) + \n  geom_pointrange() + \n  theme_minimal() +\n  labs(x = \"Estimativa\", y = \"Coeficiente\")"
  },
  {
    "objectID": "topicos/topico4.html#footnotes",
    "href": "topicos/topico4.html#footnotes",
    "title": "Experimentos",
    "section": "Notas de rodapé",
    "text": "Notas de rodapé\n\n\nNote que usamos \\(i:D_i=1\\) para indicar que a média é calculada apenas para os indivíduos tratados, isto é, o indexador \\(i\\) pula observações com \\(D_i=0\\).↩︎\nNo cálculo de variância, em vez de dividir a soma dos desvios quadrados pelo número de elementos, usamos como denominador o número de elementos menos 1 – dado que já estimamos a média do grupo, que é um parâmetro. Informalmente, isso significa dizer que já gastamos uma observação.↩︎\nA título de intuição, quando temos duas amostras independentes o erro-padrão da diferença de estimativas é uma espécie de soma de suas medidas de dispersão. Um exemplo: imagine duas pesquisas eleitorais que dizem que a candidata A tem 20% de intenção de votos, com margem de erro de 2 pontos percentuais; e outra que diz que ela subiu para 22% da intenção de votos, com margem também de 2pp; nesse caso, a diferença entre as estimativas da candidata A pode ser tanto de 2pp (\\(0.22 - 0.2 = 2pp\\)) quanto de 6pp (\\(0.18 - 0.24 = -6pp\\)).↩︎\nAqui, os graus de liberdade são indicados por df. Note que diminuímos o número de observações, agora, de 2 dado que ↩︎\nNão cobrimos tanto inferência nesse curso, embora seja um tópico fundamental; de toda forma, erros-padrão robustos são úteis para o caso em que acreditamos (ou temos evidência) de que a variação dos resíduos não é homogênea. Para uma explicação formal, ver esta página.↩︎\nO ggplot automaticamente ordenar em orderm alfabética variáveis character, o que é o caso de term; de toda forma, ao fazer isso “5%” é considerado posterior a “25%”; mudaremos isso usando str_replace para trocar ” 5%” por “05%”.↩︎"
  },
  {
    "objectID": "topicos/topico2.html",
    "href": "topicos/topico2.html",
    "title": "Regressão linear simples",
    "section": "",
    "text": "Modelos de regressão linear são extremamente úteis para entender a relação entre variáveis. Com ele, podemos examinar a relação linear entre duas variáveis – o que, como vimos, serve como um excelente estimador de valor esperados condicionais, desde que sejam satisfeitas os pressupostos do modelo como o da linearidade.\nPara praticar esse conteúdo, estas notas explicam como baixar e carregar o banco de dados usado por Ross (2001) e, a partir dele, rodar alguns modelos de regressão. Além disso, as notas também oferecem códigos para implementar modelos lineares – não por mínimos quadrados – e visualizá-los usando gggplot2."
  },
  {
    "objectID": "topicos/topico2.html#introdução",
    "href": "topicos/topico2.html#introdução",
    "title": "Regressão linear simples",
    "section": "",
    "text": "Modelos de regressão linear são extremamente úteis para entender a relação entre variáveis. Com ele, podemos examinar a relação linear entre duas variáveis – o que, como vimos, serve como um excelente estimador de valor esperados condicionais, desde que sejam satisfeitas os pressupostos do modelo como o da linearidade.\nPara praticar esse conteúdo, estas notas explicam como baixar e carregar o banco de dados usado por Ross (2001) e, a partir dele, rodar alguns modelos de regressão. Além disso, as notas também oferecem códigos para implementar modelos lineares – não por mínimos quadrados – e visualizá-los usando gggplot2."
  },
  {
    "objectID": "topicos/topico2.html#baixando-e-carregando-o-banco-de-dados",
    "href": "topicos/topico2.html#baixando-e-carregando-o-banco-de-dados",
    "title": "Regressão linear simples",
    "section": "Baixando e carregando o banco de dados",
    "text": "Baixando e carregando o banco de dados\nOs dados de Ross (2001) estão no arquivo doesoil_clean.dta, em formato de Stata. Para carregá-los no R, é preciso instalar o pacote haven, que permite ler arquivos de dados de outros programas estatísticos, como Stata e SPSS. Para instalar o pacote, basta rodar:\n\ninstall.packages(\"haven\")\n\nIsso feito, para carregar o banco de dados, basta rodar:\n\nlibrary(haven)\nross &lt;- read_dta(\"doesoil_clean.dta\")\n\nO banco deve ter a seguinte cara:\n\nhead(ross)\n\n# A tibble: 6 × 59\n  cty_name    id      id1 year  year1  wdr6 wdr123 wdr135   wdr269 wdr271 wdr272\n  &lt;chr&gt;       &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Afghanistan AFG       3 1966   1966  51.7  NA        NA 82316304     NA     NA\n2 Afghanistan AFG       3 1967   1967  46.4   4.41     NA 85420096     NA     NA\n3 Afghanistan AFG       3 1968   1968  38.1  12.6      NA 71818400     NA     NA\n4 Afghanistan AFG       3 1969   1969  38.1  14.9      NA 82736600     NA     NA\n5 Afghanistan AFG       3 1970   1970  35.8  16.9      NA 84589504     NA     NA\n6 Afghanistan AFG       3 1971   1971  45.7  14.6      NA 99899200     NA     NA\n# ℹ 48 more variables: wdr273 &lt;dbl&gt;, wdr313 &lt;dbl&gt;, wdr344 &lt;dbl&gt;, wdr400 &lt;dbl&gt;,\n#   wdr477 &lt;dbl&gt;, ssafrica &lt;dbl&gt;, mideast &lt;dbl&gt;, me_nafr &lt;dbl&gt;, oecd &lt;dbl&gt;,\n#   v6 &lt;dbl&gt;, agr &lt;dbl&gt;, v123 &lt;dbl&gt;, oil &lt;dbl&gt;, v313 &lt;dbl&gt;, metal &lt;dbl&gt;,\n#   regime &lt;dbl&gt;, regime1 &lt;dbl&gt;, wdr97 &lt;dbl&gt;, wdr151 &lt;dbl&gt;, wdr152 &lt;dbl&gt;,\n#   log135 &lt;dbl&gt;, milpers &lt;dbl&gt;, islam &lt;dbl&gt;, ELF &lt;dbl&gt;, Food &lt;dbl&gt;,\n#   AgrFood &lt;dbl&gt;, WDR85 &lt;dbl&gt;, WDR87 &lt;dbl&gt;, WDR88 &lt;dbl&gt;, illit &lt;dbl&gt;,\n#   life &lt;dbl&gt;, WDR409 &lt;dbl&gt;, WDR411 &lt;dbl&gt;, tv &lt;dbl&gt;, WDR86 &lt;dbl&gt;, …"
  },
  {
    "objectID": "topicos/topico2.html#regressão-linear",
    "href": "topicos/topico2.html#regressão-linear",
    "title": "Regressão linear simples",
    "section": "Regressão linear",
    "text": "Regressão linear\nRodar modelos de regressão linear é algo simples em R. Para regredir regime em oil, as variáveis de Ross (2001) que indicam democracia e petróleo, respectivamente, basta rodar:\n\nlm(regime ~ oil, data = ross)\n\n\nCall:\nlm(formula = regime ~ oil, data = ross)\n\nCoefficients:\n(Intercept)          oil  \n     2.4037      -0.1724  \n\n\nPara facilitar a nossa inspeção dos resultados, vamos salvar o modelo em um objeto:\n\nross_lm &lt;- lm(regime ~ oil, data = ross)\n\nPodemos usar outro pacote, o brooom, para ver os resultados de forma mais direta:\n\n# Caso não tenha o pacote, rode: install.packages(\"broom\")\nlibrary(broom)\ntidy(ross_lm)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    2.40     0.151       15.9 1.26e-54\n2 oil           -0.172    0.0103     -16.7 6.59e-60"
  },
  {
    "objectID": "topicos/topico2.html#visualizando-modelos-lineares-simples",
    "href": "topicos/topico2.html#visualizando-modelos-lineares-simples",
    "title": "Regressão linear simples",
    "section": "Visualizando modelos lineares simples",
    "text": "Visualizando modelos lineares simples\nO ggplot2 já nos fornece geometrias que simplificam o processo de criar um gráfico de dispersão com uma linha de regressão. Para isso, basta usar geom_smooth() como uma camada adicional de um gráfico que usa geom_point():\n\nlibrary(tidyverse)\n\nggplot(ross, aes(x = oil, y = regime)) +\n  geom_point(size = 3.4, color = \"red\", alpha = 0.3) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_minimal() +\n  labs(x = \"Petróleo (% do PIB)\", y = \"Polity (democracia)\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 1822 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 1822 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "topicos/topico2.html#visualizando-modelos-lineares-arbitrários",
    "href": "topicos/topico2.html#visualizando-modelos-lineares-arbitrários",
    "title": "Regressão linear simples",
    "section": "Visualizando modelos lineares arbitrários",
    "text": "Visualizando modelos lineares arbitrários\nE se eu tiver um modelo não estimado por mínimos quadrados, como visualizá-lo? Simples: basta trocar geom_smooth() por geom_abline() e passar os coeficientes do modelo como argumentos slope e intercept. Por exemplo, imagine que achamos que o melhor modelo deve ter \\(\\beta_0 = 1\\) e \\(\\beta_1 = -0.2\\):\n\nggplot(ross, aes(x = oil, y = regime)) +\n  geom_point(size = 3.4, color = \"red\", alpha = 0.3) +\n  geom_abline(slope = -0.2, intercept = 1) +\n  theme_minimal() +\n  labs(x = \"Petróleo (% do PIB)\", y = \"Polity (democracia)\")\n\nWarning: Removed 1822 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "topicos/topico2.html#testando-diferentes-modelos",
    "href": "topicos/topico2.html#testando-diferentes-modelos",
    "title": "Regressão linear simples",
    "section": "Testando diferentes modelos",
    "text": "Testando diferentes modelos\nO gráfico anterior abre a possibilidade interessante de testar diferentes modelos. Pela teoria, sabemos que um modelo por mínimos quadrados é um bom modelo, e sabemos o que ele busca minimizar (e.g., \\(\\sum_{i=1}^n (y_i - (\\hat{\\beta_0} + \\hat{\\beta_1} x_i))^2\\)). Mas e se quisermos testar outros modelos? Como selecionamos bons modelos?\nAqui, vamos explorar uma solução comum em aprendizado de máquina: vamos gerar aleatoriamente e testar diferentes modelos e ver qual deles é o melhor. Isso, no entanto, envolve criar uma função – algo que não vimos explicitamente em Lego I (caso queira estudar mais sobre, veja este capítulo do R for Data Science).\nPara começar, vamos criar uma função que faz o seguinte: gera modelos aleatoriamente sorteando valores possíveis de \\(\\beta_0\\) e \\(\\beta_1\\). Aí vai o código:\n\n# Função para gerar modelos\ngera_modelos &lt;- function(n_modelos = 1000){\n\n    beta0 &lt;- runif(n_modelos, min = -10, max = 10)\n    beta1 &lt;- runif(n_modelos, min = -1, max = 1)\n\n    modelo &lt;- tibble(beta0 = beta0, beta1 = beta1)\n\n    return(modelo)\n}\n\nUm exemplo do que o modelo retorna:\n\ngera_modelos(10)\n\n# A tibble: 10 × 2\n    beta0   beta1\n    &lt;dbl&gt;   &lt;dbl&gt;\n 1  5.61   0.707 \n 2  1.07   0.484 \n 3  0.476 -0.553 \n 4  3.61   0.941 \n 5 -2.49   0.435 \n 6 -3.13   0.649 \n 7 -3.89  -0.191 \n 8 -9.71  -0.178 \n 9 -7.51   0.898 \n10 -1.84   0.0554\n\n\nComo dá para ver, em vez de estimar os parâmetros, a função os sorteia aleatoriamente. Podemos usar agora o ggplot2 para visualizar alguns desses modelos em cima dos dados de Ross (2001):\n\n# Gera 5 modelos\nmodelos &lt;- gera_modelos(5)\n\n# Plotando modelos\nggplot(ross, aes(x = oil, y = regime)) +\n  geom_point(size = 3.4, color = \"red\", alpha = 0.3) +\n  geom_abline(data = modelos, aes(slope = beta1, intercept = beta0)) +\n  theme_minimal() +\n  labs(x = \"Petróleo (% do PIB)\", y = \"Polity (democracia)\")\n\nWarning: Removed 1822 rows containing missing values (`geom_point()`).\n\n\n\n\n\nNenhum destes 5 modelos parece bom. O que podemos fazer, no entanto, é gerar mais modelos e ver se algum deles é comparável a um estimado por mínimos quadrados. Para isso, vamos criar uma função que, para cada modelo, calcula a soma dos resíduos quadráticos (SRQ):\n\n# Função para calcular SRQ\ncalcula_srq &lt;- function(beta0, beta1, dados){\n    \n    # Remove missings (não podemos calcular SRQ com missings)\n    dados &lt;- dados %&gt;%\n        select(regime, oil) %&gt;%\n        na.omit()\n\n    # Calcula a soma dos resíduos quadráticos\n    srq &lt;- sum((dados$regime - (beta0 + beta1 * dados$oil))^2)\n    return(srq)\n}\n\nCom essa função, agora podemos gerar e testar 100 ou 1000 modelos um a uma. O código a seguir faz isso (usando rowwise() e mutate() para aplicar a função a cada linha do banco de dados):\n\n# Gera 1000 modelos\nmodelos &lt;- gera_modelos(1000)\n\n# Calcula SRQ para cada modelo\nmodelos &lt;- modelos %&gt;%\n  rowwise() %&gt;% # Aplica a função linha a linha\n  mutate(srq = calcula_srq(beta0, beta1, dados = ross)) %&gt;%\n  ungroup() # Desfaz a operação rowwsise()\n\n# Visualiza os 5 melhores modelos\nmodelos %&gt;%\n  arrange(srq) %&gt;%\n  head(5)\n\n# A tibble: 5 × 3\n  beta0  beta1     srq\n  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1  2.53 -0.158 144693.\n2  2.68 -0.161 144857.\n3  1.83 -0.159 145248.\n4  2.98 -0.183 145288.\n5  3.33 -0.215 146716.\n\n\nComparando com o modelo estimado por mínimos quadrados, abaixo, vemos que o resultado não foi nada mal.\n\n# Seleciona os 5 melhores modelos\nmodelos &lt;- modelos %&gt;%\n  arrange(srq) %&gt;%\n  slice(1:5)\n\n# Plota os modelos estimados e o modelo de minimos quadrados\nggplot(ross, aes(x = oil, y = regime)) +\n  geom_point(size = 3.4, color = \"red\", alpha = 0.3) +\n  geom_abline(data = modelos, aes(slope = beta1, intercept = beta0)) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"purple\", linewidth = 1.2) +\n  theme_minimal() +\n  labs(x = \"Petróleo (% do PIB)\", y = \"Polity (democracia)\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 1822 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 1822 rows containing missing values (`geom_point()`).\n\n\n\n\n\nA moral da história é que, assim como há diferentes estimadores possíveis para uma quantia de interesse, também há diferentes formas de estimar um modelo."
  },
  {
    "objectID": "topicos/topico2.html#indo-além",
    "href": "topicos/topico2.html#indo-além",
    "title": "Regressão linear simples",
    "section": "Indo além",
    "text": "Indo além\nPara simular diferentes modelos, usamos alguns recursos mais avançados do tidyverse que só cobriremos ocasionalmente no curso. Se você quiser se aprofundar, recomendo ver principalmente:\n\nR for Data Science, de Hadley Wickham e Garrett Grolemund, livro fundamental para quem quer aprender R e tidyverse"
  },
  {
    "objectID": "replicacao/replicacao2.html",
    "href": "replicacao/replicacao2.html",
    "title": "Replicação II",
    "section": "",
    "text": "Neste segundo exercício avaliativo, replicaremos o trabalho de Fujiwara et al. (2011), que estima o efeito do uso de regra de segundo turno sobre a competição eleitoral nos municípios brasileiros. Como estratégia de identificação, o artigo explora uma descontinuidade na alocação de diferentas regras eleitorais: municípios com 200 mil ou mais eleitores têm segundo turno quando a primeira candidatura ao executivo local não atinge mais de 50% dos votos válidos; municípios com 200 mil ou menos eleitores, ao contrário, têm sempre turno único de votação. Explorando essa descontinuidade, o resultado do artigo sugere que ter uma regra de segundo turno causa um aumento de cerca de 8 pontos percentuais na votação de candidaturas que terminam em terceiro lugar ou pior, isto é, terceiras forças tendem a se sair melhor eleitoralmente. Esse resultado está na figura Figura 1 abaixo.\n\n\n\nFigura 1: Resultados principais do artigo"
  },
  {
    "objectID": "replicacao/replicacao2.html#tarefa",
    "href": "replicacao/replicacao2.html#tarefa",
    "title": "Replicação II",
    "section": "",
    "text": "Neste segundo exercício avaliativo, replicaremos o trabalho de Fujiwara et al. (2011), que estima o efeito do uso de regra de segundo turno sobre a competição eleitoral nos municípios brasileiros. Como estratégia de identificação, o artigo explora uma descontinuidade na alocação de diferentas regras eleitorais: municípios com 200 mil ou mais eleitores têm segundo turno quando a primeira candidatura ao executivo local não atinge mais de 50% dos votos válidos; municípios com 200 mil ou menos eleitores, ao contrário, têm sempre turno único de votação. Explorando essa descontinuidade, o resultado do artigo sugere que ter uma regra de segundo turno causa um aumento de cerca de 8 pontos percentuais na votação de candidaturas que terminam em terceiro lugar ou pior, isto é, terceiras forças tendem a se sair melhor eleitoralmente. Esse resultado está na figura Figura 1 abaixo.\n\n\n\nFigura 1: Resultados principais do artigo"
  },
  {
    "objectID": "replicacao/replicacao2.html#replicação",
    "href": "replicacao/replicacao2.html#replicação",
    "title": "Replicação II",
    "section": "Replicação",
    "text": "Replicação\nO exercício de replicação consistirá em reproduzir os resultados da tabela acima (correspondentes à Tabela 1 do paper). Para tanto, deverá ser seguido o template de replicação em Quarto (ver aqui) discutido em aula para produzir um documento final em formato PDF com cerca de 6 páginas (sem contar referências bibliográficas, tabelas e gráficos). O arquivo .qmd usado, com códigos, também deverá ser entregue.\nOs dados (já limpos) necessários para o exercício podem ser obtidos no link a seguir:\n\nReplicação de Fujiwara et al. (2011)\n\nA descrição do material replicação e codebook de variáveis pode ser obtido aqui."
  },
  {
    "objectID": "replicacao/replicacao2.html#critérios-de-avaliação",
    "href": "replicacao/replicacao2.html#critérios-de-avaliação",
    "title": "Replicação II",
    "section": "Critérios de avaliação",
    "text": "Critérios de avaliação\nA avaliação levará em conta a capacidade de implementar o conhecimento visto no curso e o esforço aplicado na tarefa – e não a obtenção de um resultado específico. Em particular, vale o esforço de tentar testar as medidas escolhidas, o escopo da amostra, estimador e especificação de modelos, seleção de variáveis de controle, etc."
  },
  {
    "objectID": "template.html",
    "href": "template.html",
    "title": "Template",
    "section": "",
    "text": "Neste curso, usaremos um template em quarto para criar documentos – principalmente trabalhos parciais e final. Diferentemente de um arquivo de Word, nosso template pode ser editado em qualquer editor de texto usando Markdown; e ele também dispensa termos de formatar o documento final; de inserir bibligrafia manualmente; e de ter de copiar e colar resultados de análises feitas no R.\nAlém disso, e principalmente para auxiliar na leitura e replicação de artigos, também usaremos uma folha resumo (cheat sheet) para cada artigo que replicaremos. Essa folha resumo deverá ser preenchida a partir do seguinte modelo."
  },
  {
    "objectID": "template.html#o-que",
    "href": "template.html#o-que",
    "title": "Template",
    "section": "",
    "text": "Neste curso, usaremos um template em quarto para criar documentos – principalmente trabalhos parciais e final. Diferentemente de um arquivo de Word, nosso template pode ser editado em qualquer editor de texto usando Markdown; e ele também dispensa termos de formatar o documento final; de inserir bibligrafia manualmente; e de ter de copiar e colar resultados de análises feitas no R.\nAlém disso, e principalmente para auxiliar na leitura e replicação de artigos, também usaremos uma folha resumo (cheat sheet) para cada artigo que replicaremos. Essa folha resumo deverá ser preenchida a partir do seguinte modelo."
  },
  {
    "objectID": "template.html#download",
    "href": "template.html#download",
    "title": "Template",
    "section": "Download",
    "text": "Download\nO template pode ser baixado daqui ou deste repositório do GitHub. Extraia os arquivos para uma pasta da sua preferência. Para abrir o template no RStudio, abra o arquivo template_quarto.Rproj. Seu projeto será aberto e você deverá ver algo mais ou menos assim:\n\n\n\nTemplate de Lego II no RStudio"
  },
  {
    "objectID": "template.html#instalação",
    "href": "template.html#instalação",
    "title": "Template",
    "section": "Instalação",
    "text": "Instalação\nPara usar o template, é necessário ter o R e o quarto instalados. Para instalar especificamente o quarto, busque a versão adequada para o seu computador em:\n\nhttps://quarto.org/docs/get-started/\n\nFeito isso, é necessário instalar uma distribuição de LaTeX (que é necessário para criar arquivos em PDF). Para isso, instalamos o tinytex rodando o seguinte código diretamente do R:\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()\nFinalmente, instale o pacote quarto para R com:\ninstall.packages(\"quarto\")"
  },
  {
    "objectID": "template.html#usando-o-template",
    "href": "template.html#usando-o-template",
    "title": "Template",
    "section": "Usando o template",
    "text": "Usando o template\nCom as dependências anteriores instaladas, para usar o template basta abrir o arquivo artigo.qmd de dentro RStudio, editar seu conteúdo como quiser e clicar no botão Render. O arquivo artigo.pdf será gerado.\nTambém é possível compilar o arquivo executando o seguinte código em R:\nquarto::render(\"artigo.qmd\")\n\nDicas de uso\n\nMarkdown\nTítulos e sub-títulos são definidos com # e ##, respectivamente. Por exemplo, # Título gera um título, e ## Sub-título gera um sub-título. Para criar uma lista, use - ou * no início de cada item. Exemplo:\n- Item 1\n- Item 2\nPara criar um parágrafo, basta deixar uma linha em branco entre os parágrafos. Para criar uma citação, use &gt;. Exemplo:\n\nCitação qualquer…\n\nPara destacar um texto com itálito, use *texto*; para negrito, use **texto**; e para negrito e itálico, use ***texto***. Finalmente, links podem ser criados com [texto](url).\n\n\nCódigo em R\nPodemos inserir código bruto em R e o template o compilará e o exibirá no documento final. Por exemplo, o código abaixo gerará um gráfico:\nx &lt;- 1:10\ny &lt;- x^2\nplot(x, y)\nPara inserir código, bastar usar três crases seguidas de r, e depois do código três crases novamente. Exemplo:\n```{r}\nplot(x, y)\n```\n\n\nCitações\n\nPara inserir uma citação, use @ seguido do nome do código da referência como definido no arquivo referencias.bib. Por exemplo, @ross2001does citará Ross (2001), e [@ross2001does] citará (Ross 2001). Para inserir várias citações, separe elas por ;. Por exemplo, [@ross2001does; @cunningham2021causal].\n\n\n\nNotação\nPodemos inserir notação matemática usando \\(\\LaTeX\\). Para inserir um símbolo, use $ seguido do código \\(\\LaTeX\\) e $ novamente. Por exemplo, $\\beta$ gerará \\(\\beta\\).\nNotações que usaremos bastante no curso:\n\n\\(\\beta\\) (beta): $\\beta$\n\\(\\beta_i\\) (beta sub i): $\\beta_i$\n\\(\\alpha\\) (alfa): $\\alpha$\n\\(\\sim\\) (sim): $\\sim$\n\\(\\hat{\\beta}\\) (beta chapéu): $\\hat{\\beta}$\n\\(\\sum_{i=1}^n\\) (somatório): $\\sum_{i=1}^n$\n\\(\\mathbb{E}[X]\\) (valor esperado): $\\mathbb{E}[X]$"
  },
  {
    "objectID": "template.html#replicação",
    "href": "template.html#replicação",
    "title": "Template",
    "section": "Replicação",
    "text": "Replicação\nPara os nossos exercícios de replicação, usaremos o template acima seguindo uma divisão de conteúdo específica: uma breve introdução do trabalho a ser replicado (use a cheatsheet de replicação para extrair os principais elementos da pesquisa); uma descrição dos dados de metodologia; e uma apresentação dos resultados replicados, incluindo algumas estatísticas descritivas das variáveis de interesse.\nUm guia de como organizar esse material, aplicado para a replicação de Ross (2001), pode ser encontrado aqui."
  },
  {
    "objectID": "recursos.html",
    "href": "recursos.html",
    "title": "Recursos",
    "section": "",
    "text": "R for Data Science - Garrett Grolemund e Hadley Wickham\nCausal Inference: The Mixtape - Scott Cunningham"
  },
  {
    "objectID": "recursos.html#livros",
    "href": "recursos.html#livros",
    "title": "Recursos",
    "section": "",
    "text": "R for Data Science - Garrett Grolemund e Hadley Wickham\nCausal Inference: The Mixtape - Scott Cunningham"
  },
  {
    "objectID": "replicacao/replicacao1.html",
    "href": "replicacao/replicacao1.html",
    "title": "Replicação I",
    "section": "",
    "text": "Para o primeiro exercício avaliativo, replicaremos o estudo de Edelman, Luca, e Svirsky (2017) sobre discriminação racial de hosts no Airbnb em algumas cidades americanas. Em particular, o estudo consiste em um experimento de campo (field experiment), com 20 perfis criados com nomes fictícios distintivos de pessoas afro-americanas e de pessoas brancas, meio a meio, pedindo informação em anúncios selecionados. Dessa forma, o resultado final é que alguns anúncios de hospedagem foram selecionados aleatoriamente para receber um pedido de pessoas com determinada cor/raça inferida pelo nome, enquanto outros, não. Como é possível ver na figura Figura 1, abaixo, o resultado do experimento mostra que pessoas com nomes indicativos de pessoas afro-americanas tiveram 8 pontos percentuais menos respostas positivas aos seus pedidos do que pessoas com nomes indicativos de pessoas brancas.\n\n\n\nFigura 1: Resultados principais do artigo"
  },
  {
    "objectID": "replicacao/replicacao1.html#tarefa",
    "href": "replicacao/replicacao1.html#tarefa",
    "title": "Replicação I",
    "section": "",
    "text": "Para o primeiro exercício avaliativo, replicaremos o estudo de Edelman, Luca, e Svirsky (2017) sobre discriminação racial de hosts no Airbnb em algumas cidades americanas. Em particular, o estudo consiste em um experimento de campo (field experiment), com 20 perfis criados com nomes fictícios distintivos de pessoas afro-americanas e de pessoas brancas, meio a meio, pedindo informação em anúncios selecionados. Dessa forma, o resultado final é que alguns anúncios de hospedagem foram selecionados aleatoriamente para receber um pedido de pessoas com determinada cor/raça inferida pelo nome, enquanto outros, não. Como é possível ver na figura Figura 1, abaixo, o resultado do experimento mostra que pessoas com nomes indicativos de pessoas afro-americanas tiveram 8 pontos percentuais menos respostas positivas aos seus pedidos do que pessoas com nomes indicativos de pessoas brancas.\n\n\n\nFigura 1: Resultados principais do artigo"
  },
  {
    "objectID": "replicacao/replicacao1.html#replicação",
    "href": "replicacao/replicacao1.html#replicação",
    "title": "Replicação I",
    "section": "Replicação",
    "text": "Replicação\nO exercício de replicação consistirá em reproduzir os resultados da tabela acima (correspondentes à Tabela 2 do paper). Para tanto, deverá ser seguido o template de replicação em Quarto (ver aqui) discutido em aula para produzir um documento final em formato PDF com cerca de 6 páginas (sem contar referências bibliográficas, tabelas e gráficos). O arquivo .qmd usado, com códigos, também deverá ser entregue.\nOs dados (já limpos) necessários para o exercício podem ser obtidos no link a seguir:\n\nReplicação de Edelman, Luca, e Svirsky (2017)\n\nA descrição do material replicação do texto pode ser obtido aqui.\n\nVariáveis\nAs principais variáveis usadas no estudo são as seguintes:\n\nyes, variável dependente usada na Tabela 2\nhost_response, variável dependente com múltiplas categorias\nguest_black, tratamento\nguest_female, tratamento alternativo\nhost_race_black, indicador de raça do host (afro-americano)\nhost_gender_M, host mulher\nmultiple_listings, host com mais de um anúncio\nshared_property, propriedade compartilhada\nten_reviews, host com mais de 10 avaliações\nlog_price, preço da hospedagem (log)\nname_by_city, indicador de nome-cidade (para cluster dos erros)\n\nOutras variáveis não mencionadas acima poderão ser usadas/criadas."
  },
  {
    "objectID": "replicacao/replicacao1.html#critérios-de-avaliação",
    "href": "replicacao/replicacao1.html#critérios-de-avaliação",
    "title": "Replicação I",
    "section": "Critérios de avaliação",
    "text": "Critérios de avaliação\nA avaliação levará em conta a capacidade de implementar o conhecimento visto no curso e o esforço aplicado na tarefa – e não a obtenção de um resultado específico. Em particular, vale o esforço de tentar testar as medidas escolhidas, o escopo da amostra, estimador e especificação de modelos, seleção de variáveis de controle, etc."
  },
  {
    "objectID": "topicos/topico1.html",
    "href": "topicos/topico1.html",
    "title": "Simulações",
    "section": "",
    "text": "Em aula, estudamos Processos Geradores de Dados (PGDs) e probabilidade. Nestas notas, veremos agora como podemos usar funções de probabilidade – que, lembrando, servem para atribuir probabilidade a eventos possíveis, que chamamos de \\(\\omega\\), de um espaço amostral, que definimos como \\(\\Omega\\) – para simular dados. Isso será particularmente útil nas próximas aulas, mas também nos dará mais experiência com visualização de dados usando ggplot2.\nAntes de começar, vamos carregar o tidyverse:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "topicos/topico1.html#introdução",
    "href": "topicos/topico1.html#introdução",
    "title": "Simulações",
    "section": "",
    "text": "Em aula, estudamos Processos Geradores de Dados (PGDs) e probabilidade. Nestas notas, veremos agora como podemos usar funções de probabilidade – que, lembrando, servem para atribuir probabilidade a eventos possíveis, que chamamos de \\(\\omega\\), de um espaço amostral, que definimos como \\(\\Omega\\) – para simular dados. Isso será particularmente útil nas próximas aulas, mas também nos dará mais experiência com visualização de dados usando ggplot2.\nAntes de começar, vamos carregar o tidyverse:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "topicos/topico1.html#distribuições",
    "href": "topicos/topico1.html#distribuições",
    "title": "Simulações",
    "section": "Distribuições",
    "text": "Distribuições\nO R tem diversas funções que nos permitem sortear números de acordo com algumas distribuições. Abaixo, exemplos das mais comuns.\n\nUniformeBernoulliBinomialNormalPoisson\n\n\n\n# Sorteia um número entre 0 e 1\nrunif(1, min = 0, max = 1)\n\n[1] 0.4408237\n\n\n\n\n\n# Sorteia 1 com probabilidade 0.5\nrbinom(1, size = 1, prob = 0.5)\n\n[1] 1\n\n\n\n\n\n# Dez sequências de Bernoulli com prob. 0.5\nrbinom(1, size = 10, prob = 0.5)\n\n[1] 6\n\n\n\n\n\n# Sorteia um número de uma distribuição normal\nrnorm(1, mean = 0, sd = 1)\n\n[1] -2.4109\n\n\n\n\n\n# Sorteia um número de uma distribuição Poisson\nrpois(1, lambda = 1)\n\n[1] 3"
  },
  {
    "objectID": "topicos/topico1.html#criando-funções-de-probabilidade",
    "href": "topicos/topico1.html#criando-funções-de-probabilidade",
    "title": "Simulações",
    "section": "Criando funções de probabilidade",
    "text": "Criando funções de probabilidade\nAlgumas funções para sortear valores de distribuições mais complexas podem ser construídas a partir de funções mais simples. Por exemplo, podemos usar a uniforme para simular uma distribuição Bernoulli:\n\np &lt;- 0.5\nresultado &lt;- runif(1, min = 0, max = 1) &lt; p\nas.numeric(resultado)\n\n[1] 0\n\n\nO que fizemos? Basicamente, realizamos um sorteio a partir de uma distribuição \\(Uniforme(0, 1)\\) e, se ele for maior que \\(p\\), o resultistribuiçado desse sorteio é convertido para 1, caso contrário, para 0.\nPodemos fazer esse processo mil vezes para visualizar o resultado com um gráfico de barras:\n\np &lt;- 0.5\nn &lt;- 1000\nX &lt;- runif(n, min = 0, max = 1) &lt; p\nX &lt;- as.numeric(X)\n\ntibble(X = X) %&gt;%\n  ggplot(aes(x = X)) +\n  geom_bar() +\n  theme_minimal()"
  },
  {
    "objectID": "topicos/topico1.html#simulando-lançamentos-de-um-dado",
    "href": "topicos/topico1.html#simulando-lançamentos-de-um-dado",
    "title": "Simulações",
    "section": "Simulando lançamentos de um dado",
    "text": "Simulando lançamentos de um dado\nLançamentos de um dado geralmente são simulados a partir de uma distribuição multinomial – mas, já que em um lançamento a probabilidade de tirarmos qualquer face em um sorteio é a mesma (e.g., \\(p_1 = p_2 = ... p_6\\)), podemos criar nossa própria função de probabilidade para simular esse processo usando runif novamente. A ideia é a seguinte:\n\nSortearemos um número entre 0 e 6 usando \\(X \\sim Unif(0, 6)\\)\nSe \\(0 &lt; x \\leq 1\\), o resultado é 1; se \\(1 &lt; x \\leq 2\\), o resultado é 2; e assim por diante\nRepetimos o processo \\(n\\) vezes\n\n\nn &lt;- 1000\nX &lt;- runif(n, min = 0, max = 6)\nX &lt;- ceiling(X)\n\ntibble(X = X) %&gt;%\n  ggplot(aes(x = X)) +\n  geom_bar(width = 0.5, fill = \"orangered\") +\n  theme_minimal() +\n  labs(y = \"Frequência\", x = \"Face do dado\",\n  title = \"Simulações de lançamentos de um dado\")"
  },
  {
    "objectID": "topicos/topico3.html",
    "href": "topicos/topico3.html",
    "title": "Regressão linear múltipla",
    "section": "",
    "text": "Estas notas tem um objetivo bem simples: ensinar como usar o pacote fixest para rodar regressões lineares com efeitos fixos (além de outras utilidades).\nUsaremos como exemplo, novamente, os dados de Ross (2001). Vamos carregá-los com:\n\nlibrary(haven)\nross &lt;- read_dta(\"doesoil_clean.dta\")"
  },
  {
    "objectID": "topicos/topico3.html#introdução",
    "href": "topicos/topico3.html#introdução",
    "title": "Regressão linear múltipla",
    "section": "",
    "text": "Estas notas tem um objetivo bem simples: ensinar como usar o pacote fixest para rodar regressões lineares com efeitos fixos (além de outras utilidades).\nUsaremos como exemplo, novamente, os dados de Ross (2001). Vamos carregá-los com:\n\nlibrary(haven)\nross &lt;- read_dta(\"doesoil_clean.dta\")"
  },
  {
    "objectID": "topicos/topico3.html#fixest",
    "href": "topicos/topico3.html#fixest",
    "title": "Regressão linear múltipla",
    "section": "Fixest",
    "text": "Fixest\nO fixest serve basicamente para rodar modelos de regressão linear e generalizados de forma rápida – especialmente em bancos grandes, com muitos grupos e ou especificações complexas. O primeiro passo para usá-lo, como sempre, é instalar e carregar o pacote:\n\ninstall.packages(\"fixest\")\nlibrary(fixest)\n\nIsso feito, vamos rodar um modelo simples para regredir regime em oil com a função feols, como viemos fazendo:\n\nfeols(regime ~ oil, data = ross)\n\nNOTE: 1,822 observations removed because of NA values (LHS: 19, RHS: 1,806).\n\n\nOLS estimation, Dep. Var.: regime\nObservations: 2,708 \nStandard-errors: IID \n             Estimate Std. Error  t value  Pr(&gt;|t|)    \n(Intercept)  2.403693   0.150973  15.9214 &lt; 2.2e-16 ***\noil         -0.172361   0.010298 -16.7366 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 7.30456   Adj. R2: 0.09347\n\n\nO resultado é o mesmo que obteríamos com lm:\n\nlm(regime ~ oil, data = ross)\n\n\nCall:\nlm(formula = regime ~ oil, data = ross)\n\nCoefficients:\n(Intercept)          oil  \n     2.4037      -0.1724  \n\n\nO grande diferencial do fixest, no entanto, é podermos usar uma sintaxe simples para declarar efeitos fixos (within), algo que pode ser feito com:\n\nfeols(regime ~ oil | cty_name, data = ross)\n\nNOTE: 1,822 observations removed because of NA values (LHS: 19, RHS: 1,806).\n\n\nOLS estimation, Dep. Var.: regime\nObservations: 2,708 \nFixed-effects: cty_name: 130\nStandard-errors: Clustered (cty_name) \n    Estimate Std. Error  t value Pr(&gt;|t|) \noil 0.000353   0.011302 0.031206  0.97515 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 3.76654     Adj. R2: 0.746899\n                Within R2: 2.544e-7\n\n\nNo código acima, variáveis que aparecem depois do | são entendidas como efeitos fixos, isto é, tratadas como variáveis discretas e que, nesse caso, ocupam o lugar do intercept, indicando a média de regime para cada país quando oil é zero.\nOutra utilidade do fixest é permitir incluirmos erros-padrão por cluster – para sinalizar que nossas observações dentro de um mesmo país não são iid. Fazemos isso com:\n\nfeols(regime ~ oil | cty_name, data = ross, cluster = ~ cty_name)\n\nNOTE: 1,822 observations removed because of NA values (LHS: 19, RHS: 1,806).\n\n\nOLS estimation, Dep. Var.: regime\nObservations: 2,708 \nFixed-effects: cty_name: 130\nStandard-errors: Clustered (cty_name) \n    Estimate Std. Error  t value Pr(&gt;|t|) \noil 0.000353   0.011302 0.031206  0.97515 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 3.76654     Adj. R2: 0.746899\n                Within R2: 2.544e-7\n\n\nNote que, embora estimativas não tenham mudado, erros-padrão e p-valores foram alterados."
  },
  {
    "objectID": "topicos/topico3.html#tabelas",
    "href": "topicos/topico3.html#tabelas",
    "title": "Regressão linear múltipla",
    "section": "Tabelas",
    "text": "Tabelas\nOutra utilidade do fixest é permitr a criação e exportação rápida de tabelas padronizadas com resultados de modelos de regressão. Para isso, bastar usarmos a função etable. A título de exemplo, vamos criar três modelos para compará-los em uma tabela:\n\nm1 &lt;- feols(regime ~ oil, data = ross)\n\nNOTE: 1,822 observations removed because of NA values (LHS: 19, RHS: 1,806).\n\nm2 &lt;- feols(regime ~ oil | cty_name, data = ross)\n\nNOTE: 1,822 observations removed because of NA values (LHS: 19, RHS: 1,806).\n\nm3 &lt;- feols(regime ~ oil | cty_name + year, data = ross)\n\nNOTE: 1,822 observations removed because of NA values (LHS: 19, RHS: 1,806).\n\n\nO primeiro é o nosso modelo simples de regime ~ oil, que é acrescido de efeitos fixos para países e, posteriormente, de efeitos fixos para anos. Para criar a tabela, basta usarmos:\n\netable(m1, m2, m3)\n\n                                 m1              m2              m3\nDependent Var.:              regime          regime          regime\n                                                                   \nConstant          2.404*** (0.1510)                                \noil             -0.1724*** (0.0103) 0.0004 (0.0113) 0.0193 (0.0144)\nFixed-Effects:  ------------------- --------------- ---------------\ncty_name                         No             Yes             Yes\nyear                             No              No             Yes\n_______________ ___________________ _______________ _______________\nS.E. type                       IID    by: cty_name    by: cty_name\nObservations                  2,708           2,708           2,708\nR2                          0.09380         0.75905         0.80002\nWithin R2                        --         2.54e-7         0.00086\n---\nSignif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPor padrão, as tabelas do fixest incluem uma série de informações que não usamos tanto, além de usar os nomes das variáveis brutas nas linhas. Abaixo, segue um exemplo de tabela mais compacta, com um padrão mais próximo do que costuma ser usado em artigos:\n\netable(m1, m2, m3, \n    digits = \"r2\", \n    fitstat = c(\"n\", \"g\"), \n    se.below = T, \n    dict = c(regime = \"Polity\",\n            oil = \"Petróleo (% do PIB)\",\n            cty_name = \"País\",\n            year = \"Ano\"),\n    depvar = F, \n    #tex = T, style.tex = style.tex(\"aer\"), # Para PDF!\n    notes = \"Notas: modelos de regressão estimados com o pacote fixest.\",\n    title = \"Efeito do petróleo no regime\")\n\n                          m1       m2       m3\nConstant             2.40***                  \n                    (0.15)                    \nPetróleo (% do PIB) -0.17***    0.00     0.02 \n                    (0.01)     (0.01)   (0.01)\nFixed-Effects:      -------- -------- --------\nPaís                     No      Yes      Yes\nAno                       No       No      Yes\n___________________ ________ ________ ________\nS.E. type                IID by: País by: País\nObservations           2,708    2,708    2,708\nG                      2,706      130      130\n---\nSignif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nA maioria dos argumentos acima, como é possível ver, são intuitivos. De toda forma, para uma consulta mais detalhada de todas as possibilidades da função é possível obter ajuda com help(etable).1"
  },
  {
    "objectID": "topicos/topico3.html#simulações",
    "href": "topicos/topico3.html#simulações",
    "title": "Regressão linear múltipla",
    "section": "Simulações",
    "text": "Simulações\nEm aula, vimos um app simples que simulava um processo gerados de dados com duas variáveis independentes para ilustrar como a seleção de coeficientes afeta os resíduos de um modelo. Para facilitar seu uso, o link para o app segue abaixo:\n\nApp de resíduos"
  },
  {
    "objectID": "topicos/topico3.html#footnotes",
    "href": "topicos/topico3.html#footnotes",
    "title": "Regressão linear múltipla",
    "section": "Notas de rodapé",
    "text": "Notas de rodapé\n\n\nVale notar que, para exibir a tabela corretamente em PDF é necessário usar os argumentos tex = T e style.tex = style.tex(\"aer\").↩︎"
  },
  {
    "objectID": "topicos/topico5.html",
    "href": "topicos/topico5.html",
    "title": "Regressão descontínua",
    "section": "",
    "text": "Estas notas cobrem como estimar efeitos causais locais usando estratégias de regressão descontínua. Como o nome canônico da estratégia sugere, usaremos modelos de regressão para isso, mas também veremos como usar o pacote rdrobust que implementa um estimador mais adequado, que dá mais peso para observações próximas à descontinuidade; seleciona uma janela ótima para estimação; e usa polinômios. Para praticar, usaremos dados simulados e, também, a base de dados de Lee (2008), disponíveis aqui e que podem ser carregados com:\n\nload(\"lee.rda\")\n\nTambém precisaremos instalar o pacote rdrobust:\n\ninstall.packages(\"rdrobust\")\n\nInstalar também um pacote que criei para facilitar a criação de tabelas com resultados de RDD1:\n\nif(!require(remotes)) install.packages(\"remotes\")\nremotes::install_github(\"meirelesff/iesp\")\n\nE carregar pacotes necessários:\n\nlibrary(modelsummary) # Tabelas de regressão\nlibrary(tidyverse)\nlibrary(rdrobust)\nlibrary(fixest)\nlibrary(iesp) # Necessário pra termos tabelas de RDD"
  },
  {
    "objectID": "topicos/topico5.html#introdução",
    "href": "topicos/topico5.html#introdução",
    "title": "Regressão descontínua",
    "section": "",
    "text": "Estas notas cobrem como estimar efeitos causais locais usando estratégias de regressão descontínua. Como o nome canônico da estratégia sugere, usaremos modelos de regressão para isso, mas também veremos como usar o pacote rdrobust que implementa um estimador mais adequado, que dá mais peso para observações próximas à descontinuidade; seleciona uma janela ótima para estimação; e usa polinômios. Para praticar, usaremos dados simulados e, também, a base de dados de Lee (2008), disponíveis aqui e que podem ser carregados com:\n\nload(\"lee.rda\")\n\nTambém precisaremos instalar o pacote rdrobust:\n\ninstall.packages(\"rdrobust\")\n\nInstalar também um pacote que criei para facilitar a criação de tabelas com resultados de RDD1:\n\nif(!require(remotes)) install.packages(\"remotes\")\nremotes::install_github(\"meirelesff/iesp\")\n\nE carregar pacotes necessários:\n\nlibrary(modelsummary) # Tabelas de regressão\nlibrary(tidyverse)\nlibrary(rdrobust)\nlibrary(fixest)\nlibrary(iesp) # Necessário pra termos tabelas de RDD"
  },
  {
    "objectID": "topicos/topico5.html#regressão-global",
    "href": "topicos/topico5.html#regressão-global",
    "title": "Regressão descontínua",
    "section": "Regressão global",
    "text": "Regressão global\nComumente, RDD é descrita como a diferença vertical, em unidades de \\(Y\\), entre duas curvas (ou regressão) estimadas de cada lado de uma descontinuidade que atribui algum tratamento quando \\(X \\geq c\\) (ver Skovron e Titiunik 2015). Na prática, isso significa estimar um modelo de regressão linear por mínimos quadrados que permita que a reta da relação entre \\(Y\\) e \\(X\\) varie em cada lado de \\(c\\).\nPara exemplificar a ideia, podemos simular um PGD no qual temos uma variável \\(X \\sim Normal(0, 1)\\) (i.e., média zero, desvio de 1) e que gere \\(Y_i\\) como \\(Y_i \\sim X_i*0.8 + \\epsilon_i\\), em que \\(\\epsilon_i \\sim Normal(0, 1)\\) é um erro aleatório. O código para simular sorteios desse processo e plotar os resultados é:\n\n# Isso serve para replicarmos o sorteio\nset.seed(123)\n\n# Simula os dados\nn &lt;- 200\ndados &lt;- tibble(x = rnorm(n, 0, 1)) %&gt;% \n  mutate(y = x*0.8 + rnorm(n, 0, 1))\n\n# Plota\ndados %&gt;% \n  ggplot(aes(x = x, y = y)) +\n  geom_point() +\n  theme_minimal()\n\n\n\n\nComo dá para ver, temos uma relação bivariada positiva, no sentido de que \\(Y_i | X_i\\), isto é, a média condicional de \\(Y_i\\) depende de valores de \\(X_i\\). Com isso, estamos a um passo de entender um PGD comum em descontinuidades: a única diferença é que temos também um tratamento, \\(D_i \\in \\{1, 0\\}\\), que é recebido apenas por unidades \\(_i\\) que tiverem valores de \\(X_i\\) maiores do que um ponto de corte qualquer, \\(c\\). Se \\(c=0\\), por exemplo, \\(D_{i:X_i &gt; c} = 1\\).\nPodemos atualizar nosso PGD com essa nova variável, assumindo que o tratamento causa um aumento de \\(2\\) pontos em \\(Y_i\\), isto é, \\(Y_i \\sim X_i*0.8 + 2 * (X_i &gt; c) + \\epsilon_i\\):\n\n# Simula os dados\ndados &lt;- tibble(x = rnorm(n, 0, 1)) %&gt;% \n  mutate(d = as.numeric(x &gt; 0)) %&gt;%\n  mutate(y = x*0.2 + 2*d + rnorm(n, 0, 1))\n\n# Plota\ndados %&gt;% \n  ggplot(aes(x = x, y = y, color = as.factor(d))) +\n  geom_point() +\n  theme_minimal() +\n  scale_color_manual(values = c(\"#EF2D56\", \"#363537\")) +\n  labs(color = \"Tratamento (D)\")\n\n\n\n\nEntendendo como simular um PGD que atribui um tratamento descontinuamente2, podemos passar para a estimação do efeito que estipulamos, \\(\\hat{\\tau} = 2\\).\n\nUm modelo linear rígido\nUma primeira tentativa de estimar o efeito local no nosso exemplo anterior é rodar uma regressão incluindo a variável de tratamento, \\(D_i\\), e \\(X_i\\). O código para isso é:\n\n# Estima o modelo\nmodelo &lt;- lm(y ~ x + d, data = dados)\nsummary(modelo)\n\n\nCall:\nlm(formula = y ~ x + d, data = dados)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.36217 -0.69477  0.02199  0.67711  2.74985 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.09237    0.14299   0.646  0.51900    \nx            0.32557    0.12354   2.635  0.00907 ** \nd            1.77689    0.23822   7.459 2.72e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.027 on 197 degrees of freedom\nMultiple R-squared:  0.5604,    Adjusted R-squared:  0.556 \nF-statistic: 125.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16\n\n\nA estimativa de \\(\\hat{\\tau}\\) é bem próxima, mas vale investigarmos visualmente o que esse modelo estimou:\n\n# Plota\ndados %&gt;% \n  ggplot(aes(x = x, y = y, color = as.factor(d))) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = F, formula = y ~ x + (x &gt; 0), color = \"black\") +\n  theme_minimal() +\n  scale_color_manual(values = c(\"#EF2D56\", \"#363537\")) +\n  labs(color = \"Tratamento (D)\") \n\n\n\n\nPelo gráfico, talvez dê para perceber o seguinte: a inclinação da reta (o slope), ou o coeficiente de x, é o mesmo dos dois lados da descontinuidade. Como \\(\\hat{\\beta_0}\\) indica a média de \\(Y_i\\) quando \\(X_i=0\\), essa é valor estimado de \\(Y_i\\) quando \\(lim_{X_i \\uparrow c}\\); por outro lado, o efeito estimado de \\(D_i\\) (\\(\\hat{beta_2}\\)) indica o efeito médio local, que é o quanto a reta sobe (ou desce) quando \\(X_i\\) passa de \\(c\\) para \\(c+1\\) – a nossa estimativa de \\(lim_{X_i \\downarrow c}\\) é \\(\\hat{\\beta_0} + \\hat{beta_2}\\) e, portanto,\n\\[\n\\hat{\\tau}_{RDD} = \\hat{\\beta_0} + \\hat{\\beta_2} - \\hat{\\beta_0} = \\hat{\\beta_2}\n\\]\n\n\nUm modelo flexível\nNo mais das vezes, não podemos assumir que a relação entre \\(Y | X\\) é a mesma dos dois lados da descontinuidade. Para lidar com isso, podemos estimar um modelo flexível, que permita que a reta de regressão varie em cada lado de \\(c\\), incluindo um termo multiplicativo adicional:\n\\[\nY_i = \\beta_0 + \\beta_1 X_i + \\beta_2 D_i + \\beta_3 X_i D_i + \\epsilon_i\n\\]\nIncluindo o coeficiente \\(\\beta_3\\), estamos permitindo que a inclinação da reta varie em cada lado de \\(c\\). O código para estimar esse novo modelo é:\n\n# Estima o modelo\nmodelo &lt;- lm(y ~ x + d + x*d, data = dados)\nsummary(modelo)\n\n\nCall:\nlm(formula = y ~ x + d + x * d, data = dados)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.28380 -0.68065  0.03589  0.67026  2.76755 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.12503    0.16818   0.743   0.4581    \nx            0.36758    0.16779   2.191   0.0297 *  \nd            1.78186    0.23912   7.452 2.88e-12 ***\nx:d         -0.09223    0.24861  -0.371   0.7111    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.029 on 196 degrees of freedom\nMultiple R-squared:  0.5608,    Adjusted R-squared:  0.554 \nF-statistic: 83.41 on 3 and 196 DF,  p-value: &lt; 2.2e-16\n\n\nO novo gráfico:\n\n# Plotando os dados\ndados %&gt;% \n  ggplot(aes(x = x, y = y, color = as.factor(d), group = d)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = F, formula = y ~ x, color = \"black\") +\n  theme_minimal() +\n  scale_color_manual(values = c(\"#EF2D56\", \"#363537\")) +\n  labs(color = \"Tratamento (D)\") \n\n\n\n\nA diferença entre retas é pouco perceptível nesse exemplo, mas considere o seguinte:\n\n# Simula os dados\ndados &lt;- tibble(x = rnorm(n, 0, 1)) %&gt;% \n  mutate(d = as.numeric(x &gt; 0)) %&gt;%\n  mutate(y = x*0.2 + 2*d + -1*x*d + rnorm(n, 0, 1))\n\n# Estima o modelo\nrigido &lt;- feols(y ~ x + d, data = dados)\nflexivel &lt;- feols(y ~ x + d + x*d, data = dados)\n\netable(rigido, flexivel, digits = 3)\n\n                           rigido        flexivel\nDependent Var.:                 y               y\n                                                 \nConstant         -0.443** (0.134)  -0.242 (0.171)\nx               -0.512*** (0.112)  -0.255 (0.176)\nd                 2.19*** (0.231) 2.13*** (0.232)\nx x d                             -0.428. (0.227)\n_______________ _________________ _______________\nS.E. type                     IID             IID\nObservations                  200             200\nR2                        0.36055         0.37193\nAdj. R2                   0.35405         0.36232\n---\nSignif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nA diferença é ínfima, mas, visualmente, é perceptível:\n\n# Plota os dados\ndados %&gt;% \n  ggplot(aes(x = x, y = y, color = as.factor(d))) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = F, formula = y ~ x + (x &gt; 0), color = \"black\") +\n  geom_smooth(method = \"lm\", se = F, formula = y ~ x + (x &gt; 0) + x*(x &gt; 0), color = \"#E03616\") +\n  theme_minimal() +\n  scale_color_manual(values = c(\"#EF2D56\", \"#363537\")) +\n  labs(color = \"Tratamento (D)\")"
  },
  {
    "objectID": "topicos/topico5.html#regressão-local",
    "href": "topicos/topico5.html#regressão-local",
    "title": "Regressão descontínua",
    "section": "Regressão local",
    "text": "Regressão local\nO estimador mais adequado e comum para RDD é o que usa apenas observações próximas da descontinuidade, isto é, que usa apenas observações em uma janela em torno de \\(c\\). O quão próximas as observações precisam ser? Digamos que, no nosso exemplo, uma janela \\(c=0.2\\) seja adequada. O código para estimar esse modelo é:\n\n# Estima o modelo\ndados_janela &lt;- dados %&gt;%\n    filter(abs(x) &lt; 0.2)\n\nlocal &lt;- feols(y ~ x + d + x*d, data = dados_janela)\n\n# Resultados\netable(rigido, flexivel, local, digits = 3)\n\n                           rigido        flexivel           local\nDependent Var.:                 y               y               y\n                                                                 \nConstant         -0.443** (0.134)  -0.242 (0.171)  -0.394 (0.394)\nx               -0.512*** (0.112)  -0.255 (0.176)    -2.61 (3.45)\nd                 2.19*** (0.231) 2.13*** (0.232) 2.30*** (0.610)\nx x d                             -0.428. (0.227)     2.67 (5.15)\n_______________ _________________ _______________ _______________\nS.E. type                     IID             IID             IID\nObservations                  200             200              39\nR2                        0.36055         0.37193         0.61592\nAdj. R2                   0.35405         0.36232         0.58299\n---\nSignif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nO resultado do modelo flexível é nitidamente enviesado. Como?"
  },
  {
    "objectID": "topicos/topico5.html#janela",
    "href": "topicos/topico5.html#janela",
    "title": "Regressão descontínua",
    "section": "Janela",
    "text": "Janela\nComo dá para perceber, a escolha da janela tem consequências e, no mais das vezes, pesquisas aplicadas testam vários deles (justamente porque seu uso incorreto pode gerar viés, como no caso anterior). Se plotarmos os dados anteriores, veremos que, nesse caso, o viés decorre da falta de observações:\n\n# Plota os dados\ndados_janela %&gt;% \n  ggplot(aes(x = x, y = y, color = as.factor(d), group = d)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = F, formula = y ~ x, color = \"black\") +\n  theme_minimal() +\n  scale_color_manual(values = c(\"#EF2D56\", \"#363537\")) +\n  labs(color = \"Tratamento (D)\") \n\n\n\n\nUm exercício é usar diferentes intervalos:\n\n# Estima o modelo\nmod1 &lt;- feols(y ~ x + d + x*d, data = dados %&gt;% filter(abs(x) &lt; 1))\nmod2 &lt;- feols(y ~ x + d + x*d, data = dados %&gt;% filter(abs(x) &lt; 0.75))\nmod3 &lt;- feols(y ~ x + d + x*d, data = dados %&gt;% filter(abs(x) &lt; 0.5))\nmod4 &lt;- feols(y ~ x + d + x*d, data = dados %&gt;% filter(abs(x) &lt; 0.2))\n\n# Resultados\netable(mod1, mod2, mod3, mod4, digits = 3)\n\n                           mod1            mod2            mod3            mod4\nDependent Var.:               y               y               y               y\n                                                                               \nConstant         -0.289 (0.211)  -0.195 (0.241)  -0.235 (0.310)  -0.394 (0.394)\nx                -0.429 (0.419)  -0.067 (0.613)   -0.348 (1.33)    -2.61 (3.45)\nd               2.23*** (0.296) 2.14*** (0.351) 2.14*** (0.442) 2.30*** (0.610)\nx x d            -0.341 (0.600)  -0.738 (0.956)   -0.229 (1.77)     2.67 (5.15)\n_______________ _______________ _______________ _______________ _______________\nS.E. type                   IID             IID             IID             IID\nObservations                128             105              81              39\nR2                      0.47660         0.49073         0.48744         0.61592\nAdj. R2                 0.46393         0.47561         0.46747         0.58299\n---\nSignif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "topicos/topico5.html#rdrobust",
    "href": "topicos/topico5.html#rdrobust",
    "title": "Regressão descontínua",
    "section": "rdrobust",
    "text": "rdrobust\nNa prática, acertar escolha de janela, especificação, entre outros detalhes, não é algo simples. Por essa razão, o padrão corrente na literatura é usar o estimador proposto por Calonico, Cattaneo, e Titiunik (2015), disponível no pacote rdrobust, que usa um algoritmo para selecionar janela automaticamente (balanceando viés e precisão); corrige erros-padrão; e permite usar polinômios para flexibilizar a relação entre \\(Y\\) e \\(X\\).3 Podemos aplicá-lo nos dados que geramos (lembrando, \\(\\tau=2\\)):\n\n# Estima o modelo\nresultados &lt;- rdrobust(dados$y, dados$x)\nsummary(resultados)\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                  200\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                   99          101\nEff. Number of Obs.              50           52\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   0.699        0.699\nBW bias (b)                   1.162        1.162\nrho (h/b)                     0.602        0.602\nUnique Obs.                      99          101\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     2.175     0.379     5.738     0.000     [1.432 , 2.918]     \n        Robust         -         -     4.718     0.000     [1.261 , 3.053]     \n=============================================================================\n\n\nE produzir um gráfico com uma única linha de código:\n\nrdplot(dados$y, dados$x)\n\n\n\n\nCom os dados de Lee (2008), estimamos o efeito local também usando:\n\n# Aplica o estimador\nresultados &lt;- rdrobust(Lee2008$y, Lee2008$x)\n\nWarning in rdrobust(Lee2008$y, Lee2008$x): Mass points detected in the running\nvariable.\n\nsummary(resultados)\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 6558\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                 2740         3818\nEff. Number of Obs.             789          817\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   0.136        0.136\nBW bias (b)                   0.240        0.240\nrho (h/b)                     0.565        0.565\nUnique Obs.                    2108         2581\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     0.064     0.011     5.815     0.000     [0.042 , 0.085]     \n        Robust         -         -     4.738     0.000     [0.035 , 0.084]     \n============================================================================="
  },
  {
    "objectID": "topicos/topico5.html#especificação-e-exportação",
    "href": "topicos/topico5.html#especificação-e-exportação",
    "title": "Regressão descontínua",
    "section": "Especificação e exportação",
    "text": "Especificação e exportação\nPor padrão, a função rdrobust estima modelos de regressão locais com polinômio de ordem 1, usando como cutoff 0, entre outros. Assim como em outras funções usadas para estimar modelos, no entanto, podemos mudar várias coisas nela: a ordem do polinômio usado (argumento p =); valor do cutoff (argumento c =); e a janela usada (argumento h =).\nUsando os dados de Lee (2008), podemos, por exemplo, estimar diferentes modelos RDD que variam o polinômio usado, de 1 a 3:\n\n# Estima os modelos\nmod1 &lt;- rdrobust(Lee2008$y, Lee2008$x, p = 1)\nmod2 &lt;- rdrobust(Lee2008$y, Lee2008$x, p = 2)\nmod3 &lt;- rdrobust(Lee2008$y, Lee2008$x, p = 3)\nmodelos &lt;- list(\"Polinômio 1\" = mod1,\n                \"Polinômio 2\" = mod2,\n                \"Polinômio 3\" = mod3)\n\n# Tabela\nmodelsummary(modelos, digits = 2, coef_map = list(\"Robust\" = \"LATE\"))\n\n\n\n\n\nPolinômio 1\n Polinômio 2\n Polinômio 3\n\n\n\n\nLATE\n0.059\n0.063\n0.055\n\n\n\n(0.013)\n(0.012)\n(0.015)\n\n\nJanela\n0.1\n0.3\n0.3\n\n\nN\n1606\n3161\n3484\n\n\n\n\n\n\n\nÚtil saber: usamos a função modelsummary para exportar uma tabela com os resultados dos três modelos, que foram passados para a lista modelos acompanhada dos nomes de cada um.\nE se quisermos mudar a janela usada, isto é, a distância aceitável entre pontos e a descontinuidade? Fácil: é só mudar h:\n\n# Estima os modelos\nmod1 &lt;- rdrobust(Lee2008$y, Lee2008$x, h = 0.01)\nmod2 &lt;- rdrobust(Lee2008$y, Lee2008$x, h = 0.05)\nmod3 &lt;- rdrobust(Lee2008$y, Lee2008$x, h = 0.1)\nmodelos &lt;- list(\"Janela 0.01\" = mod1,\n                \"Janela 0.05\" = mod2,\n                \"Janela 0.1\" = mod3)\n\n# Tabela\nmodelsummary(modelos, digits = 2, coef_map = list(\"Robust\" = \"LATE\"))\n\n\n\n\n\nJanela 0.01\n Janela 0.05\nJanela 0.1\n\n\n\n\nLATE\n0.086\n0.105\n0.064\n\n\n\n(0.047)\n(0.023)\n(0.016)\n\n\nJanela\n0\n0\n0.1\n\n\nN\n104\n610\n1208\n\n\n\n\n\n\n\n\nTabelas com modelos diferentes\nPara o caso em que cada modelo tiver uma variável dependente diferente, podemos mostrar resultados de uma forma ligeiramente diferente:\n\nmodelsummary(modelos, digits = 2, \n              shape = model ~ term + statistic,\n            coef_map = list(\"Robust\" = \"LATE\"))\n\n\n\n\n\n\n\n\n\n\n\nLATE\n\n\n\n\nEst.\nS.E.\n\n\n\n\nJanela 0.01\n0.086\n0.047\n\n\nJanela 0.05\n0.105\n0.023\n\n\nJanela 0.1\n0.064\n0.016\n\n\n\n\n\n\n\nAqui, shape = model ~ term + statistic diz para a função modelsummary que queremos colocar os diferentes modelos nas linhas e, nas colunas, os coeficientes e estatísticas."
  },
  {
    "objectID": "topicos/topico5.html#footnotes",
    "href": "topicos/topico5.html#footnotes",
    "title": "Regressão descontínua",
    "section": "Notas de rodapé",
    "text": "Notas de rodapé\n\n\nNo futuro, talvez eu inclua mais funcionalidades nesse pacote, mas, por enquanto, ele só serve para isso mesmo.↩︎\nHá outras formas de simular um RDD, e em PGDs do mundo real não há garantias de que a relação entre \\(X\\) e \\(Y\\) é não-linear, ou que o efeito do tratamento, \\(D\\), não varie com \\(X\\), isto é, \\(D | X\\).↩︎\nO estimador é mais complexo do que isso e, na realidade, faz outras coisas, como aplicar pesos diferentes a determinadas observações, o que é chamado de kernel.↩︎"
  }
]