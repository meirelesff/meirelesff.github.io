[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ciência de Dados e Aprendizado de Máquina em Ciência Política",
    "section": "",
    "text": "Este é website com materias do curso Ciência de Dados e Aprendizado de Máquina em Ciência Política, ministrado no Programa de Pós-Graduação de Ciência Política da Universidade de São Paulo (USP). Neste espaço serão postados, uma semana antes de cada aula, os materiais de apoio que estudaremos em laboratório.\nA ementa do curso pode ser encontrada aqui."
  },
  {
    "objectID": "index.html#cronograma",
    "href": "index.html#cronograma",
    "title": "Ciência de Dados e Aprendizado de Máquina em Ciência Política",
    "section": "Cronograma",
    "text": "Cronograma\n\n\n\n\n\n\nAviso\n\n\n\nEste é um cronograma inicial sujeito a modificações\n\n\n\n\n\nAula\nData\nTópico\n\n\n\n\n1\n17/08\nApresentação\n\n\n2\n24/08\nIntrodução & Revisão de Programação\n\n\n3\n31/08\nAprendizado Supervisionado: Classificação\n\n\n-\n7/09\nSem aula (Feriado)\n\n\n4\n14/09\nAprendizado Supervisionado: Modelos Lineares\n\n\n-\n21/09\nSem aula (ABCP)\n\n\n5\n28/09\nAprendizado Supervisionado: Text as Data\n\n\n6\n5/10\nAprendizado Supervisionado: Modelos Não-Lineares\n\n\n-\n12/10\nSem aula (Feriado)\n\n\n-\n19/10\nSem aula (Anpocs)\n\n\n7\n26/10\nEnsemble: Stacking, Bagging, Boosting\n\n\n-\n2/11\nSem aula (Feriado)\n\n\n8\n9/11\nAprendizado Não-Supervisionado\n\n\n9\n16/11\nResampling & Validação\n\n\n10\n23/11\nTuning & Feature Selection\n\n\n11\n30/11\nDeep learning\n\n\n12\n7/12\nRevisão de Trabalhos Finais & Encerramento"
  },
  {
    "objectID": "materiais/aula1.html",
    "href": "materiais/aula1.html",
    "title": "Aula 1",
    "section": "",
    "text": "O que é Ciência de Dados? O que são modelos de aprendizado de máquina? Qual a relevância de um curso sobre isso em uma pós-graduação de Ciência Política? Essa aula de apresentação oferecerá algumas respostas a essas perguntas. Além disso, veremos alguns exemplos de aplicação de Ciência de Dados na área das Ciências Sociais, tanto na academia quanto no mercado."
  },
  {
    "objectID": "materiais/aula1.html#primeiras-tarefas",
    "href": "materiais/aula1.html#primeiras-tarefas",
    "title": "Aula 1",
    "section": "Primeiras tarefas",
    "text": "Primeiras tarefas\nNosso trabalho ao longo do curso será muito mais fácil se formos capazes de versionar nossos códigos, isto é, registrar organizadamente mudanças ao longo do tempo. Por conta disso, antes de mais nada será necessário que cada aluno e aluna tenha uma conta no GitHub para usar o git – o mais famoso gerenciador de versões de código open source. Esses são os passos que deverão ser seguidos para tanto:\n\nCrie uma conta no GitHub clicando aqui\nBaixe e instale o git para o seu sistema operacional\nAprenda a\n\nClonar repositórios\nAdicionar e commitar alterações\nSubir alterações e checar status de um repo\n\n\nEm IDEs mais modernas, como Rstudio e VScode, é possível fazer isso de forma simples, sem necessidade abrir o terminal. Aqui há tutoriais cobrindo os dois casos, aqui e aqui.\nPara evitar ter de digitar login e senha repetidamente no git, o ideal é salvar suas credenciais. O modo de se fazer isso variará de acordo com o seu sistema operacional, mas, em geral, digitar isso no seu terminal deve funcionar:\ngit config --global credential.helper store\nEsse método salvará suas credenciais de forma não criptografada, o que não é muito seguro. Se você usa muito git, possui códigos sensíveis e usa Windows, outra alternativa é usar:\ngit config --global credential.helper manager\nO equivalente para Mac OS X é:\ngit config --global credential.helper osxkeychain\n\nBásico de git\n\ngit clone\nA primeira etapa para trabalhar usando versionamento de código é ter um repositório monitorado pelo git. É possível criar um do zero, mas, nesse curso, vamos seguir um caminho mais simples: clonando um repositório criado diretamente no GitHub por vocês (veremos isso em aula).\nO primeiro passo, nesse caso, consiste em achar a página do repositório no GitHub e extrair sua URL .git. O print abaixo mostra como fazer isso – basta clicar em Code, em verde, e copiar a URL que aparece.\n\n\n\n\nURL de um repositório no GitHub\n\n\n\nIsso feito, basta abrir seu terminal, navegar até a pasta onde você deseja salvar o repositório e executar:11 <URL> deve ser trocado pela URL que você copiou na etapa anterior\ngit clone <URL>\n\n\ngit branch\nCada repositório no git tem vários branches, isto é, uma espécie de diretório onde cada novo código adicionado será armazenado. Com o uso de branches, é possível ter diversas versões do mesmo projeto salvas no mesmo repositório, cada uma totalmente diferente da outra caso isso seja útil.\nPor padrão, o branch padrão no GitHub é nomeado main, mas é importante checar isso – vamos precisar usar o nome do branch onde vamos trabalhar pra subir código. Para obter o nome do branch atual, use:\ngit branch\nÉ uma boa prática criar um branch para fazer testes em um código, ou para testar novas funcionalidades. Fazendo isso, qualquer novo código que seja adicionado ficará pendente de revisão no GitHub, o que idealmente deve ser feito por outra pessoa. Aqui há um pequeno texto que trata sobre isso.\n\n\ngit add e git commit\nSuponhamos que você clonou um repositório e adicionou nele um script. Como subir ele para o GitHub? Simples:\ngit add .\nCom isso, toda e qualquer alteração no repositório no seu computador será registrada para ser adicionada ao repositório principal no GitHub. Antes disso, no entanto, é necessário fazer um commit, criar e documentar um snapshot do seu código. Para isso, use:\ngit commit -m \"Meu primeiro arquivo\"\nNote que usamos -m para registrar uma mensagem, algo útil para sabermos o que cada snapshot tem de diferente em relação ao código anterior. É sempre uma boa prática manter esses registros.\n\n\ngit push e git status\nTendo feito alterações e registrado elas com commit, para subir elas para o GitHub basta rodar:\ngit push origin main\nIsso feito, é possível checar o estado atual do repositório com:\ngit status\nO que, se tudo der certo, deve retornar uma mensagem similar a esta abaixo.\n\n\n\ngit status\n\n\n\n\nArquivos básicos\nPor motivos de organização e de armazenamento, há dois arquivos essenciais, que todo repositório no GitHub deve ter: README.md e .gitignore.\nO README.md é um arquivo de texto (em markdown, na verdade) que é exibido na página inicial de um repositório e que serve para documentar seus códigos. Considere sempre criar um e adicione informações úteis, tais como: objetivo do código, o que ele faz, de onde vieram dados, como rodar scripts, entre outros.\nJá o .gitignore serve para registrar alguns arquivos que o git deverá ignorar, ou seja, que o git deixará de fora do versionamento. Isso é útil para bases de dados que, em geral, ocupam bastante espaço de armazenamento e não devem ser hospedadas no GitHub (ele possui um limite de 50mb por arquivo). Prefira sempre armazenar o código que baixa e processa os dados que você precisará, e não uma versão da base de dados já limpa.\n\n\n\nPor que usar versionamento de código?\n\nHave you ever:\n\nMade a change to code, realised it was a mistake and wanted to revert back?\nLost code or had a backup that was too old?\nHad to maintain multiple versions of a product?\nWanted to see the difference between two (or more) versions of your code?\nWanted to prove that a particular change broke or fixed a piece of code?\nWanted to review the history of some code?\nWanted to submit a change to someone else’s code?\nWanted to share your code, or let other people work on your code?\nWanted to see how much work is being done, and where, when and by whom?\nWanted to experiment with a new feature without interfering with working code?\n\nIn these cases, and no doubt others, a version control system should make your life easier.\nTo misquote a friend: A civilised tool for a civilised age.\n\nSabedoria retirada do StackOverflow."
  },
  {
    "objectID": "materiais/aula1.html#materiais-de-apoio",
    "href": "materiais/aula1.html#materiais-de-apoio",
    "title": "Aula 1",
    "section": "Materiais de apoio",
    "text": "Materiais de apoio\n\nTerminal\nÉ muito comum entrar no mundo da Ciência de Dados, ou da programação com R ou Python, sem saber usar o terminal – a famosa telinha preta de onde é possível executar uma série de funções e comandos em bash. Saber usá-lo de forma eficiente, no entanto, é algo útil para automatizar tarefas, instalar dependências necessárias para o funcionamento de alguns softwares e, também, trabalhar com git.\nCaso você precise preencher essa lacuna, estude e pratique o conteúdo desse workshop:\n\nD-Lab Workshop on Bash-Git\n\n\n\nGit e GitHub\nPara praticar ou aprender a usar recursos mais avançados do git e do GitHub, vale consultar:\n\nDocumentação oficial do GitHub\nLearn the Basics of Git in Under 10 Minutes"
  },
  {
    "objectID": "materiais/aula2.html",
    "href": "materiais/aula2.html",
    "title": "Aula 2",
    "section": "",
    "text": "Esta aula cobre as diferenças entre aprendizado de máquia, ou aprendizagem estatística, e outras abordagens de análise de dados. Para quem está habituado a pensar em inferência e propriedades de estimadores, o que veremos é um pouco diferente: nosso objetivo, pelo menos na maioria das nossas aplicações, será predição. A diferença importa e tem a ver, essencialmente, com o tipo de pergunta que poderemos responder.\n\n\nExistem várias definições que poderíamos usar, mas a distinção entre predição e inferência oferica no ITSL é útil. Considere um exemplo hipotético: sabemos quanto candidaturas gastaram em uma eleição, \\(X_{i}\\), e quantos votos obtiveram, \\(Y_{i}\\); com essas informações, poderíamos estimar um modelo como \\(Y_{i} = \\beta X_{i} + \\epsilon_{i}\\). O resultado do modelo estimado nos permitiria, por exemplo, avaliar se o gasto de campanha tem efeito positivo sobre votos, ou para fazer um chute embasado sobre o desempenho de uma candidatura no futuro. No primeiro caso, queremos inferir sobre o processo que deu origem aos dados; no segundo, predizer uma nova ocorrência.\nAlguns exemplos de problemas de inferência:\n\nExaminar se a iluminação pública tem relação com assaltos em São Paulo\nDescobrir quanto um carro desvaloriza com um ano a mais de uso\nSaber se pessoas com ensino superior ganham mais do que as demais\n\nAlguns exemplos de problemas de predição:\n\nA partir de exemplos de um texto de spam, identificar se um texto qualquer é ou não spam\nUsar dados fiscas dos municípios para predizer a votação de uma candidatura específica à reeleição\nOferecer uma sugestão de filme baseada no histórico de usos na Netflix"
  },
  {
    "objectID": "materiais/aula2.html#funções",
    "href": "materiais/aula2.html#funções",
    "title": "Aula 2",
    "section": "Funções",
    "text": "Funções\nCriar funções é algo extremamente útil para se automatizar determinadas rotinas. Neste curso, vamos usar, em alguns casos, funções específicas para facilitar o nosso trabalho. Caso tenha dúvidas, consulte este capítulo do R4DS ou este tutorial do Real Python."
  },
  {
    "objectID": "materiais/aula2.html#controle-de-fluxo",
    "href": "materiais/aula2.html#controle-de-fluxo",
    "title": "Aula 2",
    "section": "Controle de fluxo",
    "text": "Controle de fluxo\nUsar loops é algo normalmente praticado em cursos básicos, mas, para quem tem dúvidas, vale consultar rapidamente essa este capítulo do R4DS, para quem usa R, e este tutorial do Real Python."
  },
  {
    "objectID": "materiais/aula2.html#frameworks",
    "href": "materiais/aula2.html#frameworks",
    "title": "Aula 2",
    "section": "Frameworks",
    "text": "Frameworks\nVamos queimar várias etapas e ir logo para a aplicação dos frameworks. Nas próximas aulas, daremos vários passos atrás e cobriremos detidamente algoritmos e etapas de um projeto.\n\nTarefas\nEm R, será necessário carregar o pacote mle3 e seguir este tutorial. Tente acompanhar o código e ir modificando ele para ver o que acontece (fique à vontade para usar outros modelos ou outros datasets, como o mtcars, que já vem por padrão no pacote datasets).\nEm python, siga o getting started do Sci-kit learn, também brincando com o código. O exemplo, nesse caso, é mais complexo e cobre mais etapas de uma pipeline."
  },
  {
    "objectID": "ementa.html",
    "href": "ementa.html",
    "title": "Ementa",
    "section": "",
    "text": "Ementa\n\n\n\nA versão em PDF da ementa pode ser obtida aqui."
  },
  {
    "objectID": "ementa.html#apresentação",
    "href": "ementa.html#apresentação",
    "title": "Ementa",
    "section": "Apresentação",
    "text": "Apresentação\nEste curso introduz um conjunto de ferramentas que nos permitem usar dados de diferentes formatos para responder questões substantivas sobre política. Com ênfase em aprendizado de máquina – i.e., modelos que aprendem a fazer generalizações a partir do reconhecimento de padrões em amostras –, seu objetivo principal é capacitar alunos(as) a aplicar noções de Ciência de Dados e de programação em problemas concretos de classificação, predição e descoberta, o que lhes permitirá construir aplicações como classificadores de texto e de imagem, detectores de outliers ou modelos flexíveis de MrP.\nA abordagem do curso será principalmente prática. Na maior parte do tempo, estudaremos tópicos por meio da resolução de exercícios e da replicação de papers, dentro e fora de sala de aula. De início, após cobrirmos noções úteis de programação de revisarmos a aplicação de modelos de regressão, estudaremos os diferentes tipos de problemas em Ciência de Dados; tipos de aprendizagem e seus principais algoritmos; estratégias de validação e de tuning; e, finalmente, realizaremos projetos que servirão para testar conhecimentos adquiridos. Concluído este percurso, a expectativa é que alunos e alunas obtenham a experiência necessária para incorporar skills de Ciência de Dados em suas rotinas de pesquisa ou de trabalho."
  },
  {
    "objectID": "ementa.html#objetivos",
    "href": "ementa.html#objetivos",
    "title": "Ementa",
    "section": "Objetivos",
    "text": "Objetivos\nSão estes os principais objetivos de ensino do curso:\n\nDesenvolver habilidades de programação. Embora este não seja um curso que ensinará programação diretamente – a como uma forma de aplicar aprendizado de máquina –, alunos e alunas terão a oportunidade de praticar a escrita de código para resolver problemas de pesquisa.\nAprender a conduzir projetos básicos de Ciência de Dados de ponta a ponta. Entre outros, alunos e alunas apreenderão a estruturar perguntas em Ciência de Dados, organizar dados necessários e definir estratégias para respondê-las – o que incluirá criar pipelines, estabelecer métricas de avaliação, validar e ajustar modelos e algoritmos, entre outros.\nEstimular o trabalho colaborativo em pesquisa científica. Por conta da dinâmica do curso, que envolverá trabalhos em duplas e desenvolvimento de papers, alunos e alunas serão desafiados a identificar produções recentes na literatura internacional; e a redigir textos que os(as) ajudem a preparar teses, dissertações ou artigos para publicação."
  },
  {
    "objectID": "ementa.html#pré-requisitos",
    "href": "ementa.html#pré-requisitos",
    "title": "Ementa",
    "section": "Pré-requisitos",
    "text": "Pré-requisitos\nO curso pressupõe conhecimentos de estatística, modelos de regressão e análise de dados. Formalmente, o pré-requisito é já ter cursado a disciplina FLS 6183 Métodos Quantitativos II.\nTambém é esperado que alunos(as) tenham familiaridade com R ou Python. Como escolher entre as duas linguagens? Se você já trabalha com R e seus interesses são acadêmicos, seguir com essa escolha é o melhor; por ser mais demandado no mercado e ser mais usado em áreas conexas, como a engenharia de dados, Python pode ser interessante para quem deseja se qualificar profissionalmente, mas é necessário já ter um nível de programação para além do básico para conseguir acompanhar o curso. Em qualquer caso, recursos didáticos serão disponibilizados em ambas as linguagens, ainda que a minha capacidade de fornecer ajuda seja consideravelmente maior em R."
  },
  {
    "objectID": "ementa.html#leituras",
    "href": "ementa.html#leituras",
    "title": "Ementa",
    "section": "Leituras",
    "text": "Leituras\nEmbora tenhamos poucas leituras analíticas, manuais serão usados para cobrir a implementação de modelos e estudo de conceitos. São eles:\n\n[ITSL] Introduction to statistical learning\n[HML] Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow\n[MLRTM] Machine Learning with R, the tidyverse, and mlr\n[MLR3] MLR3 Book"
  },
  {
    "objectID": "ementa.html#logística",
    "href": "ementa.html#logística",
    "title": "Ementa",
    "section": "Logística",
    "text": "Logística\nNossas aulas terão dois blocos. No inicial e menor deles, teremos uma exposição dos temas abordados e discussão dos trabalhos de leitura indicada. Encerrada esta parte, teremos sessões nas quais alunas e alunos aplicarão conhecimentos vistos. Para facilitar essa parte, usaremos pair programming, prática que consiste no trabalho em duplas no qual há uma parte que principalmente escreve código e, a outra, o revisa e comenta em tempo real."
  },
  {
    "objectID": "ementa.html#avaliação",
    "href": "ementa.html#avaliação",
    "title": "Ementa",
    "section": "Avaliação",
    "text": "Avaliação\nO aproveitamento no curso de cada estudante será avaliado de três formas: exercícios, que serão realizados dentro e fora de sala; dois pequenos projetos; e um working paper final. A nota final no curso será dada pela soma aritmética das notas de cada tarefa avaliativa.\n\nExercícios (15%)\nEm cada aula teremos uma lista de exercícios para praticar o conteúdo visto. Estes serão apresentados em cada aula e deverão ser realizados em duplas seguindo o sistema de pair programming para serem entregues até a aula seguinte. A entrega pontual e regular dos exercícios e o esforço aplicado para resolvê-los serão os critérios de avaliação.\n\n\nProjetos (35%)\nTambém teremos dois pequenos projetos que deverão ser entregues individualmente no formato de notebooks (feitos com Rmarkdown ou Jupyter). A ideia é que ambos os desafios não apenas testem conhecimentos, mas, também, ofereçam ideias de uso de aprendizado de máquina para pesquisas em Ciência Política. Nestes, a avaliação levará em conta a capacidade de aplicar o conhecimento visto ao longo do curso e a capacidade de cumprir os objetivos propostos.\n\nProjeto 1 – Classificador de discursos presidenciais (15%)\nNo primeiro projeto, o objetivo será treinar um modelo de classificação de textos para identificar a autoria de uma amostra de discursos presidenciais no Brasil. Para tanto, será necessário pré-processar textos, transformá-los em bag of words e, finalmente, selecionar modelos mais adequados. Com o trabalho, deverá ser possível derivar probabilidades de um dado discurso ter sido proferido por cada um e cada uma dos presidentes brasileiros incluídos na amostra.\n\n\nProjeto 2 – Classificador de imagens de satélite (20%)\nNo segundo projeto, que corresponderá a 20% da nota final do curso, extraíremos imagens de satélite de locais de votação georreferenciados no Brasil para, usando redes neurais convolucionais, os classificarmos em determinadas categorias. O resultado final deverá ser uma pipeline que permita gerar diferentes esquemas de classificações de imagens de satélite de locais de votação (ou de outras localidades georreferenciadas) no Brasil.\n\n\n\nWorking paper (50%)\nFinalmente, os(as) alunos(as) deverão entregar um working paper a título de avaliação final. Este deverá aplicar algum dos métodos que veremos no curso e ter entre 10 e 15 páginas. Idealmente, será possível aproveitar essa oportunidade para rascunhar um capítulo de tese ou dissertação, ou um artigo para publicação futura. Para estimular o trabalho colaborativo, serão aceitos trabalhos finais realizados em dupla. Criatividade, aplicação correta de noções vistas no curso e estrutura dos textos (i.e., boas motivações, seções adequadas de metodologia e de resultados) serão avaliados.\nNa última aula, alunos e alunas apresentarão suas ideias e resultados parciais para obterem feedback e tirar dúvidas. A datas de entrega da avaliação será combinada no decorrer do curso."
  },
  {
    "objectID": "ementa.html#política-de-gênero",
    "href": "ementa.html#política-de-gênero",
    "title": "Ementa",
    "section": "Política de Gênero",
    "text": "Política de Gênero\nEm aulas de metodologia, homens frequentemente monopolizam a participação. Para evitar isso, seguiremos três protocolos neste curso: no uso de computadores nas atividades de pair programming, mulheres serão priorizadas; para intervir, é necessário estender a mão; quando mulheres falam, colegas não as interrompem."
  },
  {
    "objectID": "ementa.html#atendimento-a-necessidades-especiais",
    "href": "ementa.html#atendimento-a-necessidades-especiais",
    "title": "Ementa",
    "section": "Atendimento a Necessidades Especiais",
    "text": "Atendimento a Necessidades Especiais\nAlunas(os) com quaisquer necessidades ou solicitações individuais não devem exitar em procurar auxílio, tanto por e-mail quanto pessoalmente."
  },
  {
    "objectID": "ementa.html#ferramentas",
    "href": "ementa.html#ferramentas",
    "title": "Ementa",
    "section": "Ferramentas",
    "text": "Ferramentas\nPara resolver tarefas e praticar em casa, certifique-se de ter as ferramentas que usaremos devidamente instaladas em seu computador ou notebook. Para quem usará R, isso inclui tê-lo instalado e, também, o Rstudio. É possível encontrar tutoriais na internet cobrindo os passos necessários. Já para quem pretende usar Python, minha recomendação é usar Python 3 e alguma IDE como VScode ou spyder para escrever e gerenciar scripts e repositórios.\nPara além destes softwares, será necessário instalar algumas das libraries. Em Python, usaremos principalmente o biblioteca Scikit-learn, que oferece um conjunto de ferramentas de pré-processamento, construção de pipelines, seleção e validação de modelos, para além uma ampla gama de algoritmos supervisionados e não-supervisionados; e a biblioteca Keras, que é uma suíte para a construção de modelos de deep learning via Tensorflow. A depender do seu sistema operacional e da disponibilidade de pré-requisitos em seu computador, ambas as bibliotecas podem retornar erros durante a instalação, caso no qual eu posso tentar ajudar em sala ou por e-mail. Também é recomendado utilizar um ambiente virtual antes de fazer qualquer coisa (aqui uma explicação).\nPara instalar os pacotes que precisaremos, basta executar do terminal:\npip install --upgrade pip\npip install tensorflow scikit\nEm R, o equivalente mais próximo do Scikit-learn é a biblioteca mlr3, que também oferece um conjunto de ferramentas e adota princípios de programação orientada a objetos (discutiremos isso em aula). Keras e Tensorflow, por sua vez, já têm versões em R. Para instalar todos os pacotes que usaremos, basta rodar o seguinte código no R:\n\ninstall.packages(c(\"mrl3\", \"tensorflow\", \"keras\"))\n\nIsso feito, é preciso instalar o Tensorflow propriamente dito, o que pode ser feito com:\n\nlibrary(tensorflow)\ninstall_tensorflow()"
  },
  {
    "objectID": "ementa.html#plano-das-aulas",
    "href": "ementa.html#plano-das-aulas",
    "title": "Ementa",
    "section": "Plano das Aulas",
    "text": "Plano das Aulas\n\nAula 1 – Apresentação do curso\n\nLeituras sugeridas:\n\nSalganik (2019)\n\n\n\n\nAula 2 – Introdução à Ciência de Dados & Revisão de Programação\n\nLeituras:\n\nITSL, Cap. 2.1 & 2.2\nHML, Cap. 1\n\nLeituras sugeridas\n\nAthey e Imbens (2019)\nGrimmer, Roberts, e Stewart (2021)\n\n\n\n\nAula 3 – Aprendizado Supervisionado: Classificação\n\nLeituras:\n\nITSL, Cap. 4\n\nLeituras sugeridas:\n\nStreeter (2019)\nMüller (2022)\n\n\n\n\nAula 4 – Aprendizado Supervisionado: Modelos Lineares\n\nLeituras:\n\nITSL, Cap. 3\nHML, Cap. 2 (para Python)\nMLR3, Cap. 2 (para R)\nITSL, Cap. 6\n\nLeituras sugeridas:\n\nLi e Shugart (2016)\nErikson e Wlezien (2021)\n\nAula 5 – Aprendizado Supervisionado: Text as Data\nLeituras:\n\n…\n\nLeituras sugeridas:\n\nBarberá et al. (2021)\nErlich et al. (2021)\n\n\n\n\nAula 6 – Aprendizado Supervisionado: Modelos Não-Lineares\n\nLeituras:\n\nITSL, Cap. 7\n\n\n\n\nAula 7 – Ensemble: Stacking, Bagging, Boosting\n\nLeituras:\n\nITSL, Cap. 8\n\nLeituras sugeridas:\n\nKaufman, Kraft, e Sen (2019)\nMontgomery e Olivella (2018)\nChen e Zhang (2021)\nBroniecki, Leemann, e Wüest (2022)\n\n\n\n\nAula 8 – Aprendizado Não-Supervisionado\n\nLeituras:\n\nITSL, Cap. 12\n\nLeituras sugeridas:\n\nMagyar (2022)\nMueller e Rauh (2018)\nZucco Jr e Power (2021)\n\n\n\n\nAula 9 – Resampling & Validação\n\nLeituras:\n\nITSL, Cap. 5\n\nLeituras sugeridas:\n\nNeunhoeffer e Sternberg (2019)\nRaschka (2018)\n\n\n\n\nAula 10 – Tuning & Feature Selection\n\nLeituras:\n\nMLR3, Cap. 4\n\nLeituras sugeridas:\n\nDenny e Spirling (2018)\nJordan, Paul, e Philips (2022)\n\n\n\n\nAula 11 – Deep learning\n\nITSL, Cap. 10\nHML, Cap. 10.1\nLeituras sugeridas:\n\nChang e Masterson (2020)\nCantú (2019)\nMuchlinski et al. (2021)\n\n\n\n\nAula 12 – Revisão de Trabalhos Finais & Encerramento"
  },
  {
    "objectID": "ementa.html#referências",
    "href": "ementa.html#referências",
    "title": "Ementa",
    "section": "Referências",
    "text": "Referências\n\n\nAthey, Susan, e Guido W Imbens. 2019. «Machine learning methods that economists should know about». Annual Review of Economics 11: 685–725.\n\n\nBarberá, Pablo, Amber E Boydstun, Suzanna Linn, Ryan McMahon, e Jonathan Nagler. 2021. «Automated text classification of news articles: A practical guide». Political Analysis 29 (1): 19–42.\n\n\nBroniecki, Philipp, Lucas Leemann, e Reto Wüest. 2022. «Improved Multilevel Regression with Poststratification through Machine Learning (autoMrP)». The Journal of Politics 84 (1): 000–000.\n\n\nCantú, Francisco. 2019. «The fingerprints of fraud: Evidence from Mexico’s 1988 presidential election». American Political Science Review 113 (3): 710–26.\n\n\nChang, Charles, e Michael Masterson. 2020. «Using word order in political text classification with long short-term memory models». Political Analysis 28 (3): 395–411.\n\n\nChen, Ling, e Hao Zhang. 2021. «Strategic Authoritarianism: The Political Cycles and Selectivity of China’s Tax-Break Policy». American Journal of Political Science 65 (4): 845–61.\n\n\nDenny, Matthew J, e Arthur Spirling. 2018. «Text preprocessing for unsupervised learning: Why it matters, when it misleads, and what to do about it». Political Analysis 26 (2): 168–89.\n\n\nErikson, Robert S, e Christopher Wlezien. 2021. «Forecasting the 2020 presidential election: Leading economic indicators, polls, and the vote». PS: Political Science & Politics 54 (1): 55–58.\n\n\nErlich, Aaron, Stefano G Dantas, Benjamin E Bagozzi, Daniel Berliner, e Brian Palmer-Rubin. 2021. «Multi-label Prediction for Political Text-as-data». Political Analysis, 1–18.\n\n\nGrimmer, Justin, Margaret E Roberts, e Brandon M Stewart. 2021. «Machine learning for social science: An agnostic approach». Annual Review of Political Science 24: 395–419.\n\n\nJordan, Soren, Hannah L Paul, e Andrew Q Philips. 2022. «How to Cautiously Uncover the “Black Box” of Machine Learning Models for Legislative Scholars». Legislative Studies Quarterly.\n\n\nKaufman, Aaron Russell, Peter Kraft, e Maya Sen. 2019. «Improving supreme court forecasting using boosted decision trees». Political Analysis 27 (3): 381–87.\n\n\nLi, Yuhui, e Matthew S Shugart. 2016. «The seat product model of the effective number of parties: A case for applied political science». Electoral Studies 41: 23–34.\n\n\nMagyar, Zsuzsanna B. 2022. «What makes party systems different? A principal component analysis of 17 advanced democracies 1970–2013». Political Analysis 30 (2): 250–68.\n\n\nMontgomery, Jacob M, e Santiago Olivella. 2018. «Tree-Based Models for Political Science Data». American Journal of Political Science 62 (3): 729–44.\n\n\nMuchlinski, David, Xiao Yang, Sarah Birch, Craig Macdonald, e Iadh Ounis. 2021. «We need to go deeper: Measuring electoral violence using convolutional neural networks and social media». Political Science Research and Methods 9 (1): 122–39.\n\n\nMueller, Hannes, e Christopher Rauh. 2018. «Reading between the lines: Prediction of political violence using newspaper text». American Political Science Review 112 (2): 358–75.\n\n\nMüller, Stefan. 2022. «The temporal focus of campaign communication». The Journal of Politics 84 (1): 000–000.\n\n\nNeunhoeffer, Marcel, e Sebastian Sternberg. 2019. «How cross-validation can go wrong and what to do about it». Political Analysis 27 (1): 101–6.\n\n\nRaschka, Sebastian. 2018. «Model evaluation, model selection, and algorithm selection in machine learning». arXiv preprint arXiv:1811.12808.\n\n\nSalganik, Matthew J. 2019. Bit by bit: Social research in the digital age. Princeton University Press. https://www.bitbybitbook.com/en/1st-ed/.\n\n\nStreeter, Shea. 2019. «Lethal force in black and white: Assessing racial disparities in the circumstances of police killings». The Journal of Politics 81 (3): 1124–32.\n\n\nZucco Jr, Cesar, e Timothy J Power. 2021. «Fragmentation without cleavages? Endogenous fractionalization in the Brazilian party system». Comparative Politics 53 (3): 477–500."
  },
  {
    "objectID": "recursos.html",
    "href": "recursos.html",
    "title": "Recursos",
    "section": "",
    "text": "Para acompanhar o curso, conhecimentos intermediários em programaçãosão necessários. Nesta página, listo algumas referências e recursos úteis para o aprimoramento desses pré-requisitos."
  },
  {
    "objectID": "recursos.html#programação",
    "href": "recursos.html#programação",
    "title": "Recursos",
    "section": "Programação",
    "text": "Programação\n\nR\n\nR for Data Science, Garrett Grolemund and Hadley Wickham.\n\nLivro essencial, cobre o básico até o intermediário do uso de R e do tidyverse aplicados à Ciência de Dados\n\nR Cookbook, Winston Chang\n\nLivro prático focado na resolução de problemas comuns\n\nRStudio cheatsheets\n\nGuias práticos para resolução de diferentes problemas com tidyverse\n\nRweekly\n\nNewsletter semanal com novidades sobre R\n\n\n\n\nPython\n\nPython for Data Analysis, Wes McKinney\n\nEm certo sentido, é um livro similar ao R4DS, bom para iniciantes\n\nLearn Python\n\nSite com diversos tutoriais e textos sobre Python\n\nPython cheatsheets\n\nGuias práticos, agora para Python\n\nPycoders\n\nUma das mais lidas newsletters sobre Python"
  },
  {
    "objectID": "exercicios/exercicios2.html",
    "href": "exercicios/exercicios2.html",
    "title": "Exercícios 2",
    "section": "",
    "text": "Para esse exercício, será necessário carregar alguns dados climáticos de São Bernardo do Campo (SP):\n\nRPython\n\n\nlink <- \"https://raw.githubusercontent.com/jacobwright32/Web_Scraper_AI_Core_Project/bb4865ae568e23ab8fadb6ea58cf117df2164ef3/web%20scraping/Cleaned%20Data/Brazil_Sao%20Bernardo%20Do%20Campo_Cleaned.csv\"\ndados <- readr::read_csv(link)\n\n\nimport pandas as pd\n\nlink = 'https://raw.githubusercontent.com/jacobwright32/Web_Scraper_AI_Core_Project/bb4865ae568e23ab8fadb6ea58cf117df2164ef3/web%20scraping/Cleaned%20Data/Brazil_Sao%20Bernardo%20Do%20Campo_Cleaned.csv'\nc = pd.read_csv(link)\n\n\n\n\n\nAnalise a relação entre entre cobertura de nuvens (cloud_coverage) e temperatura máxima (maximum_temperature). Para isso, plote gráficos com a relação bivariada, use coeficiente de correlação ou um modelo linear (OLS). Descreva os resultados que encontrar.\n\n\n\nExiste alguma outra variável na base com maior correção com a temperatura máxima? Novamente, registre os resultados que encontrar.\n\n\n\nCrie um código que faça um gráfico da relação bivariada entre todas as variáveis contínuas na base e os salve em disco. Dica:\n\nRPython\n\n\nlibrary(tidyverse)\n\np <- ggplot()\nggsave(p, file = paste0(\"grafico.png\"))\n\n\nfrom matplotlib import pyplot as plt\nplt.savefig('grafico.png')\n\n\n\n\n\n\nRode modelos lineares simples (por mínimos quadrados ordinários) para predizer a temperatura máxima diária em São Bernardo do Campo (SP). Use as variáveis que quiser, faça transformações nelas se necessário, e reporte alguns resultados do melhor modelo que encontrar.\n\n\n\nSalve as predições do seu modelo treinado no exercício anterior e compare com os valores reais de temperatura máxima (vale usar gráficos)."
  },
  {
    "objectID": "exercicios/exercicios2.html#a-umidade",
    "href": "exercicios/exercicios2.html#a-umidade",
    "title": "Exercícios 2",
    "section": "a) Umidade",
    "text": "a) Umidade\nCrie uma função (ou um código) para sortear 1000 observações do banco de dados climáticos, calcular a média de umidade (humidity)."
  },
  {
    "objectID": "exercicios/exercicios2.html#b-histograma",
    "href": "exercicios/exercicios2.html#b-histograma",
    "title": "Exercícios 2",
    "section": "b) Histograma",
    "text": "b) Histograma\nCom a função criada anteriormente, calcule 1000 médias de amostras de humidity e plote a distribuição como um histograma."
  },
  {
    "objectID": "exercicios/exercicios2.html#c-modelos-lineares",
    "href": "exercicios/exercicios2.html#c-modelos-lineares",
    "title": "Exercícios 2",
    "section": "c) Modelos lineares",
    "text": "c) Modelos lineares\nModifique a função criada anteriormente para, depois de sortear 1000 observações do banco, rodar um modelo de regressão linear para predizer valores de humidity e extrair o r2 do modelo. Dica:\n\nRPython\n\n\nmodelo <- lm(rnorm(100) ~ rnorm(100))\nsummary(modelo)$r.squared\n\n\nfrom matplotlib import pyplot as plt\nplt.savefig('grafico.png')"
  },
  {
    "objectID": "materiais/aula3.html",
    "href": "materiais/aula3.html",
    "title": "Aula 3",
    "section": "",
    "text": "Programação orientada a objetos\nPara quem usa R, as funções do pacote mlr3 podem parecer um pouco estranhas. Para definir uma tarefa de predição linear, por exemplo, usaríamos o seguinte:\nlibrary(mlr3)\n\nmodelo <- as_task_regr(mpg ~ ., data = mtcars)\nlearner <- lrn(\"regr.lm\")\nlearner$train(modelo)\nEm particular, criamos um objeto learner e depois usamos uma função de dentro dele usando o indexador $ – mais, não salvamos o resultado em lugar algum.\nIsso é possível porque o resultado da função $train() – que é um método do objeto learner – é salvo automaticamento dentro de learner, isto é, ele é salvo in place. Essa é uma das principais características da programação orientada a objetos: objetos têm métodos, isto é, funções internas que, em geral, salvam os resultados de suas chamadas in place.4.4 Nem sempre isso ocorre, mas é uma forma intuitiva de se entender o ponto\nEm Python, isso normalmente é o padrão. Vejamos uma regressão usando sci-kit learn (. é o indexador equivalente de $ nesse contexto):\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\nX = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\ny = np.dot(X, np.array([1, 2])) + 3\nreg = LinearRegression()\nreg.fit(X, y)\nNão é essencial saber sobre classes, métodos e programação orientada a objetos, de forma geral, para acompanhar esse curso, mas pode ser útil aprender um pouco mais. Em R, a principal referência é essa parte do livro Advanced R. Para Python, esse artigo é útil.\n\n\n\n\n\n\nReferências\n\nStreeter, Shea. 2019. «Lethal force in black and white: Assessing racial disparities in the circumstances of police killings». The Journal of Politics 81 (3): 1124–32."
  },
  {
    "objectID": "temp.html",
    "href": "temp.html",
    "title": "Materiais",
    "section": "",
    "text": "flowchart LR\n  A[Pergunta] --> B[Problema]\n  B --> C{Decision}\n  C --> D[Result one]\n  C --> E[Result two]"
  },
  {
    "objectID": "temp.html#básico",
    "href": "temp.html#básico",
    "title": "Materiais",
    "section": "Básico",
    "text": "Básico\n\nRPython\n\n\nfizz_buzz <- function(fbnums = 1:50) {\n  output <- dplyr::case_when(\n    fbnums %% 15 == 0 ~ \"FizzBuzz\",\n    fbnums %% 3 == 0 ~ \"Fizz\",\n    fbnums %% 5 == 0 ~ \"Buzz\",\n    TRUE ~ as.character(fbnums)\n  )\n  print(output)\n}\n\n\ndef fizz_buzz(num):\n  if num % 15 == 0:\n    print(\"FizzBuzz\")\n  elif num % 5 == 0:\n    print(\"Buzz\")\n  elif num % 3 == 0:\n    print(\"Fizz\")\n  else:\n    print(num)"
  },
  {
    "objectID": "exercicios/exercicios3.html",
    "href": "exercicios/exercicios3.html",
    "title": "Exercícios 3",
    "section": "",
    "text": "Para esse exercício, será necessário carregar alguns dados sobre violência policial letal nos Estados Unidos:\n\nRPython\n\n\nlink <- \"https://raw.githubusercontent.com/FLS-6497/datasets/main/aula3/PKAP_raw_data.csv\"\ndados <- readr::read_csv(link)\n\n\nimport pandas as pd\n\nlink = 'https://raw.githubusercontent.com/FLS-6497/datasets/main/aula3/PKAP_raw_data.csv'\nc = pd.read_csv(link)\n\n\n\n\n\nFaça gráficos de barras com a frequência da variável race por cada uma das variáveis officer_ na base de dados. O resultado deve indicar quantas vítimas de mortes por violência letal policial de diferentes raças (whites e blacks) ocorreram em diferentes categorias (e.g., office_offduty). Dica: algumas variáveis precisam ser recategorizadas porque possuem muitas categorias com poucas ocorrências.\n\n\n\nCrie uma nova base de dados que inclua apenas as variáveis mencionadas na Tabela 1 do paper de Streeter. Dica: será necessário criar novas variáveis e descartar outras existentes na base. Para quem usa Python, também é importante recodificar variáveis para o formato de one hot encoding (em R, a maioria das funções de regressão já faz essa conversão por baixo dos panos)."
  },
  {
    "objectID": "exercicios/exercicios3.html#a-crie-uma-função-para-sortear-da-base-uma-amostra-de-treino-e-outra-de-teste.-para-isso-a-função-pode-retornar-uma-lista-com-as-duas-amostras.-crie-também-um-argumento-na-função-que-permita-selecionar-o-percentual-de-observações-na-amostra-de-treino-o-default-precisará-ser-0.7.",
    "href": "exercicios/exercicios3.html#a-crie-uma-função-para-sortear-da-base-uma-amostra-de-treino-e-outra-de-teste.-para-isso-a-função-pode-retornar-uma-lista-com-as-duas-amostras.-crie-também-um-argumento-na-função-que-permita-selecionar-o-percentual-de-observações-na-amostra-de-treino-o-default-precisará-ser-0.7.",
    "title": "Exercícios 3",
    "section": "a) Crie uma função para sortear da base uma amostra de treino e, outra, de teste. Para isso, a função pode retornar uma lista com as duas amostras. Crie também um argumento na função que permita selecionar o percentual de observações na amostra de treino (o default precisará ser 0.7).",
    "text": "a) Crie uma função para sortear da base uma amostra de treino e, outra, de teste. Para isso, a função pode retornar uma lista com as duas amostras. Crie também um argumento na função que permita selecionar o percentual de observações na amostra de treino (o default precisará ser 0.7)."
  },
  {
    "objectID": "exercicios/exercicios3.html#b-com-a-função-anterior-retreine-seu-modelo-anterior-na-amostra-de-treino-e-depois-aplique-as-predições-na-amostra-de-teste.",
    "href": "exercicios/exercicios3.html#b-com-a-função-anterior-retreine-seu-modelo-anterior-na-amostra-de-treino-e-depois-aplique-as-predições-na-amostra-de-teste.",
    "title": "Exercícios 3",
    "section": "b) Com a função anterior, retreine seu modelo anterior na amostra de treino e, depois, aplique as predições na amostra de teste.",
    "text": "b) Com a função anterior, retreine seu modelo anterior na amostra de treino e, depois, aplique as predições na amostra de teste."
  },
  {
    "objectID": "exercicios/exercicios3.html#c-com-a-função-anterior-retreine-seu-modelo-usando-diferentes-tamanhos-de-amostra-de-treino-de-0.3-a-0.9-com-intervalos-de-0.05.-crie-um-gráfico-para-reportar-alguma-métrica-de-validação-pode-ser-acurácia-ou-precisão-ou-ainda-f1-e-no-eixo-x-inclua-a-informação-sobre-o-percentual-usado",
    "href": "exercicios/exercicios3.html#c-com-a-função-anterior-retreine-seu-modelo-usando-diferentes-tamanhos-de-amostra-de-treino-de-0.3-a-0.9-com-intervalos-de-0.05.-crie-um-gráfico-para-reportar-alguma-métrica-de-validação-pode-ser-acurácia-ou-precisão-ou-ainda-f1-e-no-eixo-x-inclua-a-informação-sobre-o-percentual-usado",
    "title": "Exercícios 3",
    "section": "c) Com a função anterior, retreine seu modelo usando diferentes tamanhos de amostra de treino, de 0.3 a 0.9 com intervalos de 0.05. Crie um gráfico para reportar alguma métrica de validação (pode ser acurácia ou precisão, ou ainda F1) e, no eixo X, inclua a informação sobre o percentual usado",
    "text": "c) Com a função anterior, retreine seu modelo usando diferentes tamanhos de amostra de treino, de 0.3 a 0.9 com intervalos de 0.05. Crie um gráfico para reportar alguma métrica de validação (pode ser acurácia ou precisão, ou ainda F1) e, no eixo X, inclua a informação sobre o percentual usado"
  },
  {
    "objectID": "exercicios/exercicios3.html#a-modifique-a-função-criada-anteriormente-para-que-ela-já-separe-a-amostra-em-treino-e-teste",
    "href": "exercicios/exercicios3.html#a-modifique-a-função-criada-anteriormente-para-que-ela-já-separe-a-amostra-em-treino-e-teste",
    "title": "Exercícios 3",
    "section": "a) Modifique a função criada anteriormente para que ela já separe a amostra em treino e teste",
    "text": "a) Modifique a função criada anteriormente para que ela já separe a amostra em treino e teste"
  },
  {
    "objectID": "exercicios/exercicios3.html#a-criar-função",
    "href": "exercicios/exercicios3.html#a-criar-função",
    "title": "Exercícios 3",
    "section": "a) Criar função",
    "text": "a) Criar função\nCrie uma função para sortear da base uma amostra de treino e, outra, de teste. Para isso, a função pode retornar uma lista com as duas amostras. Crie também um argumento na função que permita selecionar o percentual de observações na amostra de treino (o default precisará ser 0.7)."
  },
  {
    "objectID": "exercicios/exercicios3.html#b-modelo-com-treino-e-teste",
    "href": "exercicios/exercicios3.html#b-modelo-com-treino-e-teste",
    "title": "Exercícios 3",
    "section": "b) Modelo com treino e teste",
    "text": "b) Modelo com treino e teste\nCom a função anterior, retreine seu modelo anterior na amostra de treino e, depois, aplique as predições na amostra de teste."
  },
  {
    "objectID": "exercicios/exercicios3.html#c-tamanho-das-amostras-de-treino",
    "href": "exercicios/exercicios3.html#c-tamanho-das-amostras-de-treino",
    "title": "Exercícios 3",
    "section": "c) Tamanho das amostras de treino",
    "text": "c) Tamanho das amostras de treino\nCom a função anterior, retreine seu modelo usando diferentes tamanhos de amostra de treino, de 0.3 a 0.9 com intervalos de 0.05. Crie um gráfico para reportar alguma métrica de validação (pode ser acurácia ou precisão, ou ainda F1) e, no eixo X, inclua a informação sobre o percentual usado"
  },
  {
    "objectID": "exercicios/exercicios3.html#a-nova-função",
    "href": "exercicios/exercicios3.html#a-nova-função",
    "title": "Exercícios 3",
    "section": "a) Nova função",
    "text": "a) Nova função\nModifique a função criada anteriormente para que ela já separe a amostra em treino e teste, rode um modelo logístico e retorne alguma métrica de validação."
  },
  {
    "objectID": "exercicios/exercicios3.html#b-cross-validation",
    "href": "exercicios/exercicios3.html#b-cross-validation",
    "title": "Exercícios 3",
    "section": "b) Cross-validation",
    "text": "b) Cross-validation\nUse a função criada anteriormente para rodar 500 modelos logísticos em diferentes amostras de treino e de teste. Reporte os resultados desse exercício com um histograma dos valores de validação de alguma métrica."
  }
]