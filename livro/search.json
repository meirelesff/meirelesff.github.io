[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Usando R",
    "section": "",
    "text": "Prefácio\nEste é um manuscrito em desenvolvimento. A medida em que os capítulos forem concluídos, serão incluídos aqui. Dúvidas e sugestões podem ser enviadas para nossos e-mails.\nPara ver a proposta mais geral do livro, clique aqui.\nBases de dados usadas nos capítulos estão disponíveis aqui.\n…\nAntes de prosseguir, vamos preparar o terreno: o R é um ambiente de programação, o que significa que não abriremos um banco de dados utilizando um menu de tarefas, nem calcularemos estatísticas clicando em um botão. Em vez disso, precisaremos programar, isto é, escrever código de forma ordenada para que o computador o execute sequencialmente. Aprender a programar, especialmente no início, pode ser um pouco difícil, mas acho que não precisamos reforçar o quanto todo o esforço envolvido valerá à pena."
  },
  {
    "objectID": "index.html#nossa-filosofia",
    "href": "index.html#nossa-filosofia",
    "title": "Usando R",
    "section": "Nossa filosofia",
    "text": "Nossa filosofia\nO mote do livro: ensinar a usar R para resolver problemas aplicados de pesquisa social e de análise de dados, e não necessariamente para aprender lógica de programação. No fundo, acreditamos que ir o mais rapidamente possível para a prática é a melhor forma de entender o potencial do R. É por essa razão que não cobrimos de forma aprofundada tópicos considerados essenciais em livros introdutórios de programação, como estruturas de repetição e condicionais e princípios de programação orientada a objetos.\nAlém da opção geral por um livro prático, procuramos seguir alguns princípios menores na escrita desse livro. São eles:\n\nPriorizamos código fácil de ler, mesmo que ele seja um pouco mais extenso;\nPreferimos usar ferramentas simples e versáteis para resolver problemas, e não necessariamente as mais eficientes e especializadas;\nOrganizamos tarefas de análise de dados em módulos independentes, como importação de dados e manipulação, de forma que cada parte possa ser reutilizada em outros projetos;\nPartimos do pressuposto de que, sempre que possível, análises devem ser replicáveis – qualquer pessoa familiarizada com o R deve ser capaz de reproduzir nossos códigos."
  },
  {
    "objectID": "index.html#para-quem-este-livro-é-indicado",
    "href": "index.html#para-quem-este-livro-é-indicado",
    "title": "Usando R",
    "section": "Para quem este livro é indicado?",
    "text": "Para quem este livro é indicado?\nRecomendamos este livro sobretudo para cientistas sociais, economistas e pessoas de áreas próximas que estão dando seus primeiros passos no mundo da metodologia quantitativa e da análise de dados. Nossa ideia é que ele seja um atalho para o aprendizado de R e que, a partir dele, a leitura de livros e manuais mais avançados, como os Wickham, Çetinkaya-Rundel, e Grolemund (2023) ou o de Aquino (2014), seja mais fácil e proveitosa.\nVamos enfatizar: este não é um livro de programação, pelo menos não em sentido estrito. Antes, ele é um guia introdutório para o uso aplicado do R em pesquisa social quantitativa. Respondendo à pergunta do sub-título, este livro é indicado principalmente para quem quer aprender rapidamente a usar o R para resolver problemas reais de pesquisa."
  },
  {
    "objectID": "index.html#como-usar-o-livro",
    "href": "index.html#como-usar-o-livro",
    "title": "Usando R",
    "section": "Como usar o livro",
    "text": "Como usar o livro\nPensamos este livro como um complemento para um curso de R de curta duração, com cinco aulas. Dessa forma, cada capítulo corresponde a um dia de trabalho: antes dos encontros, alunas e alunos idealmente lerão um capítulo para cobrir o conteúdo exposto em aula e, no turno oposto, praticam o que foi visto com os exercícios disponíveis ao final do mesmo capítulo.\nOs capítulos do livro podem ser lidos ou consultados de forma independente, mas seguem um percurso planejado: começamos com o básico sobre como instalar e usar o R e o RStudio e concluímos com modelos de regressão linear simples e multivariados. Por conta disso, para estudo individual sugerimos que cada capítulo seja lido seguindo a sequência em que são apresentados.\n\n\n\n\nAquino, Jakson Alves de. 2014. «R para cientistas sociais». EDITUS-Editora da UESC.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, e Garrett Grolemund. 2023. R for data science. \" O’Reilly Media, Inc.\"."
  },
  {
    "objectID": "01-cap.html#introdução-ao-r",
    "href": "01-cap.html#introdução-ao-r",
    "title": "1  Básico",
    "section": "1.1 Introdução ao R",
    "text": "1.1 Introdução ao R\nEste capítulo é o nosso primeiro encontro com o R. Nele, veremos alguns dos principais conceitos necessários para poder usá-lo para análise de dados – o que, afinal de contas, é o nosso principal objetivo.\nVale reforçar: esta não é uma introdução formal ao R. Antes, este capítulo cobre o fundamental para saltarmos diretamente para o uso de ferramentas mais avançadas, que nos ajudarão a fazer análise de dados e pesquisa acadêmica.\nAntes de começar, no entanto, precisaremos instalar o R. Na verdade, precisaremos instalar dois softwares: o R e o RStudio. O primeiro é de fato o software por detrás da linguagem de programação, mas ele não possui um interface, como o Excel ou outros softwares de armazenamento e análise de dados. É por isso que usaremos o R por meio do segundo software, o RStudio, que é um interface com um conjunto de funcionalidades que nos ajudará a trabalhar com o R. Depois disso, o restante do capítulo focará em como escrever código em R, como salvar e manipular informações na memória, como usar funções e como instalar pacotes."
  },
  {
    "objectID": "01-cap.html#intalando-o-r-e-rstudio",
    "href": "01-cap.html#intalando-o-r-e-rstudio",
    "title": "1  Básico",
    "section": "1.2 Intalando o R e RStudio",
    "text": "1.2 Intalando o R e RStudio\nO R é um programa de código aberto1 que pode ser baixado gratuitamente em https://cran.r-project.org, o site oficial do projeto que mantém o R. Uma vez no site, basta buscar pela opção download e seguir as instruções específicas para o seu sistema operacional.2 A instalação deverá criar um atalho para o R no seu computador que, uma vez acessado, provavelmente mostrará algo como indica a Figura 1.1.\n\n\n\nFigura 1.1: Console do R\n\n\nSem uma interface, o R nada mais é do que um console, uma tela textual onde podemos ler e digitar código. Para termos uma interface melhor, podemos agora baixar o RStudio em https://posit.co/download/rstudio-desktop/, site da empresa que o mantém – apesar de desenvolverem também outras versões, o RStudio Desktop – Open Source License também é gratuito. Novamente, basta buscar a opção mais adequada para o seu sistema operacional e seguir as intruções de instalação. Abrindo o atalho do RStudio, a visão deverá ser bem melhor.\n\n\n\nFigura 1.2: RStudio\n\n\n\n1.2.1 O RStudio\nNo RStudio, temos 4 sub-janelas por padrão, isto é, a janela do software é dividida em quatro áreas diferentes, como ilustra a Figura. Um resumo da utilidade de cada uma:\n\nJanela de script na qual escrevemos e documentamos nossos códigos;\nConsole do R, onde podemos executar código e, também, ter retorno de mensagens de erro e avisos;\nNesta sub-janela tempo duas abas principais:\n\nEnvironment, na qual visualizamos quais objetos estão na memória do R (e.g., vetores, banco de dados, listas);\nHistory, na qual podemos ver o histórico dos códigos que já executamos;\n\nAqui temos cinco abas principais:\n\nFiles, onde é possível visualizar a lista de arquivo da pasta (área de trabalho, no jargão do R) em que você está trabalhando no seu computador;\nPlots, na qual podemos visualizar gráficos criado no R;\nPackages, que exibi pacotes de funções instalados no R; e, (d) Help; onde será visualizadas as ajudas solicitadas dentro do próprio programa;\nView, usada para visualizar o resultado da execução de certas funções.\n\n\nDe início, o mais importante é pensar no RStudio como uma espécie de pacote Office, mas para o R: é nele que escreveremos nossos códigos, executaremos e visualizaremos os seus resultados.\n\n\n1.2.2 Usando o R e o RStudio pelo navegador\nPara quem tem problemas ao instalar o R, ou não pode instalá-lo por qualquer razão, há uma alternativa simples pela nuvem: o Posit Cloud, uma plataforma mantida pela mesma empresa do RStudio que permite o seu uso diretamente pelo navegador, sem a necessidade de instalação. Para usá-lo, basta criar uma conta no site, selecionar o plano gratuito (Free forever) e começar a usar o R de lá. A tela do seu navegador deverá mostrar algo como na Figura 1.3.\n\n\n\nFigura 1.3: Usando o RStudio do navegador"
  },
  {
    "objectID": "01-cap.html#sintaxe-básica-do-r",
    "href": "01-cap.html#sintaxe-básica-do-r",
    "title": "1  Básico",
    "section": "1.3 Sintaxe básica do R",
    "text": "1.3 Sintaxe básica do R\nA partir de agora, começaremos a aprender R do jeito mais direto possível: escrevendo e executando códigos. Para tanto, as próximas seções começarão a introduzir exemplos de código que, a princípio, podem parecer confusas. Mas não se preocupe: o objetivo é aprendermos R de forma prática, sem memorizações, entendendo o que cada parte de um código faz.\nDaqui até o final do livro, o seguinte se aplicará:\n\nTudo o que estiver em caixa cinza, com texto destacado por cores, é código e pode ser executado no R (basta copiar e colar o código no console do RStudio, janela (2) na Figura 1.1, e apertar enter);\nTudo o que estiver logo após precedido de um [1] ou algo do tipo é output do R, isto é, o resultado da execução de um código;\nAlguns códigos dependem de códigos anteriores; caso encontre algum erro ao rodar um código de exemplo neste livro, tente voltar atrás e rodar os códigos anteriores.\n\n\n1.3.1 R como uma calculadora\nAssim como em outras linguagens de programação, podemos usar o R como uma calculadora. Experimento digitar 2 + 2 no console do RStudio e apertar enter:\n\n2 + 2\n\n[1] 4\n\n\nO R reproduzirá o resultado da soma antecedido por [1]. Aproveitando a deixa, # indica um comentário: tudo o que vem sucedido de # o R não executará.\n\n# 2 + 2\n\nNada acontece. Comentários são úteis para documentar nossos códigos, algo que veremos em seguida. Por enquanto, experimente usar o console como uma calculadora (logo veremos usos mais interessantes do R):\n\n8 + 7 # Adição (depois do #, nada é executado)\n\n[1] 15\n\n8 - 7 # Subtração (depois do #, nada é executado)\n\n[1] 1\n\n\nPara resolver expressões numéricas, usamos ().3\n\n2 / (3 + 5)\n\n[1] 0.25\n\n4 * ((2 ^ 5) / 3)\n\n[1] 42.66667\n\n\n\n\n1.3.2 Operadores\nAnteriormente, usamos operadores aritméticos, como + e * (você deve ter percebido que * é o operador de multiplicação no R, e não x). No R, existem vários outros (tente adaptar os exemplos):\n\n3^2\n\n[1] 9\n\n11 / 5\n\n[1] 2.2\n\n11 %/% 5\n\n[1] 2\n\n11 %% 5\n\n[1] 1\n\n\nCaso você não tenha entendido algum apenas pelo seu uso, a Tabela 1.1 apresenta uma descrição dos principais operadores matemáticos comuns em R.\n\n\nTabela 1.1: Operadores matemáticos no R\n\n\nOperação\nSímbolo\n\n\n\n\nAdição\n+\n\n\nSubtração\n-\n\n\nDivisão\n/\n\n\nMultiplicação\n*\n\n\nExponenciação\n^\n\n\nDivisão inteira\n%/%\n\n\nResto da divisão\n%%\n\n\n\n\nAlém dos operandos matemáticos, existem também operadores lógicos, que usamos para saber se algo é verdadeiro ou falso. Para sermos mais concretos, podemos usar == (dois =) para testar se um número é igual a outro:\n\n1 == 1\n\n[1] TRUE\n\n\nO que o código anterior faz é testar se 1 é igual a 1, retornando TRUE. Um exemplo falso:\n\n2 == 1\n\n[1] FALSE\n\n\nTestes lógicos também nos permitem fazer operações mais complexas. Por exemplo, podemos testar se um número é maior ou menor que outro:\n\n10 &gt; 5\n\n[1] TRUE\n\n3 &gt; 1\n\n[1] TRUE\n\n\nE, indo além, podemos combinar dois testes usando o operador & (que significa E, ou AND):\n\n(10 &gt; 5) & (3 &gt; 1)\n\n[1] TRUE\n\n(10 &gt; 5) & (5 &lt; 2)\n\n[1] FALSE\n\n\nNo caso acima, o resultado de cada expressão só será TRUE se ambos os testes forem verdadeiros. Se quisermos que o resultado seja TRUE se pelo menos um dos testes for verdadeiro, usamos o operador | (ou):\n\n(10 &gt; 5) | (5 &lt; 2)\n\n[1] TRUE\n\n\nE se quisermos testar se um número ou valor pertence a um determinado conjunto? Usamos o operador %in%:\n\n1 %in% c(1, 2, 3)\n\n[1] TRUE\n\n5 %in% c(1, 2, 3)\n\n[1] FALSE\n\n1:5 %in% c(1, 2, 3)\n\n[1]  TRUE  TRUE  TRUE FALSE FALSE\n\n\n\n\n\n\n\n\nTestes lógicos\n\n\n\nTestes lógicos sempre retornam TRUE ou FALSE, em maiúsculo. Em R, algumas vezes é possível usar T e F para representar esses valores, mas não é algo recomendado.\n\n\nA Tabela 1.2 apresenta os operadores lógicos mais comuns:\n\n\nTabela 1.2: Operadores lógicos comuns no R\n\n\nOperação\nSímbolo\nExemplo\n\n\n\n\nIgualdade\n==\n1 == 1\n\n\nDiferença\n!=\n1 != 1\n\n\nMaior que\n&gt;\n1 &gt; 1\n\n\nMenor que\n&lt;\n1 &lt; 1\n\n\nMaior ou igual\n&gt;=\n1 &gt;= 1\n\n\nMenor ou igual\n&lt;=\n1 &lt;= 1\n\n\nE\n&\n(1 == 1) & (2 == 2)\n\n\nOU\n|\n(1 == 1) | (2 == 2)\n\n\nNÃO\n!\n!(1 == 1)\n\n\nPertence\n%in%\n1 %in% c(1, 2, 3)\n\n\n\n\nTodos esses operadores são úteis – mas certamente não é por causa deles que o R é tão utilizado."
  },
  {
    "objectID": "01-cap.html#funções",
    "href": "01-cap.html#funções",
    "title": "1  Básico",
    "section": "1.4 Funções",
    "text": "1.4 Funções\nParte da potencialidade do R advém do fato dele conter uma série de funções nativas para realizar as mais diversas tarefas de pesquisa. É por isso que ele é considerado um ambiente, e não apenas uma linguagem de programação.4 Dito de forma simples, funções são códigos que executam uma tarefa específica. A função sqrt(), por exemplo, calcula a raiz quadrada de um número:\n\nsqrt(4) # Raiz quadrada do número 4\n\n[1] 2\n\n\nEm R, funções têm uma anatomia específica: o nome da função, seguido de parênteses, dentro dos quais estão os argumentos da função – o input que a função recebe e processa. No caso da função sqrt(), o argumento é o número cuja raiz quadrada queremos calcular.5 Vale memorizar: uma função nada mais é do que uma espécie de ferramenta que recebe uma determinada informação e a transforma em outra.6\n\n1.4.1 Usando funções\nNo R, as informações que passamos para determinada função vão dentro de parêntesis. A função sum, por exemplo, recebe e soma dois ou mais números, todos separados por vírgula. Se esquecermos de fazer essa separação, obtemos um erro.\n\nsum(2 2) # retorna erro \n\nError: &lt;text&gt;:1:7: unexpected numeric constant\n1: sum(2 2\n          ^\n\n\n\n\n\n\n\n\nErros\n\n\n\nQuando executamos um código que o R não consegue interpretar, ele retorna um erro no console.\n\n\nPara corrigir o código anterior, basta separar os números por vírgula:\n\nsum(2, 2) # retorna 4\n\n[1] 4"
  },
  {
    "objectID": "01-cap.html#objetos",
    "href": "01-cap.html#objetos",
    "title": "1  Básico",
    "section": "1.5 Objetos",
    "text": "1.5 Objetos\nPara além de executar código, o R nos permite salvar informações na memória do programa. Essas informações são armazenadas em objetos, que podem ser usados posteriormente. De forma bem simples, objetos são como locais na memória do programa que armazenam valores quaiser. No R esses valores podem ser: números, textos, um vetor de números (isto é, uma sequência de números), um banco de dados e, até mesmo, uma função.\nPodemos armazenar objetos no R com o operador &lt;- (menor que, seguido de hífen). Basicamente, ele diz ao R para armazenar um valor em um objeto para podermos acessá-lo posteriormente. Exemplo: vamos salvar o número 2 em um objeto chamado x.\n\nx &lt;- 2\n\nTocamos em algo extremamente importante: agora, podemos digitar x no lugar de 2 para realizar outras operações.\n\nx\n\n[1] 2\n\nx + 1\n\n[1] 3\n\nx / 2\n\n[1] 1\n\n\nE como fazemos para salvar o resultado de uma nova operação, como x + 10, por exemplo? Simples: basta criar um novo objeto.\n\ny &lt;- x + 10\ny\n\n[1] 12\n\n\nAlgo que ainda não vimos, também é possível armazenar texto em um objeto – note que, para o R reconhecer algo como texto, precisamos colocá-lo entre aspas:\n\ntexto &lt;- \"um texto\"\ntexto\n\n[1] \"um texto\"\n\n\nNo R elementos entre aspas, simples ou duplas, são considerados textos.\n\n\n\n\n\n\nCriação de objetos\n\n\n\nNo R também é possível criar objetos usando o símbolo de igualdade, =, como em x = 1. No entanto, não usaremos essa sintaxe neste livro e, por razões de consistência de código, também não recomendamos seu uso.\n\n\n\n1.5.1 Tipos de objeto\nNúmeros são diferentes de textos e, em R, essa diferença também existe: ela é dada pelas classes de objetos. Classes são como categorias de objetos, isto é, grupos de objetos que compartilham de uma mesma estrutura e, portanto, podem ser manipulados de forma semelhante. O número 1 é um objeto da classe integer (inteiro), assim como os números 2 e 10, que também são inteiros. O número 1,5, ao contrário, é um objeto da classe numeric, dado que não é um número inteiro (por conta da casa decimal). Para saber a classe de um objeto, usamos a função class():\n\nclass(1)\n\n[1] \"numeric\"\n\nclass(1.5)\n\n[1] \"numeric\"\n\n\nDiferentes funções podem exigir diferentes classes de objetos. Por exemplo, a função sum() exige que os objetos que ela soma sejam da classe numeric ou integer. Se tentarmos somar um objeto da classe character, o R retornará um erro:\n\nsum(\"1\", \"2\")\n\nError in sum(\"1\", \"2\"): 'type' inválido (character) do argumento\n\n\nPara resumir, classes determinam o tipo de informação que diferentes objetos armazenam e o que podemos fazer com elas. Entendido isso, podemos começar a aprender sobre as classes mais comuns no R: integer, numeric, character, factor, matrix, data.frame e list.\n\n1.5.1.1 Números, textos e categorias\n\n1.5.1.1.1 integer\ninteger é uma classe de objeto específica para números inteiros.\n\nexemplo_inteiro &lt;- 20\nclass(exemplo_inteiro)\n\n[1] \"numeric\"\n\n\nAté agora, só criamos objetos com um elemento, mas, quando estamos analisando muitos dados, podemos combiná-los em vetores, ou seja, objetos com mais de um elementos (mais de um caso). Uma forma elementar de criar um vetor é por meio da função combine, c:\n\n# Cria um vetor de números\nx &lt;- c(18, 20, 19, 25, 21)\nx\n\n[1] 18 20 19 25 21\n\n\n\n\n1.5.1.1.2 numeric\nA classe numeric também é composta por números, mas, diferentemente de integer, armazenam números decimais.\n\nexemplo_decimal &lt;- 20.5\nclass(exemplo_decimal)\n\n[1] \"numeric\"\n\n\nPor padrão, o R já atribui classe aos objetos quando os criamos, deduzindo o tipo adequado a partir do nosso código. No caso de integer ou numeric, a escolha está atrelada à quantidade de memória reservada no programa para armazenar as informações: quando temos números decimais, a classe sempre será numeric pois é necessário mais espaço para guardar informações das casas decimais, e todos os números do vetor passaram a ter um decilma, mesmo aqueles que foram declarados (inseridos) sem decimal:7\n\ny &lt;- c(50, 65.5, 55.8, 70, 85.6)\nclass(y)\n\n[1] \"numeric\"\n\n\n\n\n\n\n\n\nDecimal\n\n\n\nO R adota o sistema de casas decimais americano, com ponto. Por isso, ao declarar um número decimal no R, usamos o ponto, e não a vírgula.\n\n\n\n\n1.5.1.1.3 character\nComo já dito, character é a classe usada no R para armazenar informações textuais, que devem estar contidas entre aspas.\n\nw &lt;- c(\"superior\", \"médio\", \"fundamental\", \"superior\")\nclass(w)\n\n[1] \"character\"\n\n\n\n\n1.5.1.1.4 factor\nSimilar a character, factor é uma classe que guarda simulneamente uma informação textual com uma númerica associada – o que costumamos chamar de variável categórica nas Ciências Sociais e similares.\n\nz &lt;- factor(c(\"Feminino\", \"Masculino\", \"Feminino\", \"Masculino\", \"Feminino\"))\nclass(z)\n\n[1] \"factor\"\n\nz\n\n[1] Feminino  Masculino Feminino  Masculino Feminino \nLevels: Feminino Masculino\n\n\nComo podemos ver pelo retorno do R anterior, um vetor da classe factor nos mostra seus levels, ou seja, as categorias da nossa variavel: Feminino e Masculino. Mas, como podemos ver, o R não nos mostra os valores numéricos associados a cada categoria. Para isso, podemos usar a função as.numeric(), que converte objetos de outras classes para numeric (quando essa conversão for possível):\n\nas.numeric(z)\n\n[1] 1 2 1 2 1\n\n\n\n\n\n1.5.1.2 Matrizes e bancos de dados\n\n1.5.1.2.1 matrix\nA classe matrix é um tipo de objeto bidimensional utilizada principalmente para representar linhas e colunas. De forma geral, matrizes são espécies de tabelas ou planilhas como as que vemos no Excel, mas com uma diferença essencial: todos os elementos devem ser do mesmo tipo, isto é, todos numeric, integer, character, e assim por diante.\nPodemos criar uma matriz com a função matrix, declarando argumentos que indicam quantas linhas e quantas colunas essa matriz deverá ter. Um exemplo de matriz:\n\nmatriz &lt;- matrix(c(1, 3, 4, 5, 6, 7), nrow = 2,  ncol = 3) \nmatriz\n\n     [,1] [,2] [,3]\n[1,]    1    4    6\n[2,]    3    5    7\n\nclass(matriz)\n\n[1] \"matrix\" \"array\" \n\n\nNote que, no exemplo anterior, criamos uma matriz com 2 linhas e 3 coluna epassamos a ela um vetor com os elementos c(1, 3, 4, 5, 6, 7). Em outras palavras, os argumentos nrow (i.e., número de linhas) e ncol (i.e., número de colunas) determinam como o conteúdo da matriz será dividido entre linhas e colunas.\n\n\n1.5.1.2.2 data.frame\nJá que matrizes salvam apenas informações da mesma classe, naturalmente precisamos de outra classe se quisermos analisar variáveis, ou colunas, de classes diferentes. data.frame é exatamente a classe que nos permite fazer isso. Especificamente, data.frame também é bidimensional e tabular, como a matrix, mas é mais versátil.\nVamos criar aqui um banco de dados a partir de vetores com a função data.frame:\n\nx &lt;- c(\"Superior\", \"Médio\", \"Médio\")\ny &lt;- c(23, 45, 63)\nz &lt;- c(\"Feminino\", \"Masculino\", \"Masculino\")\nbanco &lt;- data.frame(escolaridade = x, idade = y, sexo = z)\nclass(banco)\n\n[1] \"data.frame\"\n\n\nCom o banco criado, podemos ver suas informações com a função print, que serve para mostrar no console o conteúdo de um objeto:\n\nprint(banco)\n\n  escolaridade idade      sexo\n1     Superior    23  Feminino\n2        Médio    45 Masculino\n3        Médio    63 Masculino\n\n\nPara o caso de bancos maiores, podemos usar a função View(), que abrirá uma nova janela no RStudio com o conteúdo do banco de dados.8\n\n\n\n\n\n\ndata.frames\n\n\n\nPara criar matrizes e bancos de dados a partir de vetores, todos eles precisam ter o mesmo número de elementos, caso contrário o R retornará um erro.\n\n\n\n\n\n1.5.1.3 Listas\nFinalmente, os objetos da classe list são um dos mais complexos que veremos – eles são multimensionais. Em particular, com eles armazenamos objetos de diferentes classes, mas não só vetores do mesmo tamanho como em um data.frame. Ou seja, em um objeto tipo list podemos armazenar vetores de diversos tamanhos, matrix e data.frame, ou mesmo outras listas. Vejamos um exemplo:\n\n# Cria uma lista chamada 'guarda_trecos'\nguarda_trecos &lt;- list(x, y, z, banco)\nclass(guarda_trecos)\n\n[1] \"list\"\n\nprint(guarda_trecos)\n\n[[1]]\n[1] \"Superior\" \"Médio\"    \"Médio\"   \n\n[[2]]\n[1] 23 45 63\n\n[[3]]\n[1] \"Feminino\"  \"Masculino\" \"Masculino\"\n\n[[4]]\n  escolaridade idade      sexo\n1     Superior    23  Feminino\n2        Médio    45 Masculino\n3        Médio    63 Masculino\n\n\nComo podemos ver cada item (objeto) foi armazendos na lista guarda_trecos, na ordem em que foram colocado dentro da função list().\n\n\n\n1.5.2 Manipulando objetos\nCriamos alguns objetos de distintas classes e exibimos eles por completo no console. Mas e se quisermos apresentar no console apenas um elemento de um objeto? Para isso precisamos nos mover pelos objetos usandos índices. Ao exibir elementos de um objeto no console, o R há nos dá uma dica de como fazer isso: o [1] sempre indica o conteúdo do primeiro elemento. Se quisermos acessá-lo, basta executar:\n\nx &lt;- c(1, 2, 3, 4, 5)\nx[1]\n\n[1] 1\n\n\nDe forma geral, em objetos unidimensional basta usar objeto[índice], com a posição desejada em colchetes, para acessar determinado elemento, como o quarto e o quinto, digamos:\n\nx[4]\n\n[1] 4\n\nx[5]\n\n[1] 5\n\nx[c(4, 5)] # Podemos outro vetor para acessar mais de um elemento\n\n[1] 4 5\n\n\nEm objetos multidimensionais como um data.frame o modo de acesso de um elemento é um pouco diferente. Por exemplo, no nosso objeto banco criado anteriormente precisamos indexar linhas e colunas, objeto[linhas, colunas]. Para acessar a célula da primeira linha e da terceira coluna, usamos:\n\nbanco[1, 3]\n\n[1] \"Feminino\"\n\n\nNo exemplo acima, estamo selecionando o elemento (caso) numero 1 que estar na coluna (variável) 3 que é o sexo. É importante fixar: em objeto bidimensional como um data.frame, antes da virgula nos colchetes temos as linhas e, só depois da virgula, as colunas. Outro caso:\n\nbanco[, 3]\n\n[1] \"Feminino\"  \"Masculino\" \"Masculino\"\n\n\nQuando deixamos o do lado esquerdo do colchete vazio, estamos dizendo ao R que retorne um vetor com todas as linhas (casos) da coluna (variável) identificada no lado direito da virgula. Nesse exemplo, temos o sexo de todas as pessoas no banco. Já aqui, pegamos todas as informações da pessoa na segunda linha do banco:\n\nbanco[2, ]\n\n  escolaridade idade      sexo\n2        Médio    45 Masculino\n\n\nSe quizermos selecionar mais um caso ou variável podemos usar um vetor, também podemos usar vetores usando a função c ou dois pontos, para criar uma sequência de inteiros entre dois números:\n\nbanco[3:5, c(1, 3)]\n\n     escolaridade      sexo\n3           Médio Masculino\nNA           &lt;NA&gt;      &lt;NA&gt;\nNA.1         &lt;NA&gt;      &lt;NA&gt;\n\n\nNo exemplo acima estamos selecionando os casos de 3 a 5 (o código 3:5 cria uma sequência de inteiros de 3 a 5) da base de dados e as variáveis 1 e 3.\nIndexadores também funcionam em listas, mas com uma diferença: como listas são objetos multimensionais, precisamos usar dois conjuntos de colchetes para acessar elementos. Por exemplo, para acessar o primeiro elemento da lista guarda_trecos, usamos:\n\nguarda_trecos[[1]]\n\n[1] \"Superior\" \"Médio\"    \"Médio\"   \n\n\nO primeiro conjunto de colchetes indica que queremos acessar um elemento da lista, enquanto o segundo indica qual elemento queremos acessar. Se quisermos acessar um valor dentro do primeiro elemento da lista, basta adicionar um colchete simples logo depois dos colchetes duplos indicando o índice do elemento desejado:\n\nguarda_trecos[[1]][2]\n\n[1] \"Médio\"\n\n\nCom isso, selecionamos o segundo elemento do vetor amarzenado na sublista 1. E se o conteúdo da sublista for um data.frame, como aceso um valor dentro dele? Assim:\n\nguarda_trecos[[4]][1, 3]\n\n[1] \"Feminino\"\n\n\nPara data.frames, há um jeito mais simples de se acessar o conteúdo inteiro de uma variável: por meio do cifrão ($). Por exemplo, para acessar a variável sexo do banco, basta executar:\n\nbanco$sexo\n\n[1] \"Feminino\"  \"Masculino\" \"Masculino\"\n\n\nComo dá para notar, é preciso saber o nome da coluna que queremos acessar para usar esse meio de indexação. Um jeito simples de fazer isso é usando a função names(), que retorna os nomes das colunas de um data.frame:\n\nnames(banco)\n\n[1] \"escolaridade\" \"idade\"        \"sexo\"        \n\n\nAssim sabemos que a primeira variável se chama “escolaridade”, a segunda “idade”, e assim por diante.\nCombinando o $ com os indexadores que vimos há pouco, é fácil obter, por exemplo, o terceiro elemento da variável sexo no objeto banco:\n\nbanco$sexo[3]\n\n[1] \"Masculino\"\n\n\nManipular objetos no R pode parecer bastante complicado, mas, com o devido tempo e prática, tudo se torna mais simples. Ao final deste capítulo, sugerimos alguns exercícios que ajudarão no processo."
  },
  {
    "objectID": "01-cap.html#pipes",
    "href": "01-cap.html#pipes",
    "title": "1  Básico",
    "section": "1.6 Pipes",
    "text": "1.6 Pipes\nCriar objetos e manipulá-los pode ser algo que rapidamente foge de controle. Por exemplo, imagine que queremos calcular a média da variável idade do objeto banco e, depois, calcular a sua raiz quadrada com a função sqrt. Para isso, executaríamos:\n\nmedia_idade &lt;- mean(banco$idade)\nsqrt(media_idade)\n\n[1] 6.608076\n\n\nPara evitar ter que criar um objeto intermediário para salvar a média, podemos usar pipes, que são representados por |&gt;.9 Eles servem para encadear resultados de funções, isto é, executar uma função e, em seguida, executar outra função com o resultado da primeira. No exemplo anterior, poderíamos usar o pipe para calcular a média e, em seguida, calcular a raiz quadrada do resultado com o seguinte código:\n\nbanco$idade |&gt; \n    mean() |&gt; \n    sqrt()\n\n[1] 6.608076\n\n\nO código acima é muito mais legível. Podemos, inclusive, ler o código como se fosse uma frase: “pegue a variável idade do objeto banco e jogue ela dentro da função que calcula a média; depois, pegue esse resultado e jogue ele dentro da função que calcula a raiz quadrada”.10 Com pipes, podemos criar complexas sequências:\n\nbanco$idade |&gt; \n    mean() |&gt; \n    sqrt() |&gt; \n    round() |&gt;\n    print()\n\n[1] 7\n\n\nTalvez esse tópico pareça um pouco confuso agora, mas, quando começarmos a cobrir a manipulação de bases de dados, no Capítulo 3, pipes serão uma ferramenta essencial."
  },
  {
    "objectID": "01-cap.html#pacotes",
    "href": "01-cap.html#pacotes",
    "title": "1  Básico",
    "section": "1.7 Pacotes",
    "text": "1.7 Pacotes\nO R já vem com uma série de funcionalidades embutidas nele – como as funções sqrt e sum, que já vimos. Mas, como já dito, uma das grandes vantagens do R é a sua comunidade, que desenvolve novas funcionalidades para a linguagem e, norlamente, as disponibilizam por meio de pacotes, ou bibliotecas. Estes são como extensões do R, que adicionam novas funcionalidades ao programa – pense em um pacote como um livro de receitas ou um manual de instruções, que ensina o R como fazer coisas novas.\nEm R, a principal fonte de pacotes o CRAN (The Comprehensive R Archive Network), que é uma comunidade de desenvolvedores que mantém o código base do R e os seus pacotes oficiais, aqueles que passaram por uma série de testes e que seguem uma série de protocolos que garantem o seu funcionamento estável e harmônico com outras ferramentas no R.11\n\n1.7.1 Instalando Pacotes\nPara instalar pacotes que está no CRAN, basta sabermos o seu nome e usar a função install.packages:\n\ninstall.packages(\"electionsBR\")\n\nNo exemplo acima, instalamos o pacote electionsBR e, com ele, damos ao R a capacidade de se conectar ao repositório de dados eleitorais do TSE (Tribunal Superior Eleitoral) para obter informações eleitorais.\n\n\n1.7.2 Instalação de pacotes do GitHub\nApesar da imensidade de pacotes no CRAN, encontramos outro grande volume de pacotes em outros repositórios não-oficiais, a maioria em densevolvimento. A principal fonte destes pacotes, depois do CRAN, é o GitHub.12\nPara instalar pacotes do GitHub, precisamos instalar outro pacote antes, o remotes:\n\ninstall.packages(\"remotes\")\n\nEste pacote contém uma função, install_github, que permite ao R se conectar ao GitHub, obter de lá o código fonte de um pacote e realizar a sua instalação. Para usar esta função, precisamos antes carregar o pacote remotes, isto é, tornar ela acessível ao R, o que fazemos por meio da função library:\n\nlibrary(remotes) # Carrega o pacote\ninstall_github(\"silvadenisson/electionsBR\") # Instala o pacote\n\nInstalar e carregar pacotes são duas tarefas similares, mas suas diferenças são importantes: no primeiro caso, estamos incorporando novas funções no nosso R, assim como instalar o Office no computador nos permite usar o processador de texto Word; no segundo caso, estamos carregando o pacote instalado, assim como quando abrimos o Word pelo seu atalho no computador.\n\n\n\n\n\n\nPacotes\n\n\n\nPacotes só precisam ser instalados uma vez, mas precisam ser carregados (abertos) no R em cada seção em que precisarmos de suas funções.\n\n\nNo exemplo anterior, usamos a função library para carregar o pacote remotes; com este, usamos a função install_github para instalarmos a versão de desenvolvimento do pacote electionsBR."
  },
  {
    "objectID": "01-cap.html#scripts",
    "href": "01-cap.html#scripts",
    "title": "1  Básico",
    "section": "1.8 Scripts",
    "text": "1.8 Scripts\nTrabalhar no console, digitando e executando código diretamente de lá, é algo rápido para tarefas simples, mas inviável para análises mais complicadas. Pior que isso, sem poder salvar nossos códigos em algum lugar, não temos como reproduzir uma análise, ou compartilhar nossos passos com outras pessoas. Justamente para evitar isso, usamos scripts, documentos de texto que servem para documentar e armazenar códigos.\nNo Rstudio, podemos criar um script clicando, no menu superior esquerdo, em File &gt; New File &gt; R Script, ou, também no canto superior esquerdo, no símbolo de uma folha em branco acompanhada de um símbolo de mais em verde. Feito isso, uma nova janela será aberta, na qual podemos escrever nosso códigos. Para salvá-los, basta clicar em File &gt; Save e escolher um nome para o arquivo, ou clicar no ícone de disquete ligeiramente acima, ou, ainda, teclar ctrl/command + s. O script salvo aparecerá na sub-janela de gestão de arquivos do RStudio, indicada no item 4 da Figura 1.2.\nPara acompanhar o restante deste capítulo e os próximos, acostume-se a criar scripts e use comentários para descrever o que cada linha faz – isso será muito útil para documentar o que estamos aprendendo. A título de exemplo, um script de acompanhamento deste capítulo poderia ter o seguinte início:\n\n# Capítulo 1: Introdução ao R\n\n# Este é um comentário. Ele não é executado pelo R, mas serve para documentar o que estamos fazendo.\n# Para executar um código, basta clicar na linha e teclar ctrl/command + enter.\n# Para executar várias linhas, basta selecioná-las e teclar ctrl/command + enter.\n\n# Criando objetos\nx &lt;- 2\ny &lt;- x + 10\n\n# ...\n\nDocumentar o script é uma das tarefas mais importantes do densolvimento do seu código. Primeiro porque podes voltar em um outro momento e saber o que exatamente estas tentendo fazer com seu script. Isso pode parecer tolice, mas tenha certeza que não é, principalmente quando chegamos no nível de trabalhar com muitos scripts.\nEsse motivo acima já sería suficiente, no entanto, há outro mais importante para o desenvolvimento de pesquisas científicas que é a replicabilidade. Pois, quando documenta teu código aumenta a capacidade replicativa dele. E replicabilidade é a plavra que chave na ciência, porque não fazemos ciência para ficar na gaveta, ou melhor, em pasta perdida dentro do computador, e sim para que outra pessoa saibam o que fizemos e possam replicar, vamos abordar mais sobre replicação no capítulo 8."
  },
  {
    "objectID": "01-cap.html#recomendações",
    "href": "01-cap.html#recomendações",
    "title": "1  Básico",
    "section": "1.9 Recomendações",
    "text": "1.9 Recomendações\nPodemos criar objetos e realizar operações no R de forma simples, como vimos. No entanto, algumas coisas devem ser evitadas quando escrevemos nosso código, seja para evitar erros ou para facilitar a leitura dele por outras pessoas.\nA recomendação mais básica neste sentido é: evite criar objetos com nomes que comecem com números, caracteres especiais ou nomes de funções. Algumas destas coisas produzirão erros imediatos; outras, podem complicar códigos inteiros. Alguns exemplos.\n\n# Exemplos de nomes de objetos que produzem erros\n2x &lt;- 1\n_x &lt;- 1\n&x &lt;- 1\n\nError: &lt;text&gt;:2:2: unexpected symbol\n1: # Exemplos de nomes de objetos que produzem erros\n2: 2x\n    ^\n\n\n\n# Exemplos de nomes de objetos que não produzem erros imediatos\nsum &lt;- 1\nsqrt &lt;- 1\n\nTambém note que o R é case sensitive, A (maiúsculo) não é a mesma coisa que a (minúsculo).\n\nA &lt;- 1\nprint(a)\n\nError in eval(expr, envir, enclos): objeto 'a' não encontrado\n\n\nSempre que criar um objeto armazenando texto, não esqueça das aspas (outra forma de cometer erros no R bastante comum).\n\nx &lt;- Texto\n\nError in eval(expr, envir, enclos): objeto 'Texto' não encontrado\n\n\nPor fim, quando abrir parênteses, não esqueça de fechá-los (caso contrário, aparecerá um + no console, indicando que o R espera mais conteúdo). Caso esteja executando um código e não saiba porque apareceu um + no cosole, opte por cancelar a operação e volte ao código para ver o que há de errado.13\n\n1.9.1 Estilo\nNão é algo obrigatóro, mas algumas noções de estilo nos ajudam a compreender e partilhar códigos, tanto nossos quanto os de outras pessoas. Resumidamente, as principais considerações aqui são:\n\nUse espaços entre objetos, operadores e chamadas a funções;\nUse quebra de linhas para separar blocos de códigos;\nSempre que possível, crie objetos apenas com letras minúsculas;\nSe precisar separar o nome de um objeto, use _ (underscore);\nPrefira nomes curtos para objetos;\nPrefira o atribuidor &lt;- a = (eles fazem a mesma coisa).\n\n\ny&lt;-1 # Ruim\ny &lt;- 1 # OK\n\ny+y+y+y # Ruim\n\n[1] 4\n\ny + y + y + y # OK\n\n[1] 4\n\nprint (y) # Ruim\n\n[1] 1\n\nprint(y) # OK\n\n[1] 1\n\ny = 1 # Ruim\ny &lt;- 1 # OK\n\nOBJETO &lt;- 1 # Ruim\nobjeto &lt;- 1 # OK\n\nmeu.objeto &lt;- 1 # Ruim\nmeu_objeto &lt;- 1 # OK\n\nobjeto_com_nome_excessivamente_grande &lt;- 1 # Ruim\nobjeto &lt;- 1 # OK\n\nPara uma lista mais completa de recomendações, pessoas desenvolvedoras por trás do RStudio criaram um website com um guia completo de estilo em R – feito especificamente para pessoas que usam seus pacotes. O guia pode ser visto em: https://style.tidyverse.org/."
  },
  {
    "objectID": "01-cap.html#obtendo-ajuda",
    "href": "01-cap.html#obtendo-ajuda",
    "title": "1  Básico",
    "section": "1.10 Obtendo ajuda",
    "text": "1.10 Obtendo ajuda\nPara a nossa sorte, a comunidade em torno do R cresceu muito nos últimos anos e, com ela, a quantidade de material disponível na internet. Sempre é bom dizer: dúvidas e erros podem e devem ser buscados no Google ou, mais recentemente, no ChatGPT14 ou Google Bard15, ótimas fontes para resolução de dúvidas. De toda forma, a maneira mais simples de se obter ajuda no R sobre alguma função ou operador é consultando a sua documentação – em geral, muito boa. Para isso, podemos usar a função help:\n\nhelp(sum)\n\nEsse recurso só é útil, entretanto, quando sabemos o nome exato da função que queremos consultar (e quando a temos instalado e carregado o pacote que a função pertence). Outra forma de consultar documentação é usando um ponto de interrogação antes do nome de uma função:\n\n?sum\n\nQuando não sabemos o nome da função que queremos usar, ou até mesmo para saber se existe no R uma função específica para uma determinada tarefa que queremos executar, precisamos recorrer a outras fontes. Antes mesmo de ir para o Google, contudo, há no próprio R um pacote que faz uma busca por palavras-chave nos repositórios oficiais do R, o sos. Para usá-lo, precisamos instalá-lo e, depois, carregá-lo:\n\ninstall.packages(\"sos\")\n\n\nlibrary(sos)\n\nE, então, usar a função findFn, que tem como argumento principal um texto (string) que será pesquisado. Exemplo:\n\nfindFn('regresion')\n\nQuando executada, a função irá abrir seu navegador em uma pagina com os resultado, como a Figura 1.4 ilustra.\n\n\n\nFigura 1.4: Pacote sos\n\n\nComo é possível ver, usando o pacote sos obtemos uma lista com nome de pacotes, o nome da função específica que tem algum relação com o termo pesquisado e uma breve descrição e página que podemos acessar para ver mais detalhes.\n\n1.10.1 Como pedir ajuda ao ChatGPT\nPela nossa experiência recente oferecendo treinamento em R, muitas pessoas ou não usam, ou usam inadequadamente, soluções como o ChatGPT para obter ajudar. Por isso, algumas dicas para obter recursos de forma mais eficiente e eficaz:16\n\nNão use o ChatGPT para gerar código do zero – esse é o pior uso possível dele; sempre escreva algum código antes de pedir ajuda – caso contrário, ele poderá usar pacotes ou funções, ou mesmo seguir uma lógica, que você não conhece;\nNão use o ChatGPT para obter ajuda sobre pacotes ou funções que você não conhece – use o help ou o ? para isso; modelos de linguagem não são tão bons para recuperar informações factuais, pelo menos não sem contexto ou conexão com fontes de informação;\nTente seguir um modelo de ajuda específico: descreva em palavras o que está tentando fazer; cole o código que estava usando; e, ao final, cole o erro ou a mensagem obtida no console. Um exemplo:\n\n\nEstou tentando criar um objeto chamado x com o valor 2 no R, mas obtive um erro ao tentar somar x+x. O que estou fazendo de errado? Segue o código que usei e o erro que obtive:\n\n\nx &lt;- \"2\"\nx + x\n\n\nError in x + x: argumento não-numérico para operador binário\n\n\n\n1.10.2 Outros recursos\nAlem das opções de ajuda dentro do próprio R, a internete está cheia de material sobre. Por exemplo, nos últimos anos aumentou largamente a quantia de tutoriais no YouTube ensinando as mais diversas tarefas em R. Mais útil, há várias fontes ricas para buscar sobre os mais diferentes tópicos, como o Stackoverflow, R-bloggers, R Brasil - Programadores (Facebook), rbloggersbr (twitter), entre outros.\nO primeiro deles, o Stackoverflow, é um fórum onde programadores de todos os níveis e linguagens publicam suas dúvidas e soluções a elas. Originalmente em inglês, conta também com uma versão em português: https://pt.stackoverflow.com. Para refinar as busca dentro do fórum é necessario, antes do termo buscado, inserir o nome da linguagem dentro de colchetes. Por exemplo: [R] data.frame.\nO R-bloggers é outro site famoso na comunidade de R por reunir postagens de vários blogs sobre R. Em certo sentido, ele é um agregador de tutoriais (em inglês). Seu endereço é https://www.r-bloggers.com/tag/rblogs/.\nEm português, finalmente, há também uma iniciativa no Twitter para agregar as postagens do blogs brasileiros cadastrados, https://twitter.com/rbloggersbr. Para quem costuma usar a rede social, basta postar sobre R usando a hashtag #rstats para rapidamente se conectar a outras pessoas interessadas pela linguagem – no fim das contas, como sugerimos ao longo deste capítulo, o R é também uma comunidade, e não apenas uma linguagem de programação."
  },
  {
    "objectID": "01-cap.html#resumo-do-capítulo",
    "href": "01-cap.html#resumo-do-capítulo",
    "title": "1  Básico",
    "section": "1.11 Resumo do capítulo",
    "text": "1.11 Resumo do capítulo\nNeste capítulo, aprendemos os conceitos básicos do R, como instalar e carregar pacotes, criar objetos, usar funções e obter ajuda. Também vimos algumas recomendações para escrever códigos mais legíveis e eficientes. Com o que vimos aqui, ainda não conseguimos fazer análises em R, mas já aprendemos a usar alguns dos ingredientes que precisaremos para isso."
  },
  {
    "objectID": "01-cap.html#indo-além",
    "href": "01-cap.html#indo-além",
    "title": "1  Básico",
    "section": "1.12 Indo além",
    "text": "1.12 Indo além\nNo início, não há alternativa: a melhor forma de aprender R é escrever código em R. Por isso, para quem deseja ir além do que vimos neste capítulo, recomendamos fortemente a realização dos exercícios deste capítulo – mesmo que você já tenha feito algum curso de R antes. Para além destes, para quem deseja complementar a leitura deste capítulo com vídeos, sugerimos a série vídeos introdutórios feitos pelo R Ladies Belo Horizonte, capítulo local do R Ladies Global17, que está disponível no YouTube.\nPor ser também uma linguagem de programação, o R conta com recursos, que não vimos neste capítulo, como estruturas de controle de fluxo e funções, que se conectam a tópicos mais gerais de programação, como programação funcional e orientada a objetos. Em um curso de introdução à linguagem, ou de introdução à programação de forma mais geral, alguns desses tópicos são abordados já no início. Nesse ponto, sugerimos a leitura do livro de Aquino (2014), que avança por alguns deles.\n\n\n\n\nAquino, Jakson Alves de. 2014. «R para cientistas sociais». EDITUS-Editora da UESC."
  },
  {
    "objectID": "01-cap.html#footnotes",
    "href": "01-cap.html#footnotes",
    "title": "1  Básico",
    "section": "",
    "text": "Código aberto é uma expressão usada normalmente para se referir a programas com um tipo de licença que permite que qualquer pessoa os usem, modifiquem e compartilhem. O R um desses programas e, portanto, é gratuito.↩︎\nPara quem usa Linux, é possível instalar o R diretamente pelo terminal, usando o comando sudo apt-get install r-base, por exemplo.↩︎\nNo R, [] e {} são reservados para outros usos, como veremos ao longo deste livro.↩︎\nEmbora ele também seja uma linguagem de programação.↩︎\nEm R, argumentos são os valores que uma função recebe para executar uma tarefa e, como veremos em seguida, há funções que recebem vários argumentos, alguns deles nomeados.↩︎\nHá funções que não recebem inputs, assim como outros que não retornam outputs, mas esses não são os usos mais comuns de funções.↩︎\nNa verdade, em R, vetores de inteiros são armazenados como numeric, o que você pode ver por conta própria rodando class(c(1, 2, 3)).↩︎\nNote que, para usar a função View() adequadamente, precisamos que o RStudio esteja instalado no computador.↩︎\nO pipe |&gt;, chamado de pipe nativo, foi introduzido na versão 4.1.0 do R. Anteriormente, o pacote magrittr, parte do tidyverse, era a única fonte de pipe, com o operador %&gt;%. Para saber mais sobre as diferenças, ver um resumo do blog do tidyverse em https://www.tidyverse.org/blog/2023/04/base-vs-magrittr-pipe/.↩︎\nNote que, para usar pipes, precisamos usar a função mean() sem argumentos, isto é, sem o nome da variável que queremos calcular a média. Isso porque, com pipes, o resultado da função anterior é passado para a próxima função, e não precisamos mais especificar o objeto que queremos usar.↩︎\nEnquanto escrevemos este livro, o CRAN se aproxima de 20 mil pacotes oficiais mantidos em seu website. Informação disponível em: https://cran.r-project.org/web/packages/.↩︎\nGitHub é uma plataforma de armazenamento e versionamento de software criado em cima do Git, um software de código aberto de controle de versões. Atualmente, o GitHub é um dos maiores repositórios de código aberto no mundo. Para acessá-lo, visite https://github.com.↩︎\nEstas e outras recomendações comuns para evitar erros podem ser vistas em: http://www.alex-singleton.com/R-Tutorial-Materials/common-error-msg.pdf (em inglês).↩︎\nPara quem eventualmente o desconheça, o ChatGPT é uma interface para o modelo generativo de texto (large language model) GPT-4, desenvolvido pela Openai. Para saber mais, acesse &lt;chat.openai.com/&gt;.↩︎\nBard é o large language model do Google, que pode ser acessado em https://bard.google.com/.↩︎\nUm recurso importante para qualquer usuário do ChatGPT é o guia de prompt engineering da OpenAI que fornece uma série de dicas práticas sobre como fazer perguntas ao modelo.↩︎\nO R Ladies é uma iniciativa voltada a promover a diversidade de gênero na comunidade R. Para saber mais, acesse https://rladies.org/.↩︎"
  },
  {
    "objectID": "02-cap.html#importando-dados-no-r",
    "href": "02-cap.html#importando-dados-no-r",
    "title": "2  Importação",
    "section": "2.1 Importando dados no R",
    "text": "2.1 Importando dados no R\nSó há um segredo para se aprender quando o assunto é carregamento de dados no R: cada tipo de arquivo geralmente requer uma solução específica de importação (mas, neste capítulo, veremos uma bastante geral). Além disso, também precisamos considerar dois maiores problemas. O primeiro deles é o limite de memória do computador, já que, no R, podemos carregar dados até o limite da memória RAM disponível.1 Já o segundo diz respeito a lidar com erros de acentuação e de reconhecimento de caracteres em cada base que formos trabalhar, o que pode resultar em bases carregadas de forma inadequada – ou, até mesmo, erro no carregamento. O R oferece soluções simples para contornar estes problemas, que veremos na parte final do capítulo.\nAntes de seguirmos, precisaremos instalar alguns pacotes que nos ajudarão a carregar dados2. Alguns destes pacotes são:\n\nreadxl, para carregar planilhas do Excel;\nreadODS, para carregar planilhas Open Document;\nhaven, para importar dados do SPSS e Stata; e\nrio, para importar diversos tipos de dados.\n\nPara instalar estes pacotes, use install.packages(\"nome_do_pacote\"):\n\ninstall.packages(\"readODS\")\ninstall.packages(\"readxl\")\ninstall.packages(\"haven\")\ninstall.packages(\"rio\")"
  },
  {
    "objectID": "02-cap.html#tidyverse",
    "href": "02-cap.html#tidyverse",
    "title": "2  Importação",
    "section": "2.2 tidyverse",
    "text": "2.2 tidyverse\nReservamos um espaço especial para um pacote que é o centro deste livro: o tidyverse. Este é, na verdade, uma espécie de meta-pacote que abriga um conjunto de outros pacotes menores, específicos para diferentes tarefas. Em particular, o desenho do tidyverse segue princípios gerais, isto é, suas ferramentas são feitas com uma preocupação de consistência e de integração.\nTeremos a chance de ver várias das funções do tidyverse durante o nosso percurso, mas, no que diz respeito a carregamento de dados, ele oferece duas funções que nos ajudarão bastante: read_csv() e read_delim(), ambas pertencentes ao pacote readr. É por esta razão que também usaremos e instalaremos o tidyverse antes de prosseguir (executar a linha a seguir pode levar vários minutos dado que, por baixo dos panos, vários pacotes serão instalados):\n\ninstall.packages(\"tidyverse\")"
  },
  {
    "objectID": "02-cap.html#a-mecânica-da-importação-de-arquivos",
    "href": "02-cap.html#a-mecânica-da-importação-de-arquivos",
    "title": "2  Importação",
    "section": "2.3 A mecânica da importação de arquivos",
    "text": "2.3 A mecânica da importação de arquivos\nTemos várias formas de salvar informações em um computador. Podemos, por exemplo, escrever um texto no Word ou Libre Office e salvá-lo em um arquivo chamado Meu texto.doc, assim como podemos criar uma planilha no Excel e salvá-la no arquivo Minha planilha.xls. O importante aqui é que da mesma forma que cada um destes programas serve para trabalhar com um tipo específico de arquivo, no R também precisaremos de ferramentas específicas para abrir diferentes tipos de arquivo. Às vezes, faremos isto usando funções diferentes. Em outros casos, apenas precisaremos dizer para o R como ele deve proceder – qual encoding ele deve usar, onde ficarão os nomes das variáveis, qual é o tipo de delimitar de texto que deverá ser usado, entre outros.\nA primeira coisa que precisamos saber, portanto, é qual solução usar para cada tipo de arquivo. Há formas simples de identificar isso, mas elas pressupõe saber a extensão do arquivo que queremos abrir (as letras depois do ponto ao final do nome do arquivo, e.g., .doc, .xlsx, etc.), que indicam qual é o seu formato. No Windows, podemos descobrir a extensão de um arquivo simplesmente clicando com o botão direito do mouse em cima dele e, depois, na opção “Propriedades” no menu que será aberto; feito isto, a extensão do arquivo será exibida logo acima (no campo de texto destacado em azul).\nPara orientação geral, a Tabela 2.1 exibe um resumo dos principais tipos de arquivos de dados, geralmente usados em análises, que aprenderemos a abrir neste capítulo com suas respectivas extensões – e funções e pacotes que usaremos para carregá-los no R.\n\n\nTabela 2.1: Tipos de arquivos, suas extensões e funções usadas para carregá-los no R\n\n\n\n\n\n\n\n\nArquivo\nExtensão\nPacote\nFunção\n\n\n\n\nTexto delimitado\n.txt\nreadr\nread_delim\n\n\nTexto delimitado\n.csv\nreadr\nread_delim, read_csv\n\n\nPlanilha do Excel\nxls, xlsx, .ods\nreadxl, readODS\nread_excel, read.ods\n\n\nBanco de dados do SPSS\n.sav, .por\nhaven\nread_sav, read_por\n\n\nBanco de dados do Stata\n.dta\nhaven\nread_dta\n\n\nBanco de dados do SAS\n.sas7bdat\nhaven\nread_sas\n\n\nR Data\n.Rda\n-\nload\n\n\nApache Parquet\n.parquet\nduckdb e DBI\ndbConnect e tbl\n\n\n\n\nApesar de parecer muita coisa, a mecânica geral de carregar dados é mais ou menos a mesma para qualquer tipo de arquivo: se aprendermos a usar uma solução, provavelmente saberemos usar as demais. A ideia básica, detalhada em seguida, é:\nobjeto &lt;- nome_da_funcao(\"nome_do_arquivo.extensao\", outros_argumentos...)"
  },
  {
    "objectID": "02-cap.html#importando-arquivos",
    "href": "02-cap.html#importando-arquivos",
    "title": "2  Importação",
    "section": "2.4 Importando arquivos",
    "text": "2.4 Importando arquivos\n\n2.4.1 Arquivos de texto delimitado\nComeçaremos carregando um dos tipos de arquivos mais comuns no R: o .csv, de comma-separated values, ou valores separados por vírgulas. Além de simples, este formato é flexível (pode ser salvo também em arquivo com extensão .tab, .txt, etc.) e intuitivo: cada observação no banco (linha) é separada por quebra de parágrafo (nova linha) e cada variávei (coluna) é separada por um caractere fixo (como ponto e vígula ou vírgula)3. É possível abrir diretamente estes arquivos com algum editor de texto simples para ver como eles são organizados, como mostra a Figura 2.1.\n\n\n\nFigura 2.1: Exemplo de arquivo de texto delimitado\n\n\nComo é possível notar, temos duas variáveis neste arquivo: “Var1” e “Var2”. Cada linha é uma observação, e os valores de cada variáveis estão separados por uma vírgula. De forma geral, esta é a forma como dados são salvos neste tipo de arquivo – precisamos apenas saber qual é o separador das colunas (no caso, vírgula).\nPara carregar este arquivo, podemos usar a função read_delim do pacote readr – parte do pacote tidyverse. Como seu nome sugere, a função serve para ler arquivos delimitados. O procedimento é simples: passamos para a função o nome do arquivo, que deverá estar no diretório corrente de trabalho do R (ou passar o endereço do arquivo no computador), e o delimitador de colunas para o argumento delim =.\n\n# Carrega o pacote tidyverse\nlibrary(tidyverse)\n\n# Carrega os dados do arquivo \"exemplo.csv\"\nmeu_banco &lt;- read_delim(\"exemplo.csv\", delim = \",\")\n\n\n\n\n\n\n\nDiretório de trabalho\n\n\n\nO R só consegue carregar arquivos que estão no diretório de trabalho (para saber qual é este diretório, basta executar a função getwd() no console). Uma boa prática é criar um projeto com o RStudio na pasta onde estão os seus dados. Para tanto, basta ir em File &gt; New Project e escolher a opção Existing Directory e clicar em Create Project.\n\n\nO código acima já salva os dados do arquivo no objeto chamado meu_banco, que é um data.frame. Com isto, podemos usar a função glimpse do pacote dplyr (parte do tidyverse) para visualizar a estrutura do banco:\n\nglimpse(meu_banco)\n\nRows: 100\nColumns: 2\n$ Var1 &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19…\n$ Var2 &lt;dbl&gt; 100, 99, 98, 97, 96, 95, 94, 93, 92, 91, 90, 89, 88, 87, 86, 85, …\n\n\nOu podemos usar a função View para visualizar os dados do banco.\n\nView(meu_banco)\n\nO que deverá abrir uma nova aba no RStudio semelhante a essa:\n\n\n\nFigura 2.2: Usando a função View\n\n\nA função read_delim ainda pode ser adaptada para outros tipos de arquivos de texto delimitado, como .txt ou .tab; ou para abrir arquivos com outros delimitadores de colunas, como ponto e vírgula (delim = \";\") ou TAB (delim = \"\\t\", o que indica à função que as colunas são separadas por dois espaços simples). Os exemplos abaixo fazem exatamente isto.\n\nbanco1 &lt;- read_delim(\"exemplo_ponto_virgula.csv\", delim = \";\")\nbanco2 &lt;- read_delim(\"exemplo_texto.txt\", delim = \",\")\nbanco3 &lt;- read_delim(\"exemplo_tabular.tab\", delim = \",\")\nbanco4 &lt;- read_delim(\"exemplo_espacos.csv\", delim = \"\\tab\")\n\nAlém de arquivos armazenados no computador, também podemos carregar arquivos na internet: no lugar do nome do arquivo, é só passar para a função o link de onde o arquivo está hospedado.4.\n\nbanco5 &lt;- read_delim(\"https://github.com/tidyverse/readr/raw/master/inst/extdata/mtcars.csv\", delim = \";\")\n\nAlém destas extensões e do argumento delim, a função read_delim também nos permite passar outras instruções para o R carregar um arquivo. Dentre estas, a mais útil é skip, que serve para indicar a partir de qual linha queremos iniciar o carregamento dos dados (que pode ser usada para pular linhas que não estão formatadas corretamente).\nNa pasta de materiais complementares deste capítulo, temos um arquivo chamado pessoas.csv, que contém os nomes e as idades, salvas em duas variáveis, de algumas pessoas fictícias. Abrindo este arquivo com um editor de texto simples, veremos que o conteúdo dele está organizado de uma forma um pouco diferente do que já vimos anteriormente:\n\n\n\nFigura 2.3: Arquivo pessoas.csv\n\n\nPela Figura 2.3, é possível notar que existe a palavra “Exemplo” em uma linha acima do restante do conteúdo do arquivo e que, além disso, esta linha tem apenas um campo – o texto “Exemplo”. Vamos tentar carregar este arquivo com a função read_delim, que já vimos, para ver como o R lerá estes dados.\n\n# Carrega o arquivo \"pessoas.csv\"\npessoas &lt;- read_delim(\"pessoas.csv\", delim = \";\")\nView(pessoas)\n\n\n\n\nFigura 2.4: Arquivo pessoas.csv lido com read_delim\n\n\nP resultado, como fica evidente, não é o que queríamos. Para corrigir isso, precisamos usar o argumento skip da função read_delim para pedir que ela carregue os dados pulando algumas linhas (1, 2, 3, etc., linhas) – exatamente para pular aquele “Exemplo” e aquela linha em branco depois disso. Fazemos isto assim:\n\n# Carrega o arquivo \"pessoas.csv\" pulando tres linhas\npessoas &lt;- read_delim(\"pessoas.csv\", delim = \";\", skip = 3)\nView(pessoas)\n\n\n\n\nFigura 2.5: Arquivo pessoas.csv lido corretamente\n\n\n\n\n\n\n\n\nErros na importação de arquivos\n\n\n\nComo o exemplo do arquivos pessoas.csv ilustra, uma das principais fontes de erro na leitura de arquivos ocorre por especificação correta de como ler dados delimitados. Para evitar este tipo de problema, vale sempre abrir o arquivo que queremos carregar com um editor de texto para ver como ele está organizado.\n\n\nskip não esgota as possibilidades da função read_delim. Ao contrário, ela possui diversos argumentos adicionais úteis para contornar problemas. Na Tabela 2.2, segue uma descrição de alguns deles (para ver outros, digite no console help(read_delim)).\n\n\nTabela 2.2: Argumentos da função read_delim\n\n\n\n\n\n\n\nArgumento\nDescrição\nUso\n\n\n\n\nquote\nDelimitador de campos textuais\nquote = \"\\\"\"\n\n\ncol_names\nPassa novos nomes para as variáveis carregadas\ncol_names = c(\"Nome1\", \"Nome2\", ...\n\n\nlocale\nMuda as configurações de horário e acentuação\nVeremos adiante.\n\n\ncomment\nCarrega apenas linhas que não começam com o caractere especificado\ncomment = \"#\"\n\n\ntrim_ws\nRemove espaços em branco no início e no fim de cada campo\ntrim_ws = TRUE\n\n\ncol_types\nEspecifica o tipo de cada variável\ncol_types = \"ccdi\"\n\n\n\n\n\n\n2.4.2 Outros formatos\nUma vez que aprendemos como carregar arquivos com extensão .csv, é fácil carregar qualquer outro arquivo. O que veremos a seguir, portanto, são as funções e os pacotes mais comumente usados para carregar outros formatos de arquivo. De forma complementar, nas duas últimas seções aprendermos a lidar com os erros mais frequentes quando tentamos carregar algum arquivo e a exportar dados para arquivos dos mais diversos formatos.\n\n\n2.4.3 Planilhas\nPara abrir planilhas do Excel, com extensões .xls ou .xlsx, usamos a função read_excel do pacote readxl, que é semelhante à função read_delim. Exemplo:\n\n# Carrega o pacote readxl\nlibrary(readxl)\n\n# Carrega a planilha 'populacao_brasil.xls' na pasta do livro\ndados &lt;- read_excel(\"populacao_brasil.xls\")\n\nNovamente, a primeira coisa que passamos para a função é o nome do arquivo (ou, aqui também, o link de onde o arquivo está hospedado na internet) – na maioria dos casos, apenas isto é suficiente.\nTambém podemos passar argumentos opcionais para a função read_excel, tais como: sheet, que indica o número da planilha dentro do arquivo (1 para a primeira, 2 para a segunda, e assim por diante); e skip, que diz quantas linhas a função deve pular para começar a ler o conteúdo do arquivo, exatamente como na função read_delim.\nNo exemplo a seguir, carregamos a segunda planilha do mesmo arquivo, pedindo também para a função começar a ler os dados a partir da primeira linha.\n\n# Carrega a primeira planilha do arquivo pulando a primeira linha\ndados &lt;- read_excel(\"populacao_brasil.xls\", sheet = 1, skip = 1)\n\nO pacote readxl, entretanto, não serve para abrir planilhas feitas pelo Open Office (OpenDocument Spreadsheet, extensão .ods). Para carregar dados neste formato, existe um pacote específico: readODS. Basicamente, precisamos apenas carregá-lo e usar a função read.ods para carregar arquivos .ods:\n\n# Carrega o pacote\nlibrary(readODS)\n\n# Carrega a planilha 'populacao_brasil.ods' na pasta do livro\ndados &lt;- read.ods(\"populacao_brasil.ods\", sheet = 1)\n\n\n\n2.4.4 SPSS, Stata e SAS\nOutros softwares de análise de dados possuem arquivos próprios para armazenar dados. Estes são os casos do SPSS (arquivos .sav e .por), Stata (arquivos .dta) e SAS (arquivos .sas7bdat), todos os três muito populares na academia e no mercado.\nPara importar dados criados pelos softwares mencionados, recorremos ao pacote haven, que usa o código de outro pacote desenvolvido em C, o ReadStat, para fazer o trabalho. A título de exemplo, vamos carregar um banco de dados de um survey realizado na Austrália para avaliar o impacto de privações de sono.5 O uso do pacote é auto-explicativo.\n\n# Carrega o pacote haven\nlibrary(haven)\n\n# Carrega o arquivo \ndados &lt;- read_sav(\"sleep.sav\")\n\nNos três casos, o pacote faz o trabalho de manter as informações originais dos arquivos ao máximo possível. Em arquivos do SPSS, isso inclui manter os labels originais das variáveis e os seus tipos (a função read_sav converte variáveis numéricas e categóricas para seus tipos respectivos no R).\nPodemos verificar isto abrindo o objeto onde salvamos o arquivo do nome_do_arquivo, como na imagem abaixo – os labels aparecem logo abaixo do nome das variáveis.6 Quando possível, para arquivos do Stata e do SAS o mesmo também ocorre.7\n\n\n\nFigura 2.6: Base de dados do survey\n\n\n\n\n2.4.5 JSON\nOutro formato popular, ainda que pouco utilizado na academia, é o JSON (JavaScript Object Notation) – que pode ser encontrado cada vez mais em sites e API’s, como a de Dados Abertos do Governo Federal.8 O formato é bastante simples: chaves armazenam valores separados por dois pontos (e.g., {'valor' : 10, 23, 44}). A estrutura pode conter muitos valores separados por vírgula e, também, chaves dentro de chaves, ou ainda chaves dentro de [] (arrays), o que dá flexibilidade para aramanzenar diferentes tipos de informação. Um exemplo fictício para armazenar informações de preferências partidárias de algumas pessoas:\n[\n  {\n    \"nome\": \"João\",\n    \"idade\": 35,\n    \"partido\": \"PT\",\n    \"partidos_preferidos\": [\"PT\", \"PSB\", \"MDB\"]\n  },\n  {\n    \"nome\": \"Maria\",\n    \"idade\": 32,\n    \"partido\": \"MDB\",\n    \"partidos_preferidos\": [\"MDB\", \"PSDB\", \"DEM\"]\n  }\n]\nPara importar este tipo de arquivo no R, podemos usar a função import do pacote rio (abreviação de R Imput/Output; veremos outras utilidades dele adiante). O arquivo de exemplo vem da página da Transparência Internacional, da pesquisa Corruption Perceptions Index 2015.9\n\n# Carrega o pacote rio\nlibrary(rio)\n\n# Carrega o banco de dados do CPI 2015\ncpi &lt;- import(\"cpi-data.json\")\n\n\n\n2.4.6 R Data\nPor fim, temos o formato nativo do R, o R Data, para salvar dados. O deixamos por último por um motivo especial: ele é o formato mais adequado para salvar dados no R, tanto por simplicidade quanto por eficiência. Em primeiro lugar, e diferentemente de formatos de texto como .csv e .tab, arquivos .Rda são binários – o que, traduzindo, permite que se guarde muito mais informação em menos espaço, inclusive forçando a compressão dos dados. Em segundo lugar, ler e salvar estes arquivos pelo R é geralmente mais rápido, e isto apesar da compressão. Por fim, o formato salva e carrega objetos de um jeito mais intuitivo, como mostra o exemplo a seguir.\n\n# Carrega os mesmos dados da CPI 2015, agora em formato .Rda\nload(\"cpi2015.Rda\")\n\nNão é preciso carregar nenhum pacote, nem realizar nenhuma configuração: o objeto carregado vai direto para a memória do R, onde pode ser visto na aba Environment do RStudio. Outra vantagem do formato é que ele pode armazenar, de uma só vez, vários data.frames ou objetos quaisquer, facilitando a transposição de um projeto inteiro de um computador para outro – como quando temos precisamos analisar mais de uma base de dados.\n\n\n\n\n\n\nRDS\n\n\n\nOutro formato nativo no R é o RDS, que permite salvar e carregar arquivos usando um objeto para atribuição (dados &lt;- readRDS(\"dados.Rda\")). A diferença deste para o Rdata é que o RDS não permite salvar mais de um objeto, mas é igualmente rápido e atinge os mesmos níveis de compresão.\n\n\n\n\n2.4.7 Outros formatos\nEmbora tenhamos visto como abrir os tipos de arquivos mais comuns – delimitados por texto, planilhas e de outros softwares, entre outros – existe uma infinidade de formas de se armazenar dados em arquivos e, muitas vezes, precisaremos recorrer a alguma ferramenta diferente das que estudamos. Quando isso acontecer, no entanto, há uma opção mais simples: o pacote rio.\nResumidamente, o rio funciona como uma espécie de canivete suíço para a importação e exportação de dados: basta passar para a função import o nome do arquivo que queremos abrir. A partir disto, o rio identifica o formato do arquivo que estamos tentando abrir e chama internamente a função e especificações mais adequadas para tanto. Entre outros, os arquivos suportados pelo pacote incluem: .csv, .tsv, .fst, .psv, .fwf, .Rda, .Rds, .json, .dta, .sav, .xls, .mpt, .dif, entre outros10. Exemplo de funcionamento da função import:\n\n# Carrega o pacote rio\nlibrary(rio)\n\n# Importa alguns dados\ndados &lt;- import(\"exemplo.csv\")\ndados2 &lt;- import(\"sleep.sav\")"
  },
  {
    "objectID": "02-cap.html#exportando-dados",
    "href": "02-cap.html#exportando-dados",
    "title": "2  Importação",
    "section": "2.5 Exportando dados",
    "text": "2.5 Exportando dados\nSe importar dados para o R é algo fácil, como vimos, exportá-los é ainda mais. Tendo já alguns dados armazenados na memória do R, usamos funções semelhantes as de carregamento para exportá-los. Dentre estas, as principais são:\n\nFunções de exportação de dados {#tab-tabela33}\n\n\nArquivo\nExtensão\nPacote\nFunção\n\n\n\n\nTexto delimitado\n.txt\nreadr\nwrite_delim\n\n\nTexto delimitado\n.csv\nreadr\nwrite_delim\n\n\nSPSS\n.sav\nhaven\nwrite_sav\n\n\nStata\n.dta\nhaven\nwrite_dta\n\n\nSAS\n.sas7bdat\nhaven\nwrite_sas\n\n\nOutros\n-\nrio\nexport\n\n\nOutros\n-\nrio\nconvert\n\n\n\nPara exportar um data.frame qualquer, o procedimento básico é mais ou menos esse: o primeiro argumento que passamos para a função é o nome do objeto seguido do nome do arquivo que queremos criar entre aspas (não podemos esquecer de incluir a extensão do arquivo, que, no exemplo a seguir, é .txt).\n\n# Carrega o pacote readr\nlibrary(readr)\n\n# Cria um data.frame com duas variaveis\nbanco &lt;- data.frame(x = 1:10, y = 1:10)\n\n# Exporta ele para um arquivo .txt\nwrite_delim(banco, \"banco.txt\")\n\nExemplos das outras funções de exportação:\n\n# Outros pacotes\nlibrary(haven)\nlibrary(rio)\n\n# Exporta para .sav\nwrite_sav(banco, \"banco.sav\")\n\n# Exporta para .dta\nwrite_dta(banco, \"banco.dta\")\n\n# Exporta para .json (e' preciso declarar 'file =')\nexport(banco, \"banco.json\")\n\nAinda usando o pacote rio, também podemos converter diretamente um arquivo de um formato para outro, o que nos poupa o trabalho de, primeiro, ler o arquivo para, então, exportá-lo. Como exemplo, vamos converter o arquivo exemplo.csv, que está na pasta de materiais complementares deste livro, para .sav, formato do SPSS:\n\n# Converte o arquivo 'exemplo.csv' para .sav\nconvert(\"exemplo.csv\", \"exemplo.sav\")\n\nPara esta função, tudo o que precisamos fazer é passar o nome, ou o endereço com o nome, do arquivo que queremos converter e, como segundo argumento, o nome do arquivo que queremos criar – com a nova extensão. A depender do tamanho do arquivo, em poucos segundos a conversão é concluída. Mais tipos de conversão que a função convert executa podem ser vistos digitando ?convert no console."
  },
  {
    "objectID": "02-cap.html#lidando-com-erros",
    "href": "02-cap.html#lidando-com-erros",
    "title": "2  Importação",
    "section": "2.6 Lidando com erros",
    "text": "2.6 Lidando com erros\nAprender a usar funções adequadas para importar diferentes tipos de arquivo cobre boa parte do que precisamos para trabalhar com nossos dados no R, mas não tudo. Com frequência, usamos a ferramenta adequada e, mesmo assim, obtemos algum erro: o arquivo não abre, o R trava, ou ainda os dados abrem desconfigurados. Este tipo de coisa raramente é coberto em materiais didáticos, apesar de ser importante termos algumas noções básicas de como identificar – e de como contornar – erros na importação de dados. É justamente isso o que abordamos nesta seção.\n\n2.6.1 Especificação do delimitador\nEm arquivos delimitados de texto, talvez o erro mais comum é o de especificar de forma errada o delimitador: passar uma vírgula quando ele é, na verdade, ponto e vírgula; ou passar ponto e vírgula quando ele é outra coisa. Aqui o truque é quase banal: tentar abrir o arquivo com um editor de texto simples para olhar os dados. Na maioria das vezes, isto já permite localizar o identificador adequado. O problema desta solução é que isto pode não dar certo se o arquivo for muito grande (e o editor de texto não conseguir abri-lo).\nOutra solução é ir na tentativa e erro. Por exemplo:\n\n# Se isto nao der certo...\nbanco &lt;- read_delim(\"exemplo_ponto_virgula.csv\", delim = \",\")\n\n# Tentamos isto...\nbanco &lt;- read_delim(\"exemplo_ponto_virgula.csv\", delim = \"\\tab\")\n\n# E se tambem nao der, tentamos isto\nbanco &lt;- read_delim(\"exemplo_ponto_virgula.csv\", delim = \";\")\n\n\n\n2.6.2 Células vazias\nAlguns arquivos às vezes vêm com células vazias, isto é, com informações não preenchidas (como missings), e isto pode resultar em erros. Em geral, isto ocorre mais em arquivos de texto delimitados, mas as funções que mostramos aqui para abri-los (read_delim, principalmente) nos dão notificações sobre estes erros. Os dados são carregados normalmente, mas ficamos sabendo onde procurar lacunas na base.\n\n\n2.6.3 Problemas de acentuação\nOutro problema comum para quem trabalha com bancos de dados que contêm informações textuais (nomes, endereços, etc.) é a acentuação. Volta e meia importamos um arquivo com Ã ou Â que são exibidos como ¢ e Ă no lugar.\nExplicar por que isto acontece foge muito do escopo deste livro, mas é útil entender que cada sistema possui um conjunto de caracteres válidos para se escrever texto: em português, temos alguns acentos; em inglês, não. Assim, quando informações escritas usando um conjunto de caracteres particular, que chamamos de encoding, é trasposto para outro conjunto, coisas como estas ocorrem. E trocar de sistema operacional, abrir arquivos criados por um software em outro, entre outros, são situações onde isto pode acontecer.\nEm português, usamos principalmente os encodings UTF-8 e latin1 (mas existem outros, alguns mais específicos) e, portanto, nossa primeira tentativa de corrigir estes erros é passando estes encodings para as funções que usamos para carregar dados que possam conter acentos usados em português. No caso da função read_delim, isto seria feito da seguinte forma:\n\n# Caso o arquivo 'exemplo.csv' tivesse erro de encoding, tentariamos...\ndados &lt;- read_delim(\"exemplo.csv\", delim = \",\", locale = locale(encoding = \"UTF-8\"))\n\n# Ou tentariamos...\ndados &lt;- read_delim(\"exemplo.csv\", delim = \",\", locale = locale(encoding = \"latin1\"))\n\nÀs vezes, isto não resolve: o encoding do arquivo não é nenhum dos dois. Para a nossa sorte, o pacote readr possui uma função chamada guess_encoding que tenta descobrir o encoding de um arquivo. Caso UTF-8 e latin1 não sirvam, portanto, tente o seguinte:\n\nlibrary(readr)\nguess_encoding(\"exemplo.csv\")\n\n\n\n# A tibble: 1 × 2\n  encoding confidence\n  &lt;chr&gt;         &lt;dbl&gt;\n1 ASCII             1\n\n\nE aqui vemos que o encoding do arquivo exemplo.csv, que já carregamos antes, é provavelmente ASCII (um tipo de encoding com suporte para inglês, sem acentos).\n\n\n2.6.4 Erros humanos\nNeste ponto, precisamos falar de erros humanos: digitar errado o nome de um arquivo, passar o local errado de onde o arquivo está, usar uma função que abre um tipo de arquivo para tentar abrir arquivos de outro formato, entre outros. Mesmo parecendo algo trivial, tanto pessoas aprendendo R quanto outras experientes cometem este tipo de erro toda hora. Nosso alerta final, portanto, é: certifique-se de ter usado a função correta, de não ter digitado nada errado e de garantir de que o endereço do arquivo (ou o diretório corrente do R) existe."
  },
  {
    "objectID": "02-cap.html#bases-muito-grandes",
    "href": "02-cap.html#bases-muito-grandes",
    "title": "2  Importação",
    "section": "2.7 Bases muito grandes",
    "text": "2.7 Bases muito grandes\nO R possui uma grande limitação em relação ao carregamento de dados: por armazenar informações na memória RAM do computador, e não no disco rígido, ele não suporta dados muito pesados, isto é, bases mais pesadas do que a capacidade de memória do seu computador. Por isso, a placa de RAM do seu computador (8gb, ou 16gb, etc.) é quem dita o tamanho dos arquivos que podemos carregar.11\nCaso você tenha uma base de dados muito grande, que excede em tamanho a memória RAM do seu computador, será necessário usar outras soluções para importá-la. Há pacotes no R que fornecem algumas soluções alternativas de importação, mas não os abordaremos aqui – são pouco utilizadas e têm limitações de integração com outras ferramentas que vimos ou que ainda veremos.12 Em vez disso, seguiremos o mote geral deste livro: veremos um par de ferramentas, o pacote DBI e o pacote duckdb, que nos dá uma solução simples e versátil para carregar e manipular dados de qualquer tamanho.\n\n2.7.1 Pacote DBI\nO DBI é uma interface para conectar o R a bancos de dados relacionais como o MySQL, o Postgres, o SQLite, entre outros.13 Podemos pensar no DBI da seguinte forma: em vez de carregar e manipular dados que não cabem na memória do computador, o DBI tira essa tarefa do R e a delega para um banco de dados relacional, que é capaz de lidar com arquivos muito grandes.\nPodemos instalar o DBI com o nosso conhecido install.packages e, depois, carregá-lo com library:\n\ninstall.packages(\"DBI\")\nlibrary(DBI)\n\nNo lugar de usar alguma função read_, o carro-chefe do DBI é a função dbConnect, que serve para conectar o R a um banco de relacional. A razão de usarmos esse procedimento é simples: bancos de dados, no mais das vezes, não são arquivos que existem localmente, como uma planilha de Excel; antes, são servidores que armazenam e gerenciam informações – o que queremos fazer, portanto, é nos conectarmos a esse servidores para poder passar a ele instruções, via R, de como manipular os dados que estão armazenados nele. Um exemplo genérico de como usaríamos dbConnect, que será detalhado na sequência:\n\n# Conecta o R a um banco de dados relacional\ncon &lt;- dbConnect(duckdb::duckdb())\n\n\n\n2.7.2 DuckDB\nA maioria dos sistemas de gerenciamento de bancos de dados, como MySQL e Postgres, rodam em servidores na internet e, além disso, dependem que instalemos softwares específicos, chamados de drivers, para que o R se conecte a eles. Há alguma exceções a esta regra geral, no entanto. Uma delas é o DuckDB, um sistema de gerenciamento de banco de dados que roda localmente, isto é, no seu computador, e que não precisa de nenhum driver adicional para ser usado no R.\nO DuckDB é um banco de dados relativamente novo, mas que tem ganhado popularidade por ser rápido para tarefas típicas de análise de dados, como a leitura e manipulação de colunas com até mesmo centenas de milhões de linhas. Especialmente útil, o DuckDB contém funcionalidades para importação de grandes arquivos, como arquivos de texto delimitados; arquivos de Excel; e arquivos no formato parquet, outro formato que discutiremos em seguida. Por todas essas razões é que, neste livro, sugerimos o uso do DuckDB para fazer o carregamento e manipulação de arquivos muito grandes, que não poderiam ser carregados diretamente na memória do computador via R.\nPara instalar o DuckDB, não precisamos de nada além de install.packages:\n\ninstall.packages(\"duckdb\")\nlibrary(duckdb)\n\nCom o pacote instalado, para criar e nos conectarmos a um banco de dados DuckDB, que fará o carregamento propriamente de arquivos muitos grandes, usamos a linha que já vimos:\n\ncon &lt;- dbConnect(duckdb::duckdb())\n\nNeste código, o argumento duckdb::duckdb() serve para estabelecer que a função dbConnect deverá criar e se conectar a um banco de dados DuckDB – com isso, já temos a infraestrutura necessária em ação para carregar arquivos muito grandes. Imagine, por exemplo, que tenhamos um arquivo CSV com 8gb de tamanho chamado exemplo.csv. Para carregá-lo, passamos o objeto con criado há pouco para a função tbl do pacote dplyr (parte do tidyverse), que usaremos para importar os dados:\n\n# Carregamos o pacote tidyverse \nlibrary(tidyverse)\n\ndf &lt;- tbl(con, \"exemplo.csv\")\n\nO código acima é similar ao que usamos para carregar outros tipos de arquivos: passamos o endereço do arquivo que queremos carregar para a função tbl, que serve para ler uma tabela a partir de um banco de dados relacional ao qual nos conectamos, e criamos o objeto df, que armazenará o resultado dessa tabela. Na maioria das vezes, sequer precisamos especificar o delimitador de colunas, pois o DuckDB é capaz de identificá-lo automaticamente.14\nO processo de importação de dados com DBI e duckdb é mais ou menos esse, exceto por um detalhe: o arquivo exemplo.csv não foi efetivamente carregado na memória do computador; em vez disso, o que temos é um atalho para o arquivo que será manipulado pelo banco de dados relacional criado com o DuckDB. Desse modo, acionamos o DuckDB para que ele carregue o arquivo exemplo.csv e nos dê um atalho para manipulá-lo a partir do disco rígido. Se quisermos pré-visualizar o conteúdo do arquivo importado via DuckDB, basta executar o objeto df no console:\n\ndf\n\n# Source:   table&lt;pessoas&gt; [10 x 2]\n# Database: DuckDB v0.9.2 [fmeireles@Linux 6.6.6-100.fc38.x86_64:R 4.3.2/:memory:]\n   nome     idade\n   &lt;chr&gt;    &lt;dbl&gt;\n 1 João        35\n 2 Maria       32\n 3 José        28\n 4 Ana         31\n 5 Pedro       29\n 6 Mariana     27\n 7 Carlos      33\n 8 Juliana     30\n 9 Fernando    26\n10 Luana       34\n\n\nO resultado dessa execução exibe um sumário, com as primeiras linhas e algumas colunas do arquivo, para facilitar a nossa consulta. Vale notar também algo importante: logo na segunda linha do output do R, há o trecho Database: DuckDB ..., que indica que a base que estamos lendo está em um banco relacional DuckDB que roda a partir do nosso computador.\n\n\n2.7.3 Arquivos parquet\nAlém de carregar arquivos delimitados, o DuckDB também é capaz de carregar arquivos no formato parquet, um formato estruturado de armazenamento de dados orientado por colunas, que é especialmente útil para tarefas de análises de dados.15\nComo exemplo da potencialidade dos pacotes DBI e duckdb, carregaremos como exemplo a base de microdados de pessoas do Censo de 2010, disponibilizada na internet em formato parquet no repositório do pacote de R censobr (Pereira e Barbosa 2023).16\n\ncenso &lt;- tbl(con, \"2010_population_v0.2.0.parquet\")\n\nIsso feito, podemos pré-visualizar as informações do objeto como fizemos antes:\n\ncenso\n\n# Source:   table&lt;data/2010_population_v0.2.0.parquet&gt; [?? x 251]\n# Database: DuckDB v0.9.2 [fmeireles@Linux 6.6.6-100.fc38.x86_64:R 4.3.2/:memory:]\n   code_muni code_state abbrev_state name_state code_region name_region\n   &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;       &lt;chr&gt;      \n 1 1100015   11         RO           Rondônia   1           Norte      \n 2 1100015   11         RO           Rondônia   1           Norte      \n 3 1100015   11         RO           Rondônia   1           Norte      \n 4 1100015   11         RO           Rondônia   1           Norte      \n 5 1100015   11         RO           Rondônia   1           Norte      \n 6 1100015   11         RO           Rondônia   1           Norte      \n 7 1100015   11         RO           Rondônia   1           Norte      \n 8 1100015   11         RO           Rondônia   1           Norte      \n 9 1100015   11         RO           Rondônia   1           Norte      \n10 1100015   11         RO           Rondônia   1           Norte      \n# ℹ more rows\n# ℹ 245 more variables: code_weighting &lt;chr&gt;, V0001 &lt;chr&gt;, V0002 &lt;chr&gt;,\n#   V0011 &lt;chr&gt;, V0300 &lt;dbl&gt;, V0010 &lt;dbl&gt;, V1001 &lt;chr&gt;, V1002 &lt;chr&gt;,\n#   V1003 &lt;chr&gt;, V1004 &lt;chr&gt;, V1006 &lt;chr&gt;, V0502 &lt;chr&gt;, V0504 &lt;chr&gt;,\n#   V0601 &lt;chr&gt;, V6033 &lt;dbl&gt;, V6036 &lt;dbl&gt;, V6037 &lt;dbl&gt;, V6040 &lt;chr&gt;,\n#   V0606 &lt;chr&gt;, V0613 &lt;chr&gt;, V0614 &lt;chr&gt;, V0615 &lt;chr&gt;, V0616 &lt;chr&gt;,\n#   V0617 &lt;chr&gt;, V0618 &lt;chr&gt;, V0619 &lt;chr&gt;, V0620 &lt;chr&gt;, V0621 &lt;chr&gt;, …\n\n\nNeste exemplo, dá para notar que a base, muito grande, não é carregada inteiramente, o que é indicado logo na primeira linha do output em Source:   table&lt;data/2010_population_v0.2.0.parquet&gt; [?? x 251], o que indica que a base tem 251 colunas e um número indeterminado de linhas.\n\n\n2.7.4 Outros bancos relacionais\nBancos de dados relacionais são comuns em diferentes áreas, e há diferentes alternativas específicas para análise de dados. Para quem já tem alguma experiência com eles, o DBI oferece uma interface unificada para integrar o R a outros bancos relacionais, como o MySQL, o Postgres, o SQLite, para ficar apenas entre alguns mais populares.17 O procedimento é similar ao que vimos para o DuckDB: precisamos instalar o driver do banco de dados que queremos usar e, depois, nos conectarmos a ele com a função dbConnect.\nTalvez a segunda alternativa mais fácil, e de menor custo de configuração depois do DuckDB, seja o SQLite, um banco de dados relacional que roda localmente, no seu computador, e que não precisa de nenhum driver adicional para ser usado no R.18 Para usá-lo, precisamos instalar o pacote RSQLite e, depois, nos conectarmos a ele com a função dbConnect:\n\ninstall.packages(\"RSQLite\")\nlibrary(RSQLite)\n\ncon &lt;- dbConnect(RSQLite::SQLite())\n\n\n\n\n\n\n\nDrivers\n\n\n\nPara usar o DBI com outros bancos relacionais, precisamos instalar o driver do banco de dados específico que queremos usar. Por exemplo, para usar o DBI com o MySQL, precisamos instalar o pacote MariaDB antes; para usar com o Postgres, precisamos instalar o pacote RPostgres; e assim por diante.\n\n\nEsse é apenas mais uma das inúmeras possibilidades de uso do DBI. Para além da função dbConnect, o pacote também possui funções para criar tabelas, inserir e atualizar dados, entre outras, e existem várias opções de integração com outros tipos de bancos relacionais e formatos – dos mais tradicionais, como o MySQL, a soluções como o Google Big Query, que permite o armazenamento e a análise de grandes volumes de dados na nuvem.19. Em todo o caso, a dupla DBI + duckdb é não só suficiente como, com frequência, uma das mais indicadas para resolver a maioria dos problemas de carregamento de dados encontrados na prática."
  },
  {
    "objectID": "02-cap.html#resumo-do-capítulo",
    "href": "02-cap.html#resumo-do-capítulo",
    "title": "2  Importação",
    "section": "2.8 Resumo do capítulo",
    "text": "2.8 Resumo do capítulo\nNeste capítulo, cobrimos a mecânica básica da importação de dados no R. Começamos com os tipos de arquivos mais comuns, como arquivos de texto delimitados, planilhas e arquivos de outros softwares de análise de dados, como o SPSS e o Stata. O truque geral é: cada formato de arquivo demanda um tipo específico de solução, e o R possui funções específicas para cada um deles. Depois, vimos como carregar arquivos menos comuns, como arquivos JSON e arquivos parquet. Por fim, vimos como carregar arquivos muito grandes, que não cabem na memória do computador, usando o pacote DBI e o sistema de gerenciamento de bancos relacionais DuckDB disponível via duckdb."
  },
  {
    "objectID": "02-cap.html#indo-além",
    "href": "02-cap.html#indo-além",
    "title": "2  Importação",
    "section": "2.9 Indo além",
    "text": "2.9 Indo além\nImportar dados é uma tarefa complexa, e muitas vezes uma receita pronta, como as que vimos aqui, não servirá. Conforme você aprenda mais sobre o R e comece a trabalhar em projetos específicos, é possível que se depare com a necessidade de buscar outras soluções, ou mesmo de ter de criar ou adaptar alguma para uso próprio. Neste sentido, vale a pena conhecer alguns pacotes que podem ser úteis para importar dados de formatos mais específicos.\n…\nHá diversos pacotes em R que servem para justamente importar dados de diferentes fontes diretamente no R. Alguns deles, que podem ajudar principalmente a obter dados sobre o Brasil, são:\n\ncensobr\ncongressbr\nelectionsBR\nPNADcIBGE\nsidrar\n\n\n\n\n\nDowle, Matt, e Arun Srinivasan. 2023. data.table: Extension of ‘data.frame‘. https://CRAN.R-project.org/package=data.table.\n\n\nMuhleisen, Hannes, Mark Raasveldt, e DuckDB Contributors. 2020. duckdb: DBI Package for the DuckDB Database Management System. https://CRAN.R-project.org/package=duckdb.\n\n\nPereira, Rafael H. M., e Rogério J. Barbosa. 2023. censobr: Download Data from Brazil’s Population Census (versão v0.2.0). https://CRAN.R-project.org/package=censobr.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, e Garrett Grolemund. 2023. R for data science. \" O’Reilly Media, Inc.\"."
  },
  {
    "objectID": "02-cap.html#footnotes",
    "href": "02-cap.html#footnotes",
    "title": "2  Importação",
    "section": "",
    "text": "Assim como outras linguagens de programação, o R precisa carregar informações na memória RAM para poder trabalhar com eles, daí o limite de armazenamento de bancos grandes de dados.↩︎\nAs ferramentas que usaremos aqui não são nem de longe as únicas, nem necessariamente as melhores, para carregar dados – na verdade, o próprio R já vem com algumas funções nativas para importação de dados. Nossa escolha aqui reflete mais nossa experiência trabalhando com o R e a filosofia mais geral deste livro: as funções que usamos são simples, flexíveis e, em geral, as mais rápidas.↩︎\nUma opção interessante para arquivos grandes delimitados é a função fread do pacote data.table (Dowle e Srinivasan 2023), que não vamos abordar aqui.↩︎\nNem todas as funções de carregamento de arquivos que veremos suportam importação de arquivos da internet. Outro aspecto a notar é que read_delim e similares carregam apenas arquivos hospedados em servidores que não exigem autenticação – ou seja, que não exigem que você faça login para acessar um dado arquivo.↩︎\nDetalhes do survey podem ser vistos em: http://spss.allenandunwin.com.s3-website-ap-southeast-2.amazonaws.com/data-files.html.↩︎\nA depender da versão de software proprietário utilizada no salvamento do arquivo e de sua estrutura, labels podem não ser carregados por padrão. Nesse caso, é possível passar o data.frame carregado para a função as_factor do pacote haven que, se possível, os incluirá explicitamente no objeto.↩︎\nAs funções read_dtae read_sas possuem alguns argumentos adicionais, que podem ser úteis para corrigir acentuação e especificar outros detalhes.↩︎\nDisponível em https://dados.gov.br/.↩︎\nA página da pesquisa, bem como os dados e outros recursos, estão disponíveis em: https://www.transparency.org/cpi2015/.↩︎\nPara ver a lista completa de arquivos suportados ver https://github.com/leeper/rio↩︎\nNas versões mais recentes do RStudio, é possível ver a memória RAM disponível e já usada pela sua sessão do R no canto superior direito da tela, na aba envorinment. Para saber mais sobre as abas do RStudio, ver o [capítulo -#sec-cap1].↩︎\nEntre outros, vale checar o ff (https://CRAN.R-project.org/package=ff) e o bigmemory (https://CRAN.R-project.org/package=bigmemory), que permitem manipular dados diretamente do disco, criando apenas atalhos na memória.↩︎\nFugiria muito do escopo do livro abordar bases relacionais, tópico que, por si só, é complexo e que antecede em muito o desenvolvimento do próprio R. Recomendados, no entanto, a leitura do capítulo 21 do livro de Wickham, Çetinkaya-Rundel, e Grolemund (2023) para quem quiser uma introdução geral e intuitiva ao tema.↩︎\nAlternativamente, é possível usar a função duckdb_read_csv para importar o arquivo. Para mais detalhes, vale consultar a documentação do pacote (Muhleisen, Raasveldt, e DuckDB Contributors 2020).↩︎\nPara mais detalhes sobre o formato Apache parquet, ver: https://parquet.apache.org/.↩︎\nTodos os arquivos em parquet do Censos realizados pelo IBGE divulgados pelo pacote censobr podem ser encontrados no seguinte endereço: https://github.com/ipeaGIT/censobr/releases/tag/v0.2.0.↩︎\nPara mais detalhes sobre como usar o DBI com outros bancos relacionais, ver: https://db.rstudio.com/.↩︎\nPara mais detalhes sobre o SQLite, ver: https://www.sqlite.org/index.html.↩︎\nPara mais detalhes sobre como usar o DBI com outros bancos relacionais, ver: https://db.rstudio.com/.↩︎"
  },
  {
    "objectID": "03-cap.html#sec-tidy-data",
    "href": "03-cap.html#sec-tidy-data",
    "title": "3  Manipulação",
    "section": "3.1 Tidy data",
    "text": "3.1 Tidy data\nQualquer pessoa minimamente familiarizadas com metodologia de pesquisa sabe que bases com problemas podem invalidar uma análise: esquecer de deflacionar séries de preços em análises históricas, por exemplo, é um problema porque sabemos que R$ 100,00 de hoje não vale o mesmo que R$ 100,00 em 1998. Ainda assim, duas ou mais pessoas minimamente familiarizadas com análise de dados podem divergir sobre como estruturar uma base. Imagine, por exemplo, que tenhamos um pequeno banco de dados com a quantidade de votos de partidos políticos fictícios. Uma forma razoável de organizar estes dados seria assim:\n\n\nTabela 3.1: Exemplos de bases de dados com votos de partidos políticos\n\n\n\n\n(a) Tidy\n\n\nPartido\nVotos\n\n\n\n\nA\n234\n\n\nB\n451\n\n\nC\n200\n\n\n\n\n\n\n(b) Não-tidy\n\n\nA\nB\nC\n\n\n\n\n234\n451\n200\n\n\n\n\n\n\nSe repararmos bem, ambas as formas de disposição dos dados são consistentes. Cada linha ou coluna contém apenas o mesmo tipo de informação – partido ou votos – e é fácil identificar a estrutura de cada base: na primeira, cada linha indica os atributos de um único partido; já na segunda, cada coluna indica a votação do respectivo partido. Temos exemplos destes dois métodos inclusive em bases que já carregamos no Capítulo 2: o arquivo exemplo.csv está organizado da primeira forma, enquanto que o arquivo populacao_brasil.xls está organizado da segunda.\nAinda que a segunda forma seja útil em determinadas aplicações, daqui até o final do livro trabalharemos com a primeira forma, popularizada pelo estatístico e desenvolvedor de R Hadley como tidy data, ou dados arrumados (Wickham 2014). Nesta estrutura, basicamente três regras são seguidas:\n\nCada variável é uma coluna;\nCada observação é uma linha;\nCada valor está numa única célula.\n\nExposto dessa forma, não é óbvio o significado de cada uma dessas regras. Em primeiro lugar, o conjunto desses princípios nos indica que as colunas são compostas por variáveis, que são simplesmente atributos de cada observação. Voltando à nossa tabela inicial, “votos” é uma variável e, portanto, está em uma coluna, pois representa a votação de cada partido. O mesmo vale para o nome do partido, na coluna “partido”, e também para outros atributos do partido, como número de filiados, número de deputados, entre outros. Em outras palavras, uma variável é uma característica de uma observação e, portanto, deve estar em uma coluna.\nEm segundo lugar, as linhas indicam os indivíduos ou observações que temos – cada um dos partidos na nossa base, como na tabela anterior. Podemos pensar na observação como a nossa unidade de análise. Poderíamos ter observações repetidas de um mesmo indivíduo ao longo do tempo, como o partido A em 2003 e o partido A em 2004; neste caso, o ano seria uma nova variável na nossa base. Por fim, cada atributo de cada unidade de análise – partidos no nosso caso – está em uma única célula, o que significa que não temos informações repetidas ou ausentes. É o que vemos na tabela anterior: cada partido tem apenas um nome, uma votação e uma sigla.\nA Tabela 3.2, a seguir, resume a ideia por detrás das regras de tidy data:\n\n\nTabela 3.2: Princípios de tidy data\n\n\n\n\n\n\n\nRegra\nSignificado\nExemplo\n\n\n\n\nCada variável é uma coluna\nCada coluna deve armazenar apenas informações de um mesmo atributo\nVotação dos partidos\n\n\nCada observação é uma linha\nCada linha representa uma unidade de análise ou um indivíduo\nPartido A\n\n\nCada valor está numa única célula\nCada célula contém apenas um valor\n234\n\n\n\n\n\n3.1.1 Espalhar e reunir\nDuas operação resumem tudo o que precisamos fazer para estruturar uma base no formato tidy: alongar e reunir. No R, essas operações podem ser feitas usando o pacote tidyr, com a função pivot_wide servindo para alongar valores de uma coluna e, por sua vez, a função pivot_wider para reunir numa única coluna valores dispersos em várias.\nPara aprendermos a usar ambas as funções, trabalharemos com um banco de dados contendo informações sobre o número de homicídios ocorridos anualmente nos estados brasileiros entre 2000 e 2009, conforme disponibilizado pelo Ipeadata1 com base nos dados originais do Datasus2. Os dados estão na pasta de materiais complementares deste livro em uma planilha de Excel chamada homicidios_uf.xls. Para carregá-la (ver o Capítulo 2), usaremos a função read_excel do pacote readxl:\n\nlibrary(readxl)\nhomic &lt;- read_excel(\"homicidios_uf.xls\")\n\nCom a função head, podemos visualizar as primeiras observações deste banco.\n\nhead(homic)\n\n# A tibble: 6 × 13\n  Sigla Codigo Estado   `2000` `2001` `2002` `2003` `2004` `2005` `2006` `2007`\n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 AC    12     Acre        108    122    151    135    115    125    155    133\n2 AL    27     Alagoas     724    836    989   1041   1034   1211   1617   1839\n3 AM    13     Amazonas    559    478    512    561    523    598    697    711\n4 AP    16     Amapá       155    184    181    190    173    196    203    171\n5 BA    29     Bahia      1223   1573   1735   2155   2255   2823   3276   3608\n6 CE    23     Ceará      1229   1298   1443   1560   1538   1692   1793   1936\n# ℹ 2 more variables: `2008` &lt;dbl&gt;, `2009` &lt;dbl&gt;\n\n\nÉ possível perceber que a estrutura do banco homic não é tidy: temos várias colunas com alguns anos (que são atributos do momento em que um indivíduo é observado), em vez de uma coluna com número de homicídios e uma coluna para anos. O que gostaríamos de ter, portanto, seria algo mais ou menos assim:\n\n\n# A tibble: 6 × 5\n  Sigla Codigo Estado Ano   Homicidios\n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;      &lt;dbl&gt;\n1 AC    12     Acre   2000         108\n2 AC    12     Acre   2001         122\n3 AC    12     Acre   2002         151\n4 AC    12     Acre   2003         135\n5 AC    12     Acre   2004         115\n6 AC    12     Acre   2005         125\n\n\nComo fazer essa transformação? Usamos a função pivot_longer, para alongar a base homic que é originalmente larga. Seu uso é simples e requer apenas que passemos a ela o nome do objeto onde está o banco que queremos modificar; e o nome das variáveis que queremos alongar ou preservar como estão no banco. Aplicamos pivot_longer da seguinte forma:\n\n# Carrega o pacote tidyverse\nlibrary(tidyverse)\n\n# Reune as variaveis de ano espalhadas pela base 'homic'\nhomic2 &lt;- pivot_longer(homic, -c(Sigla, Codigo, Estado), names_to = \"Ano\", values_to = \"Homicidios\")\n\n# Verifica as primeiras observacoes do novo banco\nhead(homic2)\n\n# A tibble: 6 × 5\n  Sigla Codigo Estado Ano   Homicidios\n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;      &lt;dbl&gt;\n1 AC    12     Acre   2000         108\n2 AC    12     Acre   2001         122\n3 AC    12     Acre   2002         151\n4 AC    12     Acre   2003         135\n5 AC    12     Acre   2004         115\n6 AC    12     Acre   2005         125\n\n\nO resultado da aplicação de pivot_longer é uma base tidy. De forma mais detalhada, a função pivot_longer possui dois argumentos obrigatórios: data, que é o nome do objeto onde está o banco; e cols, que indica quais colunas devem ser alongadas (no nosso exemplo, as colunas 2000, 2001, etc.). O mais importante do código anterior é que declaramos as variáveis a manter como estavam (pois já estavam no formato tidy) com o uso de -c(). Podemos fazer o inverso: indicar quais variáveis devem ser alongadas, em vez de quais devem ser mantidas:\n\n# Reune as variaveis de ano espalhadas pela base 'homic'\nhomic3 &lt;- pivot_longer(homic, `2000`:`2009`, names_to = \"Ano\", values_to = \"Homicidios\")\nhead(homic3)\n\n# A tibble: 6 × 5\n  Sigla Codigo Estado Ano   Homicidios\n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;      &lt;dbl&gt;\n1 AC    12     Acre   2000         108\n2 AC    12     Acre   2001         122\n3 AC    12     Acre   2002         151\n4 AC    12     Acre   2003         135\n5 AC    12     Acre   2004         115\n6 AC    12     Acre   2005         125\n\n\nNo exemplo, usamos 2000`:`2009 para indicar o nome de todas as variáveis que queríamos alongar, o que deve ser lido como “selecione todas as variáveis entre 2000 e 2009” (não se preocupe se esse uso de : para selecionar variáveis não fez sentido agora, veremos isso adiante).\nA função pivot_longer também possui dois argumentos opcionais: names_to, que é o nome que iremos dar à variável que armazenará o nome das variáveis reunidas (neste caso, “Ano”); e values_to, que é o nome da variável que armazenará os valores das variáveis reunidas. Note que não é necessário declarar os argumentos names_to e values_to, caso no qual a função pivot_longer atribui às novas variáveis os nomes name e value, respectivamente.\n\n# Reune as variaveis de ano espalhadas pela base 'homic'\nhomic4 &lt;- pivot_longer(homic, -c(Sigla, Codigo, Estado))\nhead(homic4)\n\n# A tibble: 6 × 5\n  Sigla Codigo Estado name  value\n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n1 AC    12     Acre   2000    108\n2 AC    12     Acre   2001    122\n3 AC    12     Acre   2002    151\n4 AC    12     Acre   2003    135\n5 AC    12     Acre   2004    115\n6 AC    12     Acre   2005    125\n\n\n\n\n\n\n\n\nSobrescrevendo objetos\n\n\n\nAo restruturar a base homic, criamos novos objetos homic2, homic3 e homic4 para não sobrescrever o conteúdo do tibble homic original. Dito de outra maneira, executar homic &lt;- pivot_longer(homic, -c(Sigla, Codigo, Estado)) faria com que o objeto homic original fosse substituído pelo resultado de pivot_longer.\n\n\nPara desfazer a operação de alongamento, usamos a função inversa, que é pivot_wider. Precisamos passar para ela apenas o nome das variáveis que queremos espalhar em diferentes colunas (vamos usar o tibble homic2 aqui, criado algumas linhas atrás):\n\n# Espalha as variaveis de ano reunidas pela base 'homic'\nhomic5 &lt;- pivot_wider(homic2, names_from = Ano, values_from = Homicidios)\nhead(homic5)\n\n# A tibble: 6 × 13\n  Sigla Codigo Estado   `2000` `2001` `2002` `2003` `2004` `2005` `2006` `2007`\n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 AC    12     Acre        108    122    151    135    115    125    155    133\n2 AL    27     Alagoas     724    836    989   1041   1034   1211   1617   1839\n3 AM    13     Amazonas    559    478    512    561    523    598    697    711\n4 AP    16     Amapá       155    184    181    190    173    196    203    171\n5 BA    29     Bahia      1223   1573   1735   2155   2255   2823   3276   3608\n6 CE    23     Ceará      1229   1298   1443   1560   1538   1692   1793   1936\n# ℹ 2 more variables: `2008` &lt;dbl&gt;, `2009` &lt;dbl&gt;\n\n\nDiferentemente de pivot_longer, com pivot_wider temos que passar dois argumentos obrigatórios: names_from, que é o nome da variável que armazena os nomes das variáveis que queremos espalhar; e values_from, que é o nome da variável que armazena os valores das variáveis que queremos espalhar, sem aspas.3\nCom estas duas funções podemos tanto colocar em várias colunas valores que estavam agrupados numa única (último exemplo) quanto colocar numa mesma coluna valores que estavam espalhados por várias outras (primeiro exemplo). Na sequência, começaremos a usar o pacote dplyr para manipular bases de dados, mas, quando necessário, recorreremos às funções pivot_ para estruturar inicialmente elas em formato tidy."
  },
  {
    "objectID": "03-cap.html#sec-dplyr",
    "href": "03-cap.html#sec-dplyr",
    "title": "3  Manipulação",
    "section": "3.2 Operacões básicas de manipulação de dados",
    "text": "3.2 Operacões básicas de manipulação de dados\nCom uma base estruturada de forma adequada, podemos realizar outras operações nela (na verdade, frequentemente precisamos realizar operações tidy em várias etapas de limpeza de dados). Neste capítulo, vamos nos concentrar em quatro operações, que chamaremos de verbos:\n\nfiltrar, para escolher observações (linhas) para manter ou excluir com base em algum critério;\nselecionar, para escolher colunas a manter, reordenar ou remover;\nmodificar, para criar ou alterar variáveis e observações; e\nagrupar, para realizar modificações ou resumos de informações por grupo.\n\nMelhor do que explicar, a Figura 3.1 ilustra visualmente o que cada um desses verbos faz em uma base de dados.\n\n\n\n\n\n\n\n(a) Filtrar linhas\n\n\n\n\n\n\n\n(b) Selecionar colunas\n\n\n\n\n\n\n\n\n\n(c) Criar/modificar colunas\n\n\n\n\n\n\n\n(d) Resumir por grupo\n\n\n\n\nFigura 3.1: Principais verbos de manipulação de dados do pacote dplyr\n\n\nEnquanto que slice e filter fazem operações horizontais (elas cortam linhas de um banco de dados), select faz operações verticais (ela corta, ou reordena, colunas); mutate, por sua vez, faz operações dos dois tipos, já que podemos usá-la para modificar apenas algumas observações de uma variável quanto adicionar, ou remover, colunas a uma base. Por fim, group_by serve para agrupar observações em um banco, algo útil para calcular estatísticas de um grupo, algo que fazemos com summarise.\nPara exemplificar esses principais verbos de manipulação, trabalharemos com alguns dados sobre as despesas realizadas por todas as capitais brasileiras no ano de 2012, disponibilizados pela Secretaria do Tesouro Nacional em seu website.4 A base está no arquivo capitais.Rda nos materiais complementares do livro e pode ser carregada com load. Feito isto, ela ficará salva na memória no objeto capitais no formato tibble.\n\nload(\"capitais.Rda\")\n\n\n3.2.1 Filtrar linhas\nA base capitais tem 26 observações e 8 variáveis (lembre-se: você pode usar as funções View, nrow e ncol para checar isso). Começaremos a usar o pacote dplyr para selecionar e filtrar observações. Para fazer isso indicando apenas a posição das linhas, usamos a função slice - passamos um vetor para a função indicando a posição das linhas que queremos remover. Veja alguns exemplos.\n\n# Filtra apenas as cinco primeiras observações do banco capitais\nslice(capitais, 1:5)\n\n# A tibble: 5 × 8\n  regiao       uf    capital      populacao despesa_total despesa_assistencia_…¹\n  &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;                  &lt;dbl&gt;\n1 Nordeste     SE    ARACAJU         587701   1150364953.              31383656.\n2 Norte        PA    BELEM          1410430   2110549149               58105215 \n3 Sudeste      MG    BELO HORIZO…   2395785   6917817946.             172347581.\n4 Norte        RR    BOA VISTA       296959    491953689.              14018664.\n5 Centro-Oeste MS    CAMPO GRANDE    805397   2290844087.              39604187.\n# ℹ abbreviated name: ¹​despesa_assistencia_social\n# ℹ 2 more variables: despesa_saude &lt;dbl&gt;, despesa_educacao &lt;dbl&gt;\n\n# Filtra apenas a primeira e a quinta observações do banco capitais\nslice(capitais, c(1, 5))\n\n# A tibble: 2 × 8\n  regiao       uf    capital      populacao despesa_total despesa_assistencia_…¹\n  &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;                  &lt;dbl&gt;\n1 Nordeste     SE    ARACAJU         587701   1150364953.              31383656.\n2 Centro-Oeste MS    CAMPO GRANDE    805397   2290844087.              39604187.\n# ℹ abbreviated name: ¹​despesa_assistencia_social\n# ℹ 2 more variables: despesa_saude &lt;dbl&gt;, despesa_educacao &lt;dbl&gt;\n\n# Remove as 10 primeiras observacoes do banco capitais\n# e salva o resultado no objeto 'cap'\ncap &lt;- slice(capitais, -c(1:10))\nhead(cap)\n\n# A tibble: 6 × 8\n  regiao   uf    capital     populacao despesa_total despesa_assistencia_social\n  &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;                      &lt;dbl&gt;\n1 Nordeste PB    JOAO PESSOA    742478   1535075866.                  27579724.\n2 Norte    AP    MACAPA         415554    506401565.                   6743489.\n3 Nordeste AL    MACEIO         953393   1530192466.                  22125734.\n4 Norte    AM    MANAUS        1861838   2962009189.                 101830120.\n5 Nordeste RN    NATAL          817590   1325168010.                  42486957.\n6 Norte    TO    PALMAS         242070    584961477.                  20624102.\n# ℹ 2 more variables: despesa_saude &lt;dbl&gt;, despesa_educacao &lt;dbl&gt;\n\n\nEnquanto que slice remove linhas baseadas nas suas posições, a outra função para cortar horizontalmente, filter, é muito mais flexível. Com ela, podemos especificar condições para remover observações (e.g., remover observações de capitais cuja despesa total no ano de 2012 seja maior ou menor que algum valor) ou combinações de várias condições. Ela é útil, portanto, para filtrar observações com base em um ou mais critérios, como mostram os exemplos a seguir.\n\n# Filtra observacoes com populacao maior que 2 milhoes habitantes\nfilter(capitais, populacao &gt; 2000000)\n\n# A tibble: 5 × 8\n  regiao   uf    capital        populacao despesa_total despesa_assistencia_so…¹\n  &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;                    &lt;dbl&gt;\n1 Sudeste  MG    BELO HORIZONTE   2395785   6917817946.               172347581.\n2 Nordeste CE    FORTALEZA        2500194   4137588203.                78034074.\n3 Sudeste  RJ    RIO DE JANEIRO   6390290  18702324296.               565052833.\n4 Nordeste BA    SALVADOR         2710968   3618049094.                40981531.\n5 Sudeste  SP    SAO PAULO       11376685  36400104976.               919021471.\n# ℹ abbreviated name: ¹​despesa_assistencia_social\n# ℹ 2 more variables: despesa_saude &lt;dbl&gt;, despesa_educacao &lt;dbl&gt;\n\n# Filtra observacoes da regiao sul e cria um novo objeto\nsul &lt;- filter(capitais, regiao == \"Sul\")\nsul\n\n# A tibble: 3 × 8\n  regiao uf    capital       populacao despesa_total despesa_assistencia_social\n  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt;         &lt;dbl&gt;                      &lt;dbl&gt;\n1 Sul    PR    CURITIBA        1776761   5115609915.                 117962804.\n2 Sul    SC    FLORIANOPOLIS    433158   1080743166.                  33082667.\n3 Sul    RS    PORTO ALEGRE    1416714   4122115448.                 146233833.\n# ℹ 2 more variables: despesa_saude &lt;dbl&gt;, despesa_educacao &lt;dbl&gt;\n\n\nO primeiro argumento recebido por filter, assim como slice, é o nome do objeto com a base de dados (um data.frame ou tibble) e, depois, os critérios usados para filtragem. Algo essencial aqui é que podemos usar qualquer operador lógico (como ==, &gt;, &lt;, &gt;=, &lt;=, !=) para criar condições de filtragem, incluindo combinações de condições, o que é feito com o operador & (e) ou ,. Por exemplo, para filtrar observações com população maior que 500 mil e menor que 1 milhão, podemos usar qualquer uma das duas alternativas a seguir:\n\n# Filtra observacoes com populacao maior que 500 mil e menor que 1 milhao\nfilter(capitais, populacao &gt; 500000 & populacao &lt; 1000000) # ou\nfilter(capitais, populacao &gt; 500000, populacao &lt; 1000000)\n\nUm uso mais comum de filter é o de combinar critérios com base em diferentes variáveis. Imagine, por exemplo, que queremos filtrar apenas capitais que gastaram mais de R$ 250 milhões em saúde e mais de R$ 300 milhões em educação em 2012. Para isso, usamos filter da seguinte forma:\n\nfilter(capitais, \n       despesa_saude &gt; 250000000, \n       despesa_educacao &gt; 300000000)\n\nNote que, por fazer testes lógicos (que retornam TRUE ou FALSE, geralmente feitos com os operadores lógicos vistos no Capítulo 1), filter pode ser usada para realizar tarefas como remover observações com missings (função is.na()) ou valores extremos. Por exemplo, para remover observações com missings em despesa_saude, podemos usar:\n\nfilter(capitais, !is.na(despesa_saude))\n\nFinalmente, um uso de filter que não podemos deixar de mencionar é o de manter apenas observações cujos valores de uma variável pertencem a um conjunto de valores – usando, para isso, o operador %in% (visto no Capítulo 1). Por exemplo, para manter apenas capitais que pertencem às regiões Sul ou Sudeste, podemos usar:\n\nfilter(capitais, regiao %in% c(\"Sul\", \"Sudeste\"))\n\nCombinando diferentes operadores lógicos e variáveis, podemos realizar uma série de operações de filtragem. Teste as seguintes operações de filtragem para entender melhor algumas dessas possibilidades:\n\nfilter(capitais, !uf %in% c(\"RS\", \"SP\", \"MG\"))\nfilter(capitais, regiao == \"Sul\" | regiao == \"Sudeste\")\nfilter(capitais, regiao == \"Nordeste\" & populacao &lt; 1000000)\nfilter(capitais, !(regiao == \"Nordeste\" & populacao &lt; 1000000))\n\n\n\n3.2.2 Selecionar colunas\nSelecionar colunas é algo que usamos com frequência para manter, reordenar ou remover variáveis em uma análise. Para realizar este tipo de operação, usamos a função select5 do pacote dplyr (que é parte do tidyverse e, portanto, é carregado automaticamente quando executamos library(tidyverse)). Um exemplo de como usar select:\n\n# Seleciona apenas as variaveis uf, capital e populacao do banco\ncap1 &lt;- select(capitais, uf, capital, populacao)\nhead(cap1)\n\n# A tibble: 6 × 3\n  uf    capital        populacao\n  &lt;chr&gt; &lt;chr&gt;              &lt;dbl&gt;\n1 SE    ARACAJU           587701\n2 PA    BELEM            1410430\n3 MG    BELO HORIZONTE   2395785\n4 RR    BOA VISTA         296959\n5 MS    CAMPO GRANDE      805397\n6 MT    CUIABA            561329\n\n# Remove a variavel populacao\ncap2 &lt;- select(capitais, -populacao)\nhead(cap2)\n\n# A tibble: 6 × 7\n  regiao       uf    capital  despesa_total despesa_assistencia_…¹ despesa_saude\n  &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;            &lt;dbl&gt;                  &lt;dbl&gt;         &lt;dbl&gt;\n1 Nordeste     SE    ARACAJU    1150364953.              31383656.    391263344.\n2 Norte        PA    BELEM      2110549149               58105215     595930546 \n3 Sudeste      MG    BELO HO…   6917817946.             172347581.   2029533813.\n4 Norte        RR    BOA VIS…    491953689.              14018664.    105492562.\n5 Centro-Oeste MS    CAMPO G…   2290844087.              39604187.    734214086.\n6 Centro-Oeste MT    CUIABA     1302650057.              32016290.    366936045.\n# ℹ abbreviated name: ¹​despesa_assistencia_social\n# ℹ 1 more variable: despesa_educacao &lt;dbl&gt;\n\n\nO primeiro argumento da função select é o banco de dados que queremos manipular, seguido do nome das variáveis que queremos manter, sem aspas e separadas por vírgula; se quisermos excluir uma variável, colocamos um sinal de subtração, -, antes do seu nome. Além destes usos, também podemos selecionar colunas com select com base na posição delas.\n\n# Mantem apenas a 1a e a 3a colunas\nselect(capitais, 1, 3)\n\n# Exclui a 1a e a 3a colunas\nselect(capitais, -1, -3)\nselect(capitais, -c(1, 3)) # Mesmo resultado\n\nPara diminuir a quantidade de código que precisamos escrever, também podemos usar dois pontos, :, como em vetores, para selecionar colunas, o que deve ser lido como “selecione todas as colunas contidas entre a variável A e B (A:B)”:\n\n# Mantem as colunas entre uf e despesa_total\nselect(capitais, uf:despesa_total)\n\n# Mantem as colunas entre uf e populacao e a coluna despesa_saude\nselect(capitais, uf:populacao, despesa_saude)\n\nDado que podemos selecionar colunas com select, é fácil perceber que podemos reordenar, ou mesmo duplicar, colunas com ela. Para isso, basta passar para select as colunas na ordem desejada:\n\n# Reordena as colunas do banco capitais\nselect(capitais, populacao, uf, capital)\n\n# Duplica a variavel populacao\nselect(capitais, populacao, uf, capital, populacao)\n\n# Inverte a ordem das colunas\nselect(capitais, 8:1)\n\n\n3.2.2.1 Funções auxiliares a select\nE se tivermos uma base de dados muito grande, com centenas de variáveis? Como selecionar as que queremos manter sem ter que escrever o nome ou a posição de cada uma? Para casos assim, o dplyr nos fornece funções auxiliares para selecionar colunas. Destas, as principais são:\n\nstarts_with() e ends_with(), para selecionar apenas variáveis cujos nomes contenham algum prefixo ou sufixo.\n\n\n# Seleciona apenas variaveis que comecem com 'despesa'\ncap1 &lt;- select(capitais, starts_with(\"despesa\"))\nhead(cap1)\n\n# A tibble: 6 × 4\n  despesa_total despesa_assistencia_social despesa_saude despesa_educacao\n          &lt;dbl&gt;                      &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;\n1   1150364953.                  31383656.    391263344.       156571174.\n2   2110549149                   58105215     595930546        360221999 \n3   6917817946.                 172347581.   2029533813.      1169885015.\n4    491953689.                  14018664.    105492562.       110284325.\n5   2290844087.                  39604187.    734214086.       484548412.\n6   1302650057.                  32016290.    366936045.       277989807.\n\n\n\ncontains(), para selecionar apenas variáveis cujos nomes contenham alguma palavra ou caracteres.\n\n\n# Seleciona apenas variaveis que contenham 'acao'\ncap1 &lt;- select(capitais, contains(\"acao\"))\nhead(cap1)\n\n# A tibble: 6 × 2\n  populacao despesa_educacao\n      &lt;dbl&gt;            &lt;dbl&gt;\n1    587701       156571174.\n2   1410430       360221999 \n3   2395785      1169885015.\n4    296959       110284325.\n5    805397       484548412.\n6    561329       277989807.\n\n\n\nwhere(), para selecionar variáveis com base em alguma condição (e.g., manter apenas variáveis numéricas).6\n\n\n# Seleciona apenas variaveis numericas\nselect(capitais, where(is.numeric))\n\n# Seleciona variaveis numericas e 'capital'\nselect(capitais, capital, where(is.numeric))\n\n\n\n\n3.2.3 Criar e modificar variáveis\nO dplyr não serve apenas para filtrar e selecionar observações e variáveis. Com mutate, podemos alterar variáveis ou adicionar novas a um banco (elas são incluídas no fim do banco, logo após todas as demais). Podemos usá-la, por exemplo, para calcular a despesa total per capita das capitais brasileiras em 2012 – que é igual a despesas total dividida pelo número de habitantes de cada capital.\n\n# Cria a variavel despesa_per_capita\ncap1 &lt;- mutate(capitais, despesa_per_capita = despesa_total / populacao)\nselect(cap1, capital, despesa_total, populacao, despesa_per_capita)\n\n# A tibble: 26 × 4\n   capital        despesa_total populacao despesa_per_capita\n   &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;              &lt;dbl&gt;\n 1 ARACAJU          1150364953.    587701              1957.\n 2 BELEM            2110549149    1410430              1496.\n 3 BELO HORIZONTE   6917817946.   2395785              2887.\n 4 BOA VISTA         491953689.    296959              1657.\n 5 CAMPO GRANDE     2290844087.    805397              2844.\n 6 CUIABA           1302650057.    561329              2321.\n 7 CURITIBA         5115609915.   1776761              2879.\n 8 FLORIANOPOLIS    1080743166.    433158              2495.\n 9 FORTALEZA        4137588203.   2500194              1655.\n10 GOIANIA          2952160894.   1333767              2213.\n# ℹ 16 more rows\n\n\nComo mostra o exemplo anterior, só precisamos passar o nome do banco para a função, o nome da nova variável a ser criada, sem aspas, e o conteúdo dela – que pode ser o resultado de alguma operação aritmética em cima de uma das variáveis do banco. Além da economia de caracteres, a função mutate consegue usar as variáveis já existentes do banco para criar uma nova. Intuitivamente, o que ela faz é nos dar acesso às demais variáveis de forma vetorizada: se quisermos criar uma nova variável que seja igual a o logaritmo natural da variável população, portanto, mutate aplicará o log a cada elemento da variável populacao.\n\n# Cria uma variavel que e' igual ao log de populacao\ncap_log &lt;- mutate(capitais, log_populacao = log(populacao))\nselect(cap_log, capital, log_populacao)\n\n# A tibble: 26 × 2\n   capital        log_populacao\n   &lt;chr&gt;                  &lt;dbl&gt;\n 1 ARACAJU                 13.3\n 2 BELEM                   14.2\n 3 BELO HORIZONTE          14.7\n 4 BOA VISTA               12.6\n 5 CAMPO GRANDE            13.6\n 6 CUIABA                  13.2\n 7 CURITIBA                14.4\n 8 FLORIANOPOLIS           13.0\n 9 FORTALEZA               14.7\n10 GOIANIA                 14.1\n# ℹ 16 more rows\n\n\nCom mutate, também podemos criar mais de uma variável por vez:\n\n# Cria tres variaveis de uma so vez\nmutate(capitais,\n       despesa_saude_per_capita = despesa_saude / populacao,\n       despesa_educacao_per_capita = despesa_educacao / populacao,\n       despesa_assistencia_social = despesa_assistencia_social / populacao\n       )\n\nAlém de criar, podemos modificar variáveis que já temos:\n\n# Substitui a variavel de populacao\nmutate(capitais, populacao = populacao / 1000)\n\n\n\n\n\n\n\nSobrescrevendo variáveis\n\n\n\nAo criar uma variável com o mesmo nome de outra que já existe em uma base de dados, mutate sobrescreve a variável original (desde que o resultado seja salvo no mesmo objeto). Para evitar isso, podemos salvar o resultado de mutate em um novo objeto.\n\n\nPara além desses usos, mutate também pode ser usada para criar variáveis que tenham algum valor único, isto é, que se repete para todas as observações. Imagine, por exemplo, que queremos criar uma variável que indique o ano à nossa base capitais. Para isso, podemos usar mutate da seguinte forma:\n\n# Cria uma variavel indicando o ano\nmutate(capitais, ano = 2012)\n\nComo você já deve ter notado, mutate sempre retorna todas as variáveis da base original e adiciona as recém-criadas no final do banco. Podemos alterar esse comportamento por meio de dois argumentos: .keep, que indica quais variáveis queremos manter (o padrão é all); e .before ou .after. Para manter apenas as variáveis criadas, por exemplo, podemos usar .keep = \"none\":\n\nmutate(capitais, \n    ano = 2012, \n    populacao = populacao / 1000, \n    .keep = \"none\"\n)\n\n# A tibble: 26 × 2\n   populacao   ano\n       &lt;dbl&gt; &lt;dbl&gt;\n 1      588.  2012\n 2     1410.  2012\n 3     2396.  2012\n 4      297.  2012\n 5      805.  2012\n 6      561.  2012\n 7     1777.  2012\n 8      433.  2012\n 9     2500.  2012\n10     1334.  2012\n# ℹ 16 more rows\n\n\nE, para posicionar as novas variáveis antes do nome de alguma variável, usamos .before (.after funciona de maneira similar):\n\nmutate(capitais, ano = 2012, .before = regiao)\n\n# A tibble: 26 × 9\n     ano regiao     uf    capital populacao despesa_total despesa_assistencia_…¹\n   &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;         &lt;dbl&gt;                  &lt;dbl&gt;\n 1  2012 Nordeste   SE    ARACAJU    587701   1150364953.              31383656.\n 2  2012 Norte      PA    BELEM     1410430   2110549149               58105215 \n 3  2012 Sudeste    MG    BELO H…   2395785   6917817946.             172347581.\n 4  2012 Norte      RR    BOA VI…    296959    491953689.              14018664.\n 5  2012 Centro-Oe… MS    CAMPO …    805397   2290844087.              39604187.\n 6  2012 Centro-Oe… MT    CUIABA     561329   1302650057.              32016290.\n 7  2012 Sul        PR    CURITI…   1776761   5115609915.             117962804.\n 8  2012 Sul        SC    FLORIA…    433158   1080743166.              33082667.\n 9  2012 Nordeste   CE    FORTAL…   2500194   4137588203.              78034074.\n10  2012 Centro-Oe… GO    GOIANIA   1333767   2952160894.              15382878.\n# ℹ 16 more rows\n# ℹ abbreviated name: ¹​despesa_assistencia_social\n# ℹ 2 more variables: despesa_saude &lt;dbl&gt;, despesa_educacao &lt;dbl&gt;\n\n\n\n3.2.3.1 Criando variáveis condicionalmente\nOutro uso importante de mutate é em operações condicionais, como quando queremos criar uma variável que assume um determinado valor se uma condição for verdadeira (e.g., a população do município no banco capitais é maior que 500 mil habitantes) e outro valor, caso esta condicação seja falsa. Para tanto, usamos mutate em conjunto com if_else7, que também é uma função do pacote dplyr. Um exemplo:\n\n# Cria uma variavel que indica municipios com mais de 500 mil habitantes\nmutate(capitais, capitais_grandes = if_else(populacao &gt; 500000, \"Capital de grande porte\", \"Capital de menor porte\"))\n\nPara os casos em que temos múltiplas condições para testar – imagine, por exemplo, termos de criar uma variável que indique o porte das capitais em cinco faixas –, podemos usar case_when, que é uma espécie de combinação de vários if_else. Para usá-la, passamos para ela uma sequência de condições e valores, separados por vírgula, que são testadas em sequência – note que o primeiro valor que satisfizer a condição será atribuído à nova variável. Um exemplo:\n\n# Cria uma variavel que indica o porte das capitais\nporte &lt;- mutate(capitais, porte = case_when(\n  populacao &lt; 500000 ~ \"Capital de menor porte\",\n  populacao &lt; 1000000 ~ \"Capital de porte intermediario\",\n  populacao &lt; 2000000 ~ \"Capital de grande porte\",\n  populacao &lt; 5000000 ~ \"Capital de grande porte II\",\n  .default = \"Capital de grande porte III\"\n))\n\nselect(porte, capital, populacao, porte)\n\n# A tibble: 26 × 3\n   capital        populacao porte                         \n   &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;                         \n 1 ARACAJU           587701 Capital de porte intermediario\n 2 BELEM            1410430 Capital de grande porte       \n 3 BELO HORIZONTE   2395785 Capital de grande porte II    \n 4 BOA VISTA         296959 Capital de menor porte        \n 5 CAMPO GRANDE      805397 Capital de porte intermediario\n 6 CUIABA            561329 Capital de porte intermediario\n 7 CURITIBA         1776761 Capital de grande porte       \n 8 FLORIANOPOLIS     433158 Capital de menor porte        \n 9 FORTALEZA        2500194 Capital de grande porte II    \n10 GOIANIA          1333767 Capital de grande porte       \n# ℹ 16 more rows\n\n\nDuas coisas a notar: para cada condição declarada em case_when, usamos o operador ~ para indicar o valor que a variável deve assumir caso a condição seja verdadeira, ou seja, TRUE; e usamos .default para indicar o valor que a variável deve assumir caso nenhuma das condições declaradas seja verdadeira.\n\n\n\n3.2.4 Agrupar e resumir\nsummarise, assim como mutate, é usada para modificar variáveis num banco. Mas, diferentemente desta última, ela agrega as informações, retornando um resumo dos dados numa única observação. Um exemplo: calcular a população total das capitais estaduais brasileiras em 2012:\n\n# Calcula a populacao total das capitais\nsummarise(capitais, populacao_total = sum(populacao))\n\n# A tibble: 1 × 1\n  populacao_total\n            &lt;dbl&gt;\n1        43578158\n\n\nA sintaxe desta função é semelhante a da função mutate: como de praxe, passamos o nome do banco de dados para a função e, depois, o nome da variável que queremos criar seguida do seu conteúdo. Deve ficar nítido, contudo, que summarise colapsa informações em uma única linha – esse é a sua utilidade. Podemos somar valores de variáveis, calcular estatísticas descritivas (média e desvio-padrão, por exemplo), entre outros:\n\n# Calcula estatisticas da populacao das capitais estaduais em 2012\nsummarise(capitais, \n          media_populacao = mean(populacao),\n          mediana_populacao = median(populacao),\n          desvio_populacao = sd(populacao)\n          )\n\n# A tibble: 1 × 3\n  media_populacao mediana_populacao desvio_populacao\n            &lt;dbl&gt;             &lt;dbl&gt;            &lt;dbl&gt;\n1         1676083            891812         2345416.\n\n\n\n3.2.4.1 Operações dentro de grupos\nCom frequência, em vez de resumir todas as informações de um banco em uma única linha, queremos resumir as informações por grupos. Para ilustrar esse uso, vamos calcular agora a população total das capitais estaduais por região do país, isto é, somaremos a população de todas as capitais que pertencem à mesma região (i.e., o mesmo grupo). Para tanto, usamos group_by, que é uma função do dplyr que agrupa as observações de um banco de dados com base em alguma variável:\n\n# Agrupa as observacoes por regiao\ncapitais_regiao &lt;- group_by(capitais, regiao)\n\n# Calcula a populacao total por regiao\nsummarise(capitais_regiao, populacao_total = sum(populacao))\n\n# A tibble: 5 × 2\n  regiao       populacao_total\n  &lt;chr&gt;                  &lt;dbl&gt;\n1 Centro-Oeste         2700493\n2 Nordeste            11737204\n3 Norte                5017906\n4 Sudeste             20495922\n5 Sul                  3626633\n\n\nA base retornada é bem menor, e preserva apenas uma observação por região (para quem usa outros softwares de análise de dados, isto é o equivalente a agregar informações). Fundamental nesse exemplo, para calcular a população total por região usamos summarise em conjunto com group_by. Isso é necessário porque, se usássemos apenas summarise(capitais, populacao_total = sum(populacao)), o R somaria a população de todas as capitais, sem considerar a região a que elas pertencem. Dizendo de outra forma, group_by indica para a função summarise que qualquer operação de resumo de variáveis devem ser feitas dentro dos grupos indicados por ela.\nPor si só, group_by não altera nada na base de dados usada, isto é, nenhuma observação ou coluna é alterada. Ao contrário, o que ela faz é um tipo de modificação interna em uma base: é como se ela dividisse um banco em vários sub-bancos especificados por uma ou mais variáveis. Para ver se uma base foi agrupada, basta executar o seu objeto:\n\ncapitais_agrupadas_regiao &lt;- group_by(capitais, regiao)\ncapitais_agrupadas_regiao\n\n# A tibble: 26 × 8\n# Groups:   regiao [5]\n   regiao       uf    capital     populacao despesa_total despesa_assistencia_…¹\n   &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;                  &lt;dbl&gt;\n 1 Nordeste     SE    ARACAJU        587701   1150364953.              31383656.\n 2 Norte        PA    BELEM         1410430   2110549149               58105215 \n 3 Sudeste      MG    BELO HORIZ…   2395785   6917817946.             172347581.\n 4 Norte        RR    BOA VISTA      296959    491953689.              14018664.\n 5 Centro-Oeste MS    CAMPO GRAN…    805397   2290844087.              39604187.\n 6 Centro-Oeste MT    CUIABA         561329   1302650057.              32016290.\n 7 Sul          PR    CURITIBA      1776761   5115609915.             117962804.\n 8 Sul          SC    FLORIANOPO…    433158   1080743166.              33082667.\n 9 Nordeste     CE    FORTALEZA     2500194   4137588203.              78034074.\n10 Centro-Oeste GO    GOIANIA       1333767   2952160894.              15382878.\n# ℹ 16 more rows\n# ℹ abbreviated name: ¹​despesa_assistencia_social\n# ℹ 2 more variables: despesa_saude &lt;dbl&gt;, despesa_educacao &lt;dbl&gt;\n\n\nA segunda linha do output indica que a base está agrupada pela variável regiao (Groups: regiao [5]), o que significa que qualquer operação de resumo retornará uma linha para cada região do país:\n\nsummarise(capitais_agrupadas_regiao, \n          media_populacao = mean(populacao),\n          mediana_populacao = median(populacao),\n          desvio_populacao = sd(populacao)\n          )\n\n# A tibble: 5 × 4\n  regiao       media_populacao mediana_populacao desvio_populacao\n  &lt;chr&gt;                  &lt;dbl&gt;             &lt;dbl&gt;            &lt;dbl&gt;\n1 Centro-Oeste         900164.           805397           394843.\n2 Nordeste            1304134.           953393           787062.\n3 Norte                716844.           415554           644916.\n4 Sudeste             5123980.          4393038.         4868088.\n5 Sul                 1208878.          1416714           695496.\n\n\nEmbora group_by seja mais frequentemente usada em conjunto com summarise, podemos combiná-la com mutate. Imagine, por exemplo, que seja necessário adicionar uma variável à base capitais que seja igual à população das capitais de cada região, isto é, uma variável que some a população de todas as capitais de cada região (e.g., população de Porto Alegre + população de Curitiba + população de Florianópolis para a região Sul). Como fazemos isso? Usamos group_by junto de mutate:\n\n# Agrupa o banco capitais por regiao\ncap_regiao &lt;- group_by(capitais, regiao)\n\n# Soma a populacao das capitais\ncap_regiao &lt;- mutate(cap_regiao, pop_regiao = sum(populacao))\n\n# Resultado (usando select para selecionar algumas variaveis)\nselect(cap_regiao, regiao, capital, pop_regiao)\n\n# A tibble: 26 × 3\n# Groups:   regiao [5]\n   regiao       capital        pop_regiao\n   &lt;chr&gt;        &lt;chr&gt;               &lt;dbl&gt;\n 1 Nordeste     ARACAJU          11737204\n 2 Norte        BELEM             5017906\n 3 Sudeste      BELO HORIZONTE   20495922\n 4 Norte        BOA VISTA         5017906\n 5 Centro-Oeste CAMPO GRANDE      2700493\n 6 Centro-Oeste CUIABA            2700493\n 7 Sul          CURITIBA          3626633\n 8 Sul          FLORIANOPOLIS     3626633\n 9 Nordeste     FORTALEZA        11737204\n10 Centro-Oeste GOIANIA           2700493\n# ℹ 16 more rows\n\n\nEnquanto uma base estiver agrupada, todas as operações que realizarmos nela serão feitas nos grupos. Para evitar isto, usamos ungroup.\n\n# Agrupa o banco capitais por regiao\ncap_regiao &lt;- group_by(capitais, regiao)\n\n# Soma a populacao das capitais\ncap_regiao &lt;- mutate(cap_regiao, pop_regiao = sum(populacao))\n\n# Desagrupa o banco\ncap_regiao &lt;- ungroup(cap_regiao)\n\n\n\n\n\n\n\nDesagrupando bases resumidas\n\n\n\nSe usarmos summarise para criar uma base resumida por grupo, podemos usar o argumento .groups = \"drop\" para desagrupar a base resultante, sem a necessidade de usar ungroup. Exemplo:\n\ncap_regiao &lt;- group_by(capitais, regiao)\nsummarise(cap_regiao, pop_regiao = sum(populacao), .groups = \"drop\")\n\n\n\n\n\n\n3.2.5 Modificando múltiplas variáveis com mutate e summarise\nOs exemplos anteriores mostram como alterar ou resumir variáveis, agrupando elas ou não, de forma individual. No mais das vezes, é isso o que precisamos: transformar apenas uma ou duas variáveis, ou ainda resumir múltiplas informações usando group_by. Em outros casos, porém, precisaremos alterar inúmeras variáveis ao mesmo tempo: imagine, por exemplo, ter de transformar em logaritmo 50 variáveis; com o que vimos anteriormente, isso equivaleria a repetir essa transformação também 50 vezes, uma para cada variável. Algo mais ou menos assim:\n\n# Processo para transformar 50 variaveis (exemplo hipotetico)\ndf &lt;- mutate(df, var1 = log(var1),\n             var2 = log(var2),\n             var3 = log(var3),\n             ... # O codigo continuaria ate chegarmos em var50\n             )\n\nPara evitar as repetições de código, o dplyr oferece uma função auxiliar chamada across para aplicar uma operação a múltiplas variáveis. Seu uso é ligeiramente diferente do que vimos até agora:\n\n# Transforma em logaritmo todas as variaveis numericas\ncap &lt;- mutate(capitais, across(where(is.numeric), log))\nselect(cap, where(is.numeric))\n\n# A tibble: 26 × 5\n   populacao despesa_total despesa_assistencia_…¹ despesa_saude despesa_educacao\n       &lt;dbl&gt;         &lt;dbl&gt;                  &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;\n 1      13.3          20.9                   17.3          19.8             18.9\n 2      14.2          21.5                   17.9          20.2             19.7\n 3      14.7          22.7                   19.0          21.4             20.9\n 4      12.6          20.0                   16.5          18.5             18.5\n 5      13.6          21.6                   17.5          20.4             20.0\n 6      13.2          21.0                   17.3          19.7             19.4\n 7      14.4          22.4                   18.6          20.8             20.5\n 8      13.0          20.8                   17.3          19.2             19.3\n 9      14.7          22.1                   18.2          21.0             20.4\n10      14.1          21.8                   16.5          20.7             20.2\n# ℹ 16 more rows\n# ℹ abbreviated name: ¹​despesa_assistencia_social\n\n\nEm vez de especificar o nome de cada variável que será criada ou modificada, across aplica uma operação a todas as variáveis que satisfaçam uma determinada condição. De forma esquemática, toda chamada da função across contém duas partes: primeiro, indicamos quais variáveis serão modificadas (no exemplo, usamos where(is.numeric) para selecionar todas as variáveis numéricas da base); segundo, indicamos qual operação faremos nas variáveis selecionadas (no caso, usamos log).\nacross é flexível o suficiente para permitir, também, usá-la para resumir variáveis de um banco. Podemos, por exemplo, calcular a média de todas as variáveis numérica da base capitais com:\n\n# Calcula a media de todas as variaveis numericas\nsummarise(capitais, across(where(is.numeric), mean))\n\n# A tibble: 1 × 5\n  populacao despesa_total despesa_assistencia_s…¹ despesa_saude despesa_educacao\n      &lt;dbl&gt;         &lt;dbl&gt;                   &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;\n1   1676083   4176143826.              102628661.    949270809.       798449762.\n# ℹ abbreviated name: ¹​despesa_assistencia_social\n\n\nacross, como dá para imaginar, também pode ser usada junto de group_by para resumir variáveis por grupo. Para calcular a média de todas as variáveis numéricas da base capitais por região, por exemplo, usamos:\n\ncap &lt;- group_by(capitais, regiao)\nsummarise(cap, across(where(is.numeric), mean))\n\n# A tibble: 5 × 6\n  regiao       populacao despesa_total despesa_assistencia_social despesa_saude\n  &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;                      &lt;dbl&gt;         &lt;dbl&gt;\n1 Centro-Oeste   900164.   2181885013.                  29001118.    693170960.\n2 Nordeste      1304134.   2235820825.                  37825580.    664463187.\n3 Norte          716844.   1159226954.                  34821304.    264852902.\n4 Sudeste       5123980.  15869659949.                 424970795.   3077616245.\n5 Sul           1208878.   3439489509.                  99093101.    818974725.\n# ℹ 1 more variable: despesa_educacao &lt;dbl&gt;\n\n\nIndo além, across não está limitada a usarmos where para selecionar variáveis – é possível usar qualquer lógica de seleção válida para a função select, que vimos anteriormente. Desse modo, todos os seguintes usos são válidos (teste cada um deles):\n\n# Transforma em logaritmo todas as variaveis que comecem com 'despesa'\nmutate(capitais, across(starts_with(\"despesa\"), log))\n\n# Resume apenas variaveis selecionadas pelo nome\nsummarise(capitais, across(c(populacao, despesa_total), median))\n\n# Calcula valores per capita das variaveis de despesa\nmutate(capitais, across(contains(\"despesa\"), \\(x) x / populacao))\n\nNo último exemplo, usamos o que é chamado de função anônima para aplicar uma operação a todas as variáveis que satisfazem uma determinada condição, usando x como uma espécie de coringa – o que o R interpreta como sendo cada uma das variáveis selecionadas por contains(\"despesa\").8 Aqui, o \\(x) sempre deve ser colocado para indicar que queremos aplicar uma operação a cada uma das variáveis selecionadas. Para entender melhor como isso funciona, teste o seguinte código:\n\n\n3.2.6 Encadeando operações com pipes\nTODO.\n\n\n3.2.7 Outras operações úteis: ordernar, renomear e sortear\nEmbora não seja o objetivo do capítulo cobrir todas as possibilidades de manipulação de bancos de dados, o dplyr contém algumas funções que podem ser extremamente úteis em determinadas situações. Reordenar observações de acordo com os valores de uma variável (por exemplo, ordenando o banco capitais pelo tamanho de suas populações) poderia ser uma delas. Selecionar aleatoriamente apenas algumas observações de um banco para ter uma amostra, outra. Longe de esgotar as possibilidades do pacote, listamos aqui algumas funções que nos ajudam a resolver estes e outros problemas específicos (é recomendável reproduzir esses exemplos para fixar as funções de interesse). Seguem:\n\n# arrange() serve para ordenar as observacoes de um banco\nhead(arrange(capitais, populacao))\n\n# rename() serve para renomear uma variavel (nome atual vem na frente, seguido do nome antigo)\nnames(capitais) # nomes atuais\n\ncapitais |&gt; \n    rename(populacao_novo = populacao)\nnames(capitais) # novos nomes\n\ncapitais |&gt; \n    rename(populacao = populacao_novo, SAUDE = despesa_saude)\nnames(capitais) # nomes novos 2\n\n# sample_n() sorteia apenas algumas obsvervacoes de um banco\nsample_frac(capitais, 2) # sorteia duas capitais\nsample_frac(capitais, 3) # sorteia tres capitais\n\n\n\n3.2.8 Manipulando bases muito grandes\nE se quisermos manipular grandes bases de dados, grandes o suficiente para não caberem na memória RAM do computador? No Capítulo 2, vimos que podemos usar o pacote DBI junto do duckdb para ler essas bases em instâncias intermediárias – bancos de dados relacionais gerenciados pelo DuckDB. A grande vantagem dessa solução é que ela é totalmente integrada ao tidyverse: uma vez importando via DuckDB, podemos manipular uma base usando todas as funções9 do dplyr. Para ilustrar, vamos importar novamente a base de microdados de pessoas do Censo de 2010 (Pereira e Barbosa 2023) usando DBI e duckdb:\n\nlibrary(duckdb)\nlibrary(DBI)\n\ncon &lt;- dbConnect(duckdb::duckdb())\ncenso &lt;- tbl(con, \"2010_population_v0.2.0.parquet\")\n\nCom o banco importado para o DuckDB, podemos manipulá-lo normalmente com dplyr – que traduzirá nosso código em R para algo que o DuckDB entenda. Para selecionar apenas as três primeiras colunas da base de microdados, por exemplo, podemos usar select assim:\n\nselect(censo, 1:3)\n\n# Source:   SQL [?? x 3]\n# Database: DuckDB v0.9.2 [fmeireles@Linux 6.6.6-100.fc38.x86_64:R 4.3.2/:memory:]\n   code_muni code_state abbrev_state\n   &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;       \n 1 1100015   11         RO          \n 2 1100015   11         RO          \n 3 1100015   11         RO          \n 4 1100015   11         RO          \n 5 1100015   11         RO          \n 6 1100015   11         RO          \n 7 1100015   11         RO          \n 8 1100015   11         RO          \n 9 1100015   11         RO          \n10 1100015   11         RO          \n# ℹ more rows\n\n\nOu, outro exemplo, podemos usar summarise para calcular o tamanho da população brasileira em 2010 de acordo com os dados do Censo de 2010 (usando a variável V0010 da base, que contém os pesos amostrais, isto é, o quanto cada linha representa em termos de habitantes):\n\nsummarise(censo, populacao = sum(V0010))\n\n# Source:   SQL [1 x 1]\n# Database: DuckDB v0.9.2 [fmeireles@Linux 6.6.6-100.fc38.x86_64:R 4.3.2/:memory:]\n   populacao\n       &lt;dbl&gt;\n1 190755799.\n\n\nSe quisermos saber a população de cada região, basta incluir antes uma chamada à função group_by, para agrupar a base:\n\ncenso |&gt; \n    group_by(name_region) |&gt;\n    summarise(populacao = sum(V0010))\n\n# Source:   SQL [5 x 2]\n# Database: DuckDB v0.9.2 [fmeireles@Linux 6.6.6-100.fc38.x86_64:R 4.3.2/:memory:]\n  name_region  populacao\n  &lt;chr&gt;            &lt;dbl&gt;\n1 Norte        15864454.\n2 Sudeste      80364410.\n3 Centro-oeste 14058094.\n4 Nordeste     53081950.\n5 Sul          27386891.\n\n\nEm todos os casos, se quisermos salvar o resultado das operações em um objeto é necessário usar a função collect. A razão disso decorre do fato de que, ao usar dplyr com bancos de dados, o resultado das operações não é salvo na memória RAM, mas sim no DuckDB. Usando collect para trazer o resultado para a memória RAM, o código anterior ficaria assim:\n\nconsulta &lt;- censo |&gt;\n    group_by(name_region) |&gt;\n    summarise(populacao = sum(V0010)) |&gt;\n    collect()\n\nconsulta\n\n# A tibble: 5 × 2\n  name_region  populacao\n  &lt;chr&gt;            &lt;dbl&gt;\n1 Norte        15864454.\n2 Nordeste     53081950.\n3 Sul          27386891.\n4 Centro-oeste 14058094.\n5 Sudeste      80364410.\n\n\nComo se percepe pelo output do R, o objeto exibido agora é um tibble com o resultado da operação."
  },
  {
    "objectID": "03-cap.html#sec-joins",
    "href": "03-cap.html#sec-joins",
    "title": "3  Manipulação",
    "section": "3.3 Cruzar e combinar dados",
    "text": "3.3 Cruzar e combinar dados\nAté aqui, cobrimos algumas das principais operações de manipulação de dados: sabemos como chegar ao formato tidy e como filtrar linhas e selecionar, criar, modificar e resumir colunas de uma base. O que ainda não vimos é como cruzar dados de diferentes bases – algo geralmente necessário em pesquisas reais.\nPara aprendermos a fazer cruzamentos, usaremos duas bases de dados com informações sobre as cinco regiões do país. Para carregar as duas bases, chamadas de regioes e territorio e que estão no arquivo regioes.Rda10, pode usar a função load:\n\nload(\"regioes.Rda\")\n\nExecutando os objetos no console, você verá que cada tibble contém uma coluna chamada regiao, que indica o nome de cada uma das regiões do país. Importante para os nossos exemplos, a base territorio tem uma linha a menos, pois não contém a região Sul. Além disso, a grafia da região Centro-Oeste está diferente nas duas bases: na base regioes, usa-se hífen; na territorio, não.\n\n\n\nregioes\n\n# A tibble: 5 × 2\n  regiao       populacao\n  &lt;chr&gt;            &lt;dbl&gt;\n1 Norte         15864454\n2 Nordeste      53081950\n3 Centro-Oeste  14058094\n4 Sudeste       80364410\n5 Sul           27386891\n\n\n\nterritorio\n\n# A tibble: 4 × 2\n  regiao           km2\n  &lt;chr&gt;          &lt;dbl&gt;\n1 Norte        3853840\n2 Nordeste     1554291\n3 Centro Oeste 1606234\n4 Sudeste       924608\n\n\n\n\n\n3.3.1 Cruzamentos e colunas-chave\nPara cruzar dados de diferentes bases, usamos as funções _join do pacote dplyr, como left_join, inner_join, full_join e right_join. A diferença entre elas é a forma de combinar as informações das bases. Para entender melhor, vamos cruzar as duas bases de dados que temos usando left_join:\n\nleft_join(regioes, territorio, by = join_by(regiao == regiao))\n\n# A tibble: 5 × 3\n  regiao       populacao     km2\n  &lt;chr&gt;            &lt;dbl&gt;   &lt;dbl&gt;\n1 Norte         15864454 3853840\n2 Nordeste      53081950 1554291\n3 Centro-Oeste  14058094      NA\n4 Sudeste       80364410  924608\n5 Sul           27386891      NA\n\n\nA explicação do código é a seguinte: left_join combina as informações de duas bases de dados, mantendo todas as linhas da base à esquerda (no caso, regioes) e adicionando as informações da base à direita (no caso, territorio) quando houver correspondência entre as variáveis usadas para cruzar as bases (no caso, usamos regiao == regiao, passado no argumento by = join_by(regiao == regiao), para dizer que a informação contida na coluna regiao de uma base tem correspondência na coluna regiao da outra). Em outras palavras, para cada região do país na base regiões, a sua correspondente foi buscada na base territorio e, se encontrada, as informações da coluna km2 foram adicionadas à base regioes como uma nova coluna.11\nO resultado do cruzamento das bases regioes e territorio também ilustra o que acontece quando falta correspondência entre valores. Como a base territorio não contém a região Sul, a linha correspondente a essa região na base regioes ficou com valores faltantes na coluna km2; adicionalmente, dado que a grafia da região Centro-Oeste estava diferente nas duas bases, left_join não encontrou um valor de km2 na base territorios para preencher.\nO que podemos tirar de lição geral do exemplo de left_join é que para adicionarmos variáveis a um banco de dados a partir de informações específicas (Sudeste com Sudeste, Norte com Norte, etc.) precisamos de variáveis que possuam valores comuns em duas bases. Isso significa que não podemos combinar duas bases que não partilhem informações comuns, chamadas convencionalmente de colunas-chave: só foi possível cominar as bases regioes e territorio porque ambas têm uma variável com o nome das macrorregiões do Brasil, e é a partir delas que junção das bases foi feita: como Sudeste em uma das bases é igual a Sudeste na outra, o R entende que as linhas que contêm essa informação devem ser mantidas lado a lado. O que a função left_join faz, portanto, é combinar bases a partir de valores comuns de variáveis de ambas.\n\n\n\n\n\n\nColunas-chave e cruzamentos\n\n\n\nPara cruzar duas bases de dados, precisamos de variáveis que possuam valores comuns em ambas, as colunas-chave, que podem ser nomeadas de formas diferentes nas duas bases – mas precisam ser da mesma classe.\n\n\n\n\n3.3.2 Funções _join\nDe forma prática, a função left_join (e as demais funções _join) possui três argumentos principais. O primeiro indica a primeira base de dados usada na junção dos dados; a segunda, a outra base que será unida à primeira; por fim, usamos o argumento by para indicar quais variáveis são comuns nas duas bases. Esse último argumento é o principal da função, já que é com ele que informamos ao R como unir as variáveis.\nleft_join, contudo, é apenas uma das funções contidas no pacote dplyr. Além disso, ela realiza essa operação de forma específica: como o left_ indica, ela cruza valores da segunda base passada à função para a primeira. A consequência desse procedimento, desse modo, é que todas as observações do primeiro banco (regioes) são preservadas, e as da segunda base são usadas para preencher os casos comuns.\nE se quisermos manter todas as observações da base territorio e usar as da base regioes para preencher valores de população? Para além da solução mais óbvia (trocar territorio e regioes de lugar), podemos usar right_join:\n\nright_join(regioes, territorio, by = join_by(regiao == regiao))\n\n# A tibble: 4 × 3\n  regiao       populacao     km2\n  &lt;chr&gt;            &lt;dbl&gt;   &lt;dbl&gt;\n1 Norte         15864454 3853840\n2 Nordeste      53081950 1554291\n3 Sudeste       80364410  924608\n4 Centro Oeste        NA 1606234\n\n\nO resultado é autoexplicativo. O dplyr também possui outras variantes de _join úteis. Considere essas duas:\n\ninner_join(regioes, territorio, by = join_by(regiao == regiao))\n\n# A tibble: 3 × 3\n  regiao   populacao     km2\n  &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt;\n1 Norte     15864454 3853840\n2 Nordeste  53081950 1554291\n3 Sudeste   80364410  924608\n\n\n\nfull_join(regioes, territorio, by = join_by(regiao == regiao))\n\n# A tibble: 6 × 3\n  regiao       populacao     km2\n  &lt;chr&gt;            &lt;dbl&gt;   &lt;dbl&gt;\n1 Norte         15864454 3853840\n2 Nordeste      53081950 1554291\n3 Centro-Oeste  14058094      NA\n4 Sudeste       80364410  924608\n5 Sul           27386891      NA\n6 Centro Oeste        NA 1606234\n\n\nComo é possível depreender, inner_join e full_join cruzam dados de formas inteiramente diferentes: no primeiro caso, apenas linhas que possuem correspondência nas duas bases são mantidas; no segundo, todas as linhas são mantidas, mesmo que não haja correspondência entre as bases.\nEm vez de termos de memorizar cada nome de função, uma forma mais intuitiva de entender suas diferentes utilidades é por meio de um diagrama de Venn como o que segue. Nele, cada círculo representa uma base de dados, e as interseções entre eles indicam as observações que serão mantidas em cada função. O que fica patente é que left_join e right_join são complementares: o que uma função mantém, a outra exclui, assim como inner_join e full_join. A depender do caso – e do que queremos manter –, uma ou outra função será mais útil.\n\n\n\nFigura 3.2: Usos das funções _join\n\n\n\n\n3.3.3 Controlando o comportamento das funções _join\nNa maioria das vezes, o que cobrimos é o suficiente para cruzar duas bases. Algo que não vimos em maior detalhe é que, quando os nomes das colunas-chave em duas bases são diferentes, precisamos usar o argumento by de forma diferente. Para entender como, imagine que temos agora uma base chamada regioes2 que contém as mesmas informações de regioes, mas com o nome da coluna-chave diferente:\n\nregioes2 &lt;- regioes |&gt;\n    rename(regiao2 = regiao)\n\nSe tentarmos cruzar regioes2 com territorio usando o código que já vimos anteriormente, teremos um erro:\n\nleft_join(regioes2, territorio, by = join_by(regiao == regiao))\n\nError in `left_join()`:\n! Join columns in `x` must be present in the data.\n✖ Problem with `regiao`.\n\n\nNestes casos, precisamos usar o argumento by de forma diferente. Em vez de passar uma expressão regiao == regiao, vamos precisar indicar que a coluna regiao2 da base regioes2 é igual à coluna regiao da base territorio:\n\nleft_join(regioes2, territorio, by = join_by(regiao2 == regiao))\n\n# A tibble: 5 × 3\n  regiao2      populacao     km2\n  &lt;chr&gt;            &lt;dbl&gt;   &lt;dbl&gt;\n1 Norte         15864454 3853840\n2 Nordeste      53081950 1554291\n3 Centro-Oeste  14058094      NA\n4 Sudeste       80364410  924608\n5 Sul           27386891      NA\n\n\nO resultado, agora, não retorna erro – exatamente porque especifica quais colunas têm correspondência entre as bases.\nOutro alerta comum ao usar funções _join é o de multiple matches, que ocorrem quando há mais de uma correspondência entre as bases, isto é, quando uma mesma observação da base à esquerda tem mais de uma correspondência na base à direita. Para entender melhor o ponto, vamos criar uma base de dados chamada regioes3 que contém duas observações para a região Sudeste (transformando a região Sul em Sudeste com if_else):\n\nregioes3 &lt;- regioes |&gt;\n    mutate(regiao = if_else(regiao == \"Sul\", \"Sudeste\", regiao))\n\nSe tentarmos cruzar regioes3 com territorio, não teremos erro:\n\nleft_join(territorio, regioes3, by = join_by(regiao == regiao))\n\n# A tibble: 5 × 3\n  regiao           km2 populacao\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n1 Norte        3853840  15864454\n2 Nordeste     1554291  53081950\n3 Centro Oeste 1606234        NA\n4 Sudeste       924608  80364410\n5 Sudeste       924608  27386891\n\n\nO código roda sem problemas e, como resultado, as duas linhas da região Sudeste são mantidas – mas, se você rodou o código localmente, verá que o R emite uma mensagem avisando que há múltiplas correspondências. Caso esse seja o resultado que você espera da operação, basta usar o argumento relationship = \"many-to-many\", ou relationship = \"one-to-many\", para indicar que todas as correspondências devem ser mantidas:\n\nleft_join(regioes3, territorio, by = join_by(regiao == regiao), relationship = \"many-to-many\")\n\n# A tibble: 5 × 3\n  regiao       populacao     km2\n  &lt;chr&gt;            &lt;dbl&gt;   &lt;dbl&gt;\n1 Norte         15864454 3853840\n2 Nordeste      53081950 1554291\n3 Centro-Oeste  14058094      NA\n4 Sudeste       80364410  924608\n5 Sudeste       27386891  924608\n\n\nCaso isso não seja o que você espera, é necessário investigar o que está acontecendo – em geral, avisos de múltiplas correspondências podem indicar linhas duplicadas ou outros problemas em uma base quando não esperamos o aviso.\n\n\n3.3.4 Empilhando bases\nPara fechar esta seção sobre cruzamentos, vamos falar sobre outro tipo comum de combinar bases: o empilhamento, isto é, quando queremos combinar duas bases que possuem as mesmas variáveis, mas com observações diferentes. Em casos assim, usamos a função bind_rows:\n\nbind_rows(regioes, regioes3)\n\n# A tibble: 10 × 2\n   regiao       populacao\n   &lt;chr&gt;            &lt;dbl&gt;\n 1 Norte         15864454\n 2 Nordeste      53081950\n 3 Centro-Oeste  14058094\n 4 Sudeste       80364410\n 5 Sul           27386891\n 6 Norte         15864454\n 7 Nordeste      53081950\n 8 Centro-Oeste  14058094\n 9 Sudeste       80364410\n10 Sudeste       27386891\n\n\nO resultado é uma base de dados empilhada, que contém todas as observações de regioes e regioes2 – algo útil quando queremos, por exemplo, combinar dados de diferentes anos, ou de diferentes estados, em uma única base."
  },
  {
    "objectID": "03-cap.html#resumo-do-capítulo",
    "href": "03-cap.html#resumo-do-capítulo",
    "title": "3  Manipulação",
    "section": "3.4 Resumo do capítulo",
    "text": "3.4 Resumo do capítulo\nEste capítulo sobre manipulação de dados começou com uma breve introdução sobre o formato tidy, que é o formato ideal para a maioria das operações de manipulação de dados. Em seguida, vimos como filtrar linhas de uma base de dados com filter, selecionar colunas com select, criar e modificar variáveis com mutate e resumir informações com summarise. Também vimos como agrupar e resumir informações com group_by e summarise, e como modificar múltiplas variáveis com across. Por fim, vimos como cruzar dados de diferentes bases com left_join, right_join, inner_join e full_join, e como empilhar bases com bind_rows.\n\n\n\n\nPereira, Rafael H. M., e Rogério J. Barbosa. 2023. censobr: Download Data from Brazil’s Population Census (versão v0.2.0). https://CRAN.R-project.org/package=censobr.\n\n\nSpector, Phil. 2008. Data manipulation with R. Springer Science & Business Media.\n\n\nWickham, Hadley. 2014. «Tidy data». Journal of Statistical Software 59 (10): 1–23.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, e Garrett Grolemund. 2023. R for data science. \" O’Reilly Media, Inc.\"."
  },
  {
    "objectID": "03-cap.html#footnotes",
    "href": "03-cap.html#footnotes",
    "title": "3  Manipulação",
    "section": "",
    "text": "Estes dados podem ser obtidos diretamente pelo website do Ipeadata: http://www.ipeadata.gov.br/.↩︎\nO website do Datasus, do qual estes dados também podem ser obtidos, é: http://datasus.saude.gov.br/.↩︎\nMuitas vezes é confuso o uso ou não de aspas ao passar o nome de variáveis para alguma função em R. Via de regra, funções do tidyverse dispensam as aspas, algo chamado de tidy evaluation e que tem como objetivo facilitar a escrita de código.↩︎\nOs dados completos podem ser obtidos no endereço: http://www.tesouro.fazenda.gov.br/pt_PT/contas-anuais.↩︎\nNão raro podemos ter alguns problemas ao usar a função select quando estamos com o pacote MASS carregado: ambos possuem uma função chamada select, o que pode gerrar erros como Error in select(...) : unused argument (...). Nestes casos, temos duas opções: (1) descarregar o pacote MASS com detach(\"package:MASS\", unload = T), ou, (2), usar a função select com dplyr::select.↩︎\nEm versões anteriores do dplyr, a função select_if era usada como padrão para selecionar colunas com base em alguma condição. A partir da versão 1.0.0, no entanto, a função where passou a ser o padrão recomendado para esse tipo de uso.↩︎\nExiste outra função, ifelse, no R-base que cumpre a mesma função de if_else, mas é de forma geralmente mais lenta que esta. Para uma dicussão deste e de outros problemas de ifelse, ver Spector (2008).↩︎\nEntender como across e mutate funcionam por meio de funções anônimas envolve estudar tópicos como controle de fluxo e programação funcional, algo que extrapola os objetivos deste livro. Para quem quiser aprender sobre, o melhor lugar para começar é o capítulo 26 da segunda edição do livro R for Data Science, de Wickham, Çetinkaya-Rundel, e Grolemund (2023).↩︎\nAlgumas funções específicas do dplyr, na verdade, não possuem equivalentes que podem ser traduzidos para SQL, a linguagem de consulta utilizada pela maioria dos sistemas de gerenciamento de bancos relacionais. Para uma visão geral sobre os casos em que é possível usar dplyr com bancos de dados, ver a documentação do pacote dbplyr, responsável por traduzir código em R para SQL.↩︎\nÉ possível salvar mais de um objeto ou base de dados em um arquivo .Rda. Para isso, basta separar os objetos por vírgula na hora de salvá-los (e.g., save(df1, df2, df3, file = \"dados.Rda\")).↩︎\nUm insight útil da documentação do pacote dplyr é o de que as funções _join são chamadas de mutate join justamente porque funcionam como mutate(), adicionando novas colunas a uma base. Ver, por exemplo, a documentação de left_join com ?left_join.↩︎"
  },
  {
    "objectID": "04-cap.html#o-que-são-visualizações",
    "href": "04-cap.html#o-que-são-visualizações",
    "title": "4  Visualização",
    "section": "4.1 O que são visualizações?",
    "text": "4.1 O que são visualizações?\nDados podem ser apresentados em uma tabela, seja com valores brutos ou resumidos em alguma métrica, como veremos no próximo capítulo. No entanto, como argumentam Kastellec e Leoni (2007), em geral a análise gráfica é mais intuitiva. Quando bem feito, um gráfico é capaz mostrar dados de forma precisa, nítida e eficiente Healy (2018).\nPara definirmos melhor do que estamos falando, existe um debate que tende a dividir a produção de gráficos em dois ramos: a) a vizualização de dados; e, b) infográficos. Embora a primeira vista pareça não haver diferença entre as duas coisas, ela existe: a visualização de gráficos está mais para um ramo da computação, enquanto que infográficos estão mais para o campo do design (e da arte). Se você pretende apresentar dados para um público que não está habituado com a leitura de gráficos, investir em infográficos pode ajudar a comunicar ideias para pessoas sem familiaridade com dados. Porém, se você pretende exibir dados de pesquisas, é preferível investir numa boa vizualização de dados – que é o caminho que seguimos aqui. Visualização de dados, neste sentido, é a produção de gráficos usando linguagem de programação para nos ajudar a explorar e analisar dados.\nIndependente do que se entenda por visualização, há alguns princípios gerais na área. A vizualização de dados pode nos ajudar a explorar e analisar dados. Por exemplo, o quarteto de Anscombe (1973) abaixo nos mostra quatro tipo de relação entre variáveis que pode nos levar ao afirmações equivocada se olhamos apenas para relação númerica.\n\n\n\n\n\nNo exemplo a acima todas relações entre as variáveis term a correlação de 0,816. Entretanto, como vemos o gráfico (a) e o (c) podem até consideras uma relação linear, porém, no (c) tem um possível outlier. Nos gráficos (b) e (d) claramente não são relações lineares, mas também não iguais. Ou seja, a visualização nos ajuda na compreensão das relações de variáveis, assim como, na compreensão das distribuições estatísticas que fazem parte. Ou como dito Tufte (1983) “gráfico modernos podem ser muito mais que simplesmente substituiruma pequena tabela eststística”1.\nUm gráfico ele precisar adotar as três ideias acima citadas, ser claro, preciso e eficiente na apresentação dos dados. Pois, um gráfico tem que conseguir passar sua mensagem, ou sua história, sem a necessidade do auxílio de um texto.\nPara que tenhamos esse visual gráfico claro, preciso e eficiente devemos levar em conta algumas observações do Tufte (1983). Para ele gáficos excelente mostra os dados, ou seja, todo e qualquer artifício de designer deve ser para ajudar deixar os dados mais claros e não mais obscuros. Por que o leitor/espectador deve concentrar-se na substancia dos dados e não em qualquer outro elemento, como metodologia ou tecnologia usada na produção do gráfico.\nAlém do mais o gráfico deve ter capacidade levar os olhos do espectador a comparação dos diferentes pedaços de dados disponibilizados. Contundo, evitando qualquer distorção desses dados levando em consideração o proósito que você tem com os dados, e. g. exploração e descrição.\nAs lições do Tufter (1983) é amplamente utilizada no termo da moda, storytelling wich data. Tendo como perguntas centrais: que história queremos contar com nossos dados? Quem é nosso público? esse material vai ser para apresentação oral ou impressa?\nEssas e outras perguntas podem e devem serem feitas quando estamos produzindo uma vizualização de dados. Mas como este é um livro eminentemente prático não vamos entrar em detalhes sobre a teoria2."
  },
  {
    "objectID": "04-cap.html#ggplot",
    "href": "04-cap.html#ggplot",
    "title": "4  Visualização",
    "section": "4.2 GGPLOT",
    "text": "4.2 GGPLOT\nO que precisamos para fazer um gráfico no ggplot23? Considerando o ggplot, precisamos apenas determinar quais são os nosso dados e a geometria que vamos usar. e. g.:\n\n# carregando o pacote\nlibrary(haven)\nlibrary(ggplot2)\n\n# carregando os dados\ndados &lt;- read_sav(\"data/eseb_2022/eseb2022.sav\", \n                  encoding = \"latin1\")\n\n# meu primeiro grafico\nggplot(dados, aes(D01A_FX_ID)) + \n  geom_bar()\n\n\n\n\nPara gerar o gráfico acima utilizamos a base de dados do ESEB 20224. Como variável utilizamos “D01a_FX_ID” que é faixa de idade do entrevistado. Na sequência com auxilio do “+” agregamos uma camada de geometria que no caso foi a barra. Perceba que a função ggplot mapeou a base de dados e entendeu que todas variáveis dela agoa fazer parte de “ambiente” ggplot assim podemos usá-las sem indexar ao objeto dados (dados$D01A_FX_ID). Esse mapeamento já identificou os eixos que nesse caso só foi informado o eixo X na estética (Aesthetic - função aes).\nPor sua vez, a camada geometria geom_bar por padrão fazer uma contagem dos itens dentro da variável informada, que nesse caso é a faixa de idade, então ela vai fazer a contagem de quantos entrevistos tem em cada faixa. Ou seja, para fazer um gráfico de barras com a contagem de algo podemos informar os dados bruto, sem precisar fazer uma tabela de frequência previamente.\nPodemos melhora a capacidade de informar desse gráfico, para isso Temos 5 elementos que consititui a lógica de fazer graficos no R com ggplot, já usamos dois primeiros, são eles:\n\nDados - Conjutos de informações que deseja visualizar e as variáveis que serão mapeados para os atributos estéticos;\nGeometria - Camadas que contém elementos geoméricos e transformações estatísticas, no ggplot e extensões para ggplot as funções começam com prefixo “geom_”;\nEscalas - Refere-se aos valores em um espaço, mas também a cor, tamanho ou forma de atributos do gráfico, além de eixos e legendas. Começam com prefixo “scale_”;\nCoordenadas - O sistema de coordenadas utilizada no plano, por padrão coordenada cartesiana, xy. Estão disponíveis também outros sistemas de coordenadas como polar e projeção de mapas. Começam com prefixo “coord_”;\nFaceta - Para fazer gráficos em subgrupos do mesmo conjunto de dados. Começão com prefixo “facte_”;\nTemas - Controla questões de exibição, como tamanho da fonte cor do plano de fundo, rotação de texto nos eixos, grade, entre outros. Há uma função genérica chama “theme” e o prefixo para temas diversos é “theme_”.\n\nDito isto, vamos editar nosso gráfico.\nPodemos usar uma camada scale_ para exbir os valores (códigos) de todas as faixas de idade. Por exemplo scale_x_contiunous que serve para editar a escala do eixo x quando ele é continuo, no caso varia 1 a 7.\n\nggplot(dados, aes(D01A_FX_ID)) + \n  geom_bar() +\n  scale_x_continuous(breaks = 1:7)\n\n\n\n\nEmbora já seja possível ver no eixo x todos codigos 1 a 7 referente as categorias de faixa de idade, não é possível saber a qual catergoria de fato corresponde esse código. Essa base de dados ques estamos trabalhando foi construida originalmente no com spss, que para variáveis catégoricas é atribuido um código e um label, por padrão com fução read_sav são carregados os códigos dessas váriaveis. Nesse capítulo não vamos tratar de questões referente a manipulação/tratamento de dados, mas com a função print_labels do pacote haven podemos saber quais são os labels de cada catégoria.\n\nprint_labels(dados$D01A_FX_ID)\n\n\nLabels:\n value        label\n     1 16 e 17 anos\n     2 18 a 24 anos\n     3 25 a 34 Anos\n     4 35 a 44 Anos\n     5 45 a 54 Anos\n     6 55 a 64 anos\n     7    65 e mais\n\n\nPodemos usar essa informação para editar nosso gráfico. Para isso dentro do aes vamos transformar nossa variável de interesse em texto, e no lugar de usar uma escala continua vamos usar uma escala discreta para alterar os valores do eixo x.\n\nggplot(dados, aes(as.character(D01A_FX_ID))) + \n  geom_bar() +\n  scale_x_discrete(labels = c(\"1\" = \"16-17\",\n                              \"2\" = \"18-24\",\n                              \"3\" = \"25-34\", \n                              \"4\" = \"35-44\",\n                              \"5\" = \"45-54\",\n                              \"6\" = \"55-64\",\n                              \"7\" = \"65+\"))\n\n\n\n\nPara altera nomes dos eixos, titulos e subtitulos, por exemplo, podemos usar a função labs em mais uma camada.\n\nggplot(dados, aes(as.character(D01A_FX_ID))) + \n  geom_bar() +\n  scale_x_discrete(labels = c(\"1\" = \"16-17\",\n                              \"2\" = \"18-24\",\n                              \"3\" = \"25-34\", \n                              \"4\" = \"35-44\",\n                              \"5\" = \"45-54\",\n                              \"6\" = \"55-64\",\n                              \"7\" = \"65+\")) +\n  labs(title = \"Entrevistados por faixa de idade\",\n       subtitle = \"ESEB - 2022\",\n       x = \"Faixa de Idade\",\n       y = \"N\") \n\n\n\n\nEssa grade por trás das barras não traz nenhuma informação relevante para esse gráfico, assim como a cor de fundo. Então podemos retirar esses elementos deixando o gráfico mais limpo em termos de informação desnecessaria para isso podemos aplicar um tema diferente do padrão do ggplot.\n\nggplot(dados, aes(as.character(D01A_FX_ID))) + \n  geom_bar() +\n  scale_x_discrete(labels = c(\"1\" = \"16-17\",\n                              \"2\" = \"18-24\",\n                              \"3\" = \"25-34\", \n                              \"4\" = \"35-44\",\n                              \"5\" = \"45-54\",\n                              \"6\" = \"55-64\",\n                              \"7\" = \"65+\")) +\n  labs(title = \"Entrevistados por faixa de idade\",\n       subtitle = \"ESEB - 2022\",\n       x = \"Faixa de Idade\",\n       y = \"N\") +\n  theme_classic()\n\n\n\n\nDependendo do uso que vamos fazer seja preferivél ter os valores da quantidade de entrevistados direto em cada barra, assim, podemos aplicar mais uma camada com a função geom_text\n\nggplot(dados, aes(as.character(D01A_FX_ID))) + \n  geom_bar() +\n  scale_x_discrete(labels = c(\"1\" = \"16-17\",\n                              \"2\" = \"18-24\",\n                              \"3\" = \"25-34\", \n                              \"4\" = \"35-44\",\n                              \"5\" = \"45-54\",\n                              \"6\" = \"55-64\",\n                              \"7\" = \"65+\")) +\n  labs(title = \"Entrevistados por faixa de idade\",\n       subtitle = \"ESEB - 2022\",\n       x = \"Faixa de Idade\",\n       y = \"N\") +\n  geom_text(stat = \"count\", aes(label = ..count..), \n            vjust=-0.2) + \n  theme_classic()\n\n\n\n\nCom estamos usando os micro-dados e toda operação aritimetica está sendo feita dentro do ambiente do ggplot, é necessário informa na função geom_text qual é a estátistica que está sendo feita que nesse caso é contagem (o padrão da função geom_bar). Nesse caso a estética é o valor dessa contagem que é recuperado pelo operador “..count..”, foi adcionado um ajustamento vertical, que quando possitivo os valores são platados mais próximo do eixo x e negativo mais longe do eixo de referência (vjust eixo x, hjust eixo y).\nSuponha que em seu projeto de visualização de dados as informações do eixo y sejam desnecessária uma vez que já está direto acima da barra. Podemos usar nossa função genérica theme para fazer essa edição. Como ja estamos usando um tema, a camada com a função genérica vai logo após o tema em uso.\n\nggplot(dados, aes(as.character(D01A_FX_ID))) + \n  geom_bar() +\n  scale_x_discrete(labels = c(\"1\" = \"16-17\",\n                              \"2\" = \"18-24\",\n                              \"3\" = \"25-34\", \n                              \"4\" = \"35-44\",\n                              \"5\" = \"45-54\",\n                              \"6\" = \"55-64\",\n                              \"7\" = \"65+\")) +\n  labs(title = \"Número de entrevistados por faixa de idade\",\n       subtitle = \"ESEB - 2022\",\n       x = \"Faixa de Idade\",\n       y = \"N\") +\n  geom_text(stat = \"count\", aes(label = ..count..), \n            vjust=-0.2) + \n  theme_classic() +\n  theme(axis.line.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.title.y = element_blank())\n\n\n\n\nObservem que mesmo mantendo na função labs y = “N”, esse elemento não fica no gráfico porque foi subtituído na função theme por um elemento em branco - element_blanc no argumento axis.title.y. Bem, todos elementos de exibição do gráfico pode ser controlado por essa função theme, inclusive pode ser usada para você criar o próprio tema.\nVamos agora fazer um novo gráfico com a mesma geometria (barra), sendo que com os dados já agregado em algum nível. Para isso vamos usar os dados do tamanho da população do Brasil por Estado, a partir da parcial do censo 20225.\n\noptions(scipen = 999)\n\ndados &lt;- read.csv2(\"data/POP2022_Brasil.csv\", fileEncoding = \"latin1\")\n\nggplot(dados, aes(reorder(Unidades_Federacao, POPULACAO), POPULACAO)) + \n  geom_bar(stat = \"identity\") +\n  labs(title = \"População Brasileira por Estado\",\n       subtitle = \"Censo - 2022 (IBGE)\",\n       y = \"N\") +\n  coord_flip() +\n  theme_classic() +\n  theme(axis.line.y = element_blank(),\n        axis.title.y = element_blank())\n\n\n\n\nRepetimos basicamente o mesmo código do gráfico com os dados do ESEB. As principais alterações foram: 1) no aes, foi incluir um valor para y (POPULACAO), e 2) na geometria (geom_bar) incluir o argumento stat igual a “identity”, que informa que não é necessário fazer qualquer transformação no dado, ele vai se usado do jeito que veio.\nNo mais, algumas alterações foram feitas para melhorar a visualização: 1) no elemento x foi incluido uma função reorder que reodena os x por um valor qualquer, no caso escolhemos o próprio valor da população contido na variável “POPULACAO”; 2) como os labels das unidade da federação são relativamente grandes usamos a função coor_flip para que os labels que iam aparacer orginalmente no eixo x, seja exibido no eixo y, o mesmo com o eixo y, ou seja, uma mudança nos eixos.\nObserve que na nossa função genérica de gráfico excluimos os dois argumento refentes a ticks (traços) e texto do eixo y, com isso o gráfico voltou a exibir o rotulo de cada coluna (unidade da federação) e os respectivos traços.\nAlém do gráfico de barras que exploramos o ggplot tem outros tipos de gráficos (geometrias) nativas, que já vem inclusa quando instalamos o pacote, tais como: linhas - geom_line, barra de erro - geom_errobar, disperção - geom_point, histograma - geom_histogram entre outras.\n\n\n\n\n\n\nGGPLOT - Extensões\n\n\n\nAlém das geometria nativas você adicionar outras geometrias e temas, por exemplo. Para isso você pode criar suas próprias extensões ou instalar a que outros desenvolvedores fizeram. Para instalar você pode procurar pacotes. O tidyverse organiza e disponiliza informações para coleção bastatante rica: https://exts.ggplot2.tidyverse.org/gallery/6. Que por exemplo o gganimate para fazer gráficos animanos em gif, o ggdag para desenhar relações clausais, ou o ggpol para plotar seus em formato de parlamentos.\n\n\nVamos usar os dados anterioes para criar um mapa, onde cada estado será colorido por pela quantidade de populacação identificada pelo IBGE. Mas para isso vamos precisar ter um objeto com as informações geográficas (geolocalização) dos estados. Temos na nossa pasta data tem um arquivo que tem essas informações, o shp_uf_brasil.Rds. Mas você poderia pra o caso brasileiro o pacote geobr. De todo modo se você quiser trabalhar com outras geolocalização é só procurar um pacote específico, e se não tiver, procurar o shapesfile (shp) da região que precisa.\nPara criar o nosso mapa vamos unir (fazer um merge) as informações geografica do objeto estado com as informações do censo do objeto dados. Depois vamos usar a geometiria geom_sf para criar o mapa.\n\nestados &lt;- readRDS(\"data/shp_uf_brasil.Rds\")\n\nestados &lt;- merge(estados, dados,\n                 by.x = \"name_state\", \n                 by.y = \"Unidades_Federacao\")\n\nggplot(estados) +\n  geom_sf(aes(fill = POPULACAO)) +\n  scale_fill_gradient(low = \"#56B1F7\", high =  \"#132B43\") +\n  theme_bw()\n\n\n\n\nCom essa geometria geom_sf não precisamos atribuir um x ou um y na aes, pois, x e y serão as coordenadas geográficas contidas na variável “geometry” do nosso objeto estados que é da class sf. Então atribuímos apenas um fill para colorir os estados, neste caso, em uma escala continua porque a váriavel população é continua. Se fosse uma variável categórica o ggplot compreenderia que a escala de cores seria discreta, uma cor para cada categoria.\n\n\n\n\n\n\nErros\n\n\n\nSe eventualmente ocorrer um erro referente a função geom_sf - error in compute_layer(), ou similar. Carregue o pacote “sf” - library(sf), considerando que já está instalado, se não instale primeiro. Pois, esse é o pacote que originalmente criou a geometria geom_sf e outras funções para trabalhar com dados geolocalizados."
  },
  {
    "objectID": "04-cap.html#colorindo",
    "href": "04-cap.html#colorindo",
    "title": "4  Visualização",
    "section": "4.3 Colorindo",
    "text": "4.3 Colorindo\n\n\n\n\nHealy, Kieran. 2018. Data visualization: a practical introduction. Princeton University Press.\n\n\nKastellec, Jonathan P, e Eduardo L Leoni. 2007. «Using graphs instead of tables in political science». Perspectives on politics 5 (4): 755–71.\n\n\nTufte, Edward R. 1983. «The visual display of». Quantitative Information, 13.\n\n\nWickham, Hadley. 2016. ggplot2: Elegant Graphics for Data Analysis. Springer.\n\n\nWilkinson, Leland. 2012. The grammar of graphics. Springer."
  },
  {
    "objectID": "04-cap.html#footnotes",
    "href": "04-cap.html#footnotes",
    "title": "4  Visualização",
    "section": "",
    "text": "tradução livre↩︎\nVer: ……….↩︎\nnormalmente só falamos ggplot quando estamos falando do pacote ggplot2↩︎\nDisponibilizadas pelo https://www.cesop.unicamp.br/↩︎\nLançada pelo IBGE em junho de 2023↩︎\nhttps://exts.ggplot2.tidyverse.org/gallery/↩︎"
  },
  {
    "objectID": "05-cap.html#estatísticas-descritivas",
    "href": "05-cap.html#estatísticas-descritivas",
    "title": "5  Análise",
    "section": "5.1 Estatísticas descritivas",
    "text": "5.1 Estatísticas descritivas\nComo vimos no capítulo anterior, uma das primeiras coisas que fazemos ao analisar um conjunto de dados é inspecionar suas características, o que pode ser feito por meio de gráficos. Há um problema, no entanto: gráficos não nos oferecem descrições precisas das características de uma variável – o que normalmente é demandado em publicações acadêmicas. Embora gráficos sejam ferramentas essenciais em qualquer projeto, saber como resumir as características de uma variável de forma precisa é um complemento necessário.\nA chave para descrever de forma precisa nossas variáveis é usarmos algumas medidas numéricas que resumam a distribuição dos valores que elas assumem. Pense, por exemplo, em uma variável que meça a altura de um grupo de pessoas. Os valores dessa variável poderiam ser estes:\n\n\n\n\nTabela 5.1: Altura fictícia de 6 pessoas (em metros)\n\n\nPessoa\nAltura (metros)\n\n\n\n\n1\n1.60\n\n\n2\n1.70\n\n\n3\n1.75\n\n\n4\n1.80\n\n\n5\n1.85\n\n\n6\n1.90\n\n\n\n\n\n\n\n\nUma forma de descrever essa informação seria, naturalmente, listar cada uma das alturas individuais, isto é, dizer que a pessoa 1 tem 1,60, a 2 tem 1,70, e assim por diante. Caso tenhamos muitas observações, contudo, a descrição deixa de fazer sentido e, no lugar, precisamos de algo mais sintético. Um exemplo? Note que a altura máxima que vimos acima é 1.9 e a mínima é 1.6. Essas duas medidas já nos dão uma ideia geral de que todas as informações estão contidas entre estes limites mínimo e máximo. Mais, podemos calcular a média das alturas, que é 1.8, para ter uma ideia de qual é altura “típica” de uma pessoa da turma; e, finalmente, podemos calcular o desvio padrão, que é 0.11, para ter uma ideia do quanto as alturas individuais se distanciam da média. Munido dessas informações, temos uma boa ideia da distribuição das alturas do grupo de pessoas, tenha ele 6 ou 600 integrantes.\nNa Estatística, tais medidas são conhecidas como estatísticas descritivas e são usadas tanto para descrever tendências centrais (e.g., média, mediana, moda) quanto para descrever a dispersão dos valores (e.g., desvio padrão, variância, mínimo, máximo, etc.). A depender do tipo de variável que estamos analisando, algumas dessas medidas são mais adequadas que outras: para variáveis numéricas (i.e., contínuas), por exemplo, a média e o desvio padrão são medidas geralmente são utilizadas; já para variáveis categóricas (e.g., sexo), a moda, isto é, o valor mais frequente, é uma medida útil.\n\n\n\n\n\n\nEstatísticas descritivas\n\n\n\nUma estatística descritiva é um número único que condensa uma propriedade de uma variável (Kellstedt e Whitten 2018, cap. 6). Estatísticas descritivas comuns incluem a média, a mediana, a moda, o desvio padrão, a variância, o valor mínimo, o valor máximo, entre outros.\n\n\nEm R, podemos calcular essas e outras estatísticas descritivas usando funções específicas. Para exemplificar, vamos calcular algumas estatísticas descritivas para a variável pct_gastos da base gov. Para calcular a média, que já vimos no Capítulo 3, usamos a função mean():1\n\nmean(gov$pct_gastos)\n\n[1] 27.10714\n\n\nOutras estatísticas descritivas podem ser calculadas de forma similar. Seguem algumas das mais comuns:\n\nmedian(): mediana, que é o valor que divide a distribuição em duas partes iguais;\nvar(): variância, que é a média dos quadrados dos desvios em relação à média;\nsd(): desvio padrão, que é a raiz quadrada da variância;\nmin(): mínimo;\nmax(): máximo;\nrange(): intervalo, que é a diferença entre o máximo e o mínimo;\n\nPor exemplo:\n\nmedian(gov$pct_gastos)\n\n[1] 27.84\n\nsd(gov$pct_gastos)\n\n[1] 15.68703\n\nmin(gov$pct_gastos)\n\n[1] 2.62\n\nmax(gov$pct_gastos)\n\n[1] 61.72\n\n\nCom esse conjunto de estatísticas calculadas, já temos uma boa ideia da distribuição da variável pct_gastos da base gov. Para termos uma ideia mais completa, podemos usar a função summary(), que calcula várias estatísticas descritivas de uma variável de uma só vez:\n\nsummary(gov$pct_gastos)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2.62   16.25   27.84   27.11   36.35   61.72 \n\n\nOs números anteriores formam uma espécie de retrato: média e mediana indicam que o centro da distribuição está em torno de 27, isto é, candidaturas típicas tendem a gastar em torno desse valor percentual; valores mínimo e máximo são de 2.62 e 61.72, respectivamente, o que nos mostra os limites de gastos registrados nos nossos dados; e, finalmente, os primeiro e terceiro quantis mostram que a maioria dos gastos percentuais registrados na nossa base está situada entre os valores de 16.245 e 36.355.\n\n\n\n\n\n\nQuantis\n\n\n\nQuantis, ou quartis, são estatísticas descritivas que dividem uma distribuição em quatro partes. O primeiro quartil, às vezes chamado de Q1, divide todos os valores de uma variável em duas partes iguais, sendo que 25% dos valores estão abaixo dele e, 75%, acima; Q3, por sua vez, é o valor que divide a distribuição com 75% dos valores abaixo dele e 25% acima; e, finalmente, o Q2 é a mediana, que divide a distribuição com 50% dos valores acima, e 50% abaixo, dela.\n\n\n\n5.1.1 Calculando múltiplas estatísticas descritivas\nCalcular várias estatísticas de uma só vez é algo normal em pesquisas. Por exemplo, suponha que queremos calcular a média e o desvio padrão das variáveis pct_gastos e pct_votos da base gov. Para tanto, podemos usar a função summarise() do pacote dplyr, que já vimos no Capítulo 3:\n\ngov |&gt;\n    summarise(media_gastos = mean(pct_gastos),\n              desvio_gastos = sd(pct_gastos),\n              media_votos = mean(pct_votos),\n              desvio_votos = sd(pct_votos))\n\n# A tibble: 1 × 4\n  media_gastos desvio_gastos media_votos desvio_votos\n         &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n1         27.1          15.7        28.2         22.8\n\n\n\n\n5.1.2 Estatísticas descritivas por grupo\nOutra tarefa comum é calcular estatísticas descritivas de uma variável para grupos específicos. Imagine, por exemplo, que queremos calcular a média e desvio padrão das variáveis pct_gastos e pct_votos para cada um dos três estados incluídos na base gov. Como fazemos isso? Simples: por meio das funções group_by() e summarise() do pacote dplyr, que já vimos no Capítulo 3. Depois de agruparmos a base por uf, calculamos as estatísticas para cada grupo com summarise:\n\ngov |&gt;\n    group_by(uf) |&gt;\n    summarise(media_gastos = mean(pct_gastos),\n              desvio_gastos = sd(pct_gastos),\n              media_votos = mean(pct_votos),\n              desvio_votos = sd(pct_votos))\n\n# A tibble: 4 × 5\n  uf    media_gastos desvio_gastos media_votos desvio_votos\n  &lt;chr&gt;        &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n1 GO            24.6          14.6        24.7         19.6\n2 MG            28.9          11.6        32.8         24.6\n3 PR            31.7          26.0        32.6         34.2\n4 RJ            24.8          16.5        24.8         24.6\n\n\nNote que a principal diferença aqui foi o uso de group_by(uf) para dizer ao R que operações de resumo deveriam ser feitas para cada um dos grupos definidos pela variável uf.\n\n\n5.1.3 Transformando tabelas de estatísticas descritivas\nQuando calculamos estatísticas descritivas para grupos, o resultado é uma tabela com uma linha para cada grupo e uma coluna para cada estatística calculada. Se quisermos alterar essa disposição de informações, podemos usar os princípios tidy que vimos no Capítulo 3. Por exemplo, para obtermos uma tabela com uma linha para cada estatística calculada e uma coluna para cada grupo, podemos usar as funções pivot_longer() e pivot_wider() do pacote tidyr em duas etapas. Primeiro, usamos pivot_longer() para alongar as colunas com estatísticas:\n\ntab_longa &lt;- gov |&gt;\n    group_by(uf) |&gt;\n    summarise(media_gastos = mean(pct_gastos),\n              desvio_gastos = sd(pct_gastos),\n              media_votos = mean(pct_votos),\n              desvio_votos = sd(pct_votos)) |&gt;\n    pivot_longer(cols = -uf, names_to = \"estatistica\", values_to = \"valor\")\n\ntab_longa\n\n# A tibble: 16 × 3\n   uf    estatistica   valor\n   &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1 GO    media_gastos   24.6\n 2 GO    desvio_gastos  14.6\n 3 GO    media_votos    24.7\n 4 GO    desvio_votos   19.6\n 5 MG    media_gastos   28.9\n 6 MG    desvio_gastos  11.6\n 7 MG    media_votos    32.8\n 8 MG    desvio_votos   24.6\n 9 PR    media_gastos   31.7\n10 PR    desvio_gastos  26.0\n11 PR    media_votos    32.6\n12 PR    desvio_votos   34.2\n13 RJ    media_gastos   24.8\n14 RJ    desvio_gastos  16.5\n15 RJ    media_votos    24.8\n16 RJ    desvio_votos   24.6\n\n\nTudo o que fizemos aqui foi indicar que queremos manter a coluna uf e alongar as demais (cols = -uf) para que cada uma delas vire uma linha (names_to = \"estatistica\") e que seus valores sejam posicionados em uma nova coluna (values_to = \"valor\"). Isso feito, podemos usar pivot_wider() para transformar a coluna uf em múltiplas colunas, uma para cada estado:\n\ntab_final &lt;- tab_longa |&gt;\n    pivot_wider(names_from = uf, values_from = valor)\n\ntab_final\n\n# A tibble: 4 × 5\n  estatistica      GO    MG    PR    RJ\n  &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 media_gastos   24.6  28.9  31.7  24.8\n2 desvio_gastos  14.6  11.6  26.0  16.5\n3 media_votos    24.7  32.8  32.6  24.8\n4 desvio_votos   19.6  24.6  34.2  24.6\n\n\nNem sempre é intuitivo saber quando usar pivot_longer() e pivot_wider(), e em qual ordem, mas, com um pouco de prática, é fácil pegar os padrões mais recorrentes de transformação de acordo com os princípios tidy – caso queira praticar mais um pouco, os exercícios do Capítulo 3 são um bom lugar para começar.\n\n\n5.1.4 Exportando resultados\nUma vez calculadas algumas estatísticas descritivas, a sequência natural é exportá-las para um arquivo de texto ou planilha para uso posterior. Uma forma fácil de fazer isso é por meio da função write_csv() do pacote readr, que já vimos no Capítulo 2:\n\ntab_final |&gt;\n    write_csv(\"minha_tabela.csv\")\n\nO ponto negativo dessa abordagem é que, por padrão, a função write_csv() não aplica nenhuma formatação ao resultado. É por essa razão que sugerimos usar o pacote gt – um pacote que facilita a criação modular de tabelas em HTML, LaTeX ou documentos de texto – para salvar estatísticas descritivas. Exportar a tabela anterior com gt é questão de aplicar a função gt(), para criar um objeto gt, e, em seguida, usar a função gtsave() para exportá-lo em formato HTML:\n\ntab_final |&gt;\n    gt() |&gt;\n    gtsave(\"minha_tabela.html\")\n\nAbrindo o arquivo minha_tabela.html em um navegador de internet (clicando no arquivo com o botão direito do mouse e selecionando a opção “Abrir com…”), obtemos o seguinte resultado:\n\n\n\n\n\n\n  \n    \n      estatistica\n      GO\n      MG\n      PR\n      RJ\n    \n  \n  \n    media_gastos\n24.56250\n28.87333\n31.74667\n24.84750\n    desvio_gastos\n14.62260\n11.61861\n25.97810\n16.50908\n    media_votos\n24.70000\n32.83000\n32.65000\n24.85000\n    desvio_votos\n19.55345\n24.55244\n34.23450\n24.60989\n  \n  \n  \n\n\n\n\nA tabela exportada tem uma boa formatação, ainda que falte ajustar detalhes como o excesso de casas decimais e a ausência de título e fonte. Para esses e outros ajustes finos, o pacote gt oferece uma série de funções auxiliares. Por exemplo, para manter apenas uma casa decimal e adicionar títulos, podemos usar as funções fmt_number(), tab_header() e tab_source_note() da seguinte forma:\n\ntab_final |&gt;\n    gt() |&gt;\n    fmt_number(decimals = 1) |&gt;\n    tab_header(title = \"Estatísticas descritivas de gastos e votos por estado\") |&gt;\n    tab_source_note(source_note = \"Fonte: TSE.\")\n\n\n\n\n\n  \n    \n      Estatísticas descritivas de gastos e votos por estado\n    \n    \n    \n      estatistica\n      GO\n      MG\n      PR\n      RJ\n    \n  \n  \n    media_gastos\n24.6\n28.9\n31.7\n24.8\n    desvio_gastos\n14.6\n11.6\n26.0\n16.5\n    media_votos\n24.7\n32.8\n32.6\n24.9\n    desvio_votos\n19.6\n24.6\n34.2\n24.6\n  \n  \n    \n      Fonte: TSE.\n    \n  \n  \n\n\n\n\nE, usando um pouco de manipulação de dados, conseguimos renomear a coluna de estatisticas e seus valores para algo mais adequado:\n\ntab_formatada &lt;- tab_final |&gt;\n    rename(Estatística = estatistica) |&gt;\n        mutate(Estatística = case_when(Estatística == \"media_gastos\" ~ \"Média de gastos\",\n                                       Estatística == \"desvio_gastos\" ~ \"Desvio de gastos\",\n                                       Estatística == \"media_votos\" ~ \"Média de votos\",\n                                       Estatística == \"desvio_votos\" ~ \"Desvio de votos\")) |&gt;\n    gt() |&gt;\n    fmt_number(decimals = 1) |&gt;\n    tab_header(title = \"Estatísticas descritivas de gastos e votos por estado\") |&gt;\n    tab_source_note(source_note = \"Fonte: TSE.\") \n\ntab_formatada\n\n\n\n\n\n  \n    \n      Estatísticas descritivas de gastos e votos por estado\n    \n    \n    \n      Estatística\n      GO\n      MG\n      PR\n      RJ\n    \n  \n  \n    Média de gastos\n24.6\n28.9\n31.7\n24.8\n    Desvio de gastos\n14.6\n11.6\n26.0\n16.5\n    Média de votos\n24.7\n32.8\n32.6\n24.9\n    Desvio de votos\n19.6\n24.6\n34.2\n24.6\n  \n  \n    \n      Fonte: TSE.\n    \n  \n  \n\n\n\n\nA tabela resultante tem uma formatação muito melhor. Podemos agora exportá-la para um documento de texto, no formato RTF:\n\ntab_formatada |&gt;\n    gtsave(\"minha_tabela.rtf\")\n\nO arquivo salvo adapta a formatação que vimos acima para o formato de texto que pode ser aberto em qualquer editor – o que facilita o trabalho de incluir resultados do R em um documento de Word, por exemplo.\n\n\n5.1.5 Criando tabelas automaticamente com modelsummary\nO pacote gt, visto anteriormente, permite inúmeras customizações em uma tabela, várias delas que sequer mostramos2 – o custo é ter de aprender a usar uma série de funções e argumentos. Para quem não quer se preocupar com isso, uma alternativa econômica é usar o pacote modelsummary, que calcula estatísticas descritivas e cria tabelas automaticamente a partir de uma base de dados. Para criar uma tabela descritiva da base gov, por exemplo, basta usar a função datasummary_skim() como fizemos abaixo:\n\ndatasummary_skim(gov)\n\n\n\n\n\nUnique (#)\nMissing (%)\nMean\nSD\nMin\nMedian\nMax\n\n\n\n\n\npct_gastos\n14\n0\n27.1\n15.7\n2.6\n27.8\n61.7\n\n\n\npct_votos\n14\n0\n28.2\n22.8\n2.1\n25.7\n69.6\n\n\n\n\n\n\n\n\nComo é possível notar, datasummary_skim() automaticamente detecta quais colunas na nossa base são numéricas e, partir disso, calcula e reporta uma série de estatísticas úteis, como número de linhas; números de missings; média; entre outas. Para termos mais controle sobre o resultado, podemos usar a função datasummary() especificando quais variáveis e quais estatísticas queremos calcular:\n\ndatasummary(pct_gastos + pct_votos ~ Mean + Median, data = gov)\n\n\n\n\n\nMean\nMedian\n\n\n\n\npct_gastos\n27.11\n27.84\n\n\npct_votos\n28.19\n25.72\n\n\n\n\n\n\n\nNo código anterior, usamos pct_gastos + pct_votos para indicar quais variáveis da base gov deveriam ser incluídas na tabela, e Mean + Median para indicar quais estatísticas deveriam ser calculadas para cada uma delas. Adaptando um pouco essa fórmula, podemos criar uma tabela com estatísticas descritivas para cada um dos estados da base gov:\n\ndatasummary(pct_gastos + pct_votos ~ Mean * uf, data = gov)\n\n\n\n\n\nGO\nMG\nPR\nRJ\n\n\n\n\npct_gastos\n24.56\n28.87\n31.75\n24.85\n\n\npct_votos\n24.70\n32.83\n32.65\n24.85\n\n\n\n\n\n\n\nO resultado, agora, é uma tabela com uma linha para cada estado e uma coluna para cada estatística calculada. Para exportar essa tabela para um arquivo de texto, usamos apenas um argumento adicional, output:\n\ndatasummary(pct_gastos + pct_votos ~ Mean * uf, data = gov, output = \"tabela.txt\") # Texto\ndatasummary(pct_gastos + pct_votos ~ Mean * uf, data = gov, output = \"tabela.rtf\") # RTF\ndatasummary(pct_gastos + pct_votos ~ Mean * uf, data = gov, output = \"tabela.html\") # HTML\n\nUma nota final: ainda que tenha opções de customização que não cobrimos aqui, modelsummary não produz resultados iniciais tão bem acabados quanto o gt, mas é uma boa ferramenta para criar tabelas descritivas de forma rápida. A depender do uso, uma opção é começar a exploração de dados usando datasummary() para, se preciso, refinar resultados para exportação com gt() e suas funções auxiliares."
  },
  {
    "objectID": "05-cap.html#modelos-de-regressão-linear-simples",
    "href": "05-cap.html#modelos-de-regressão-linear-simples",
    "title": "5  Análise",
    "section": "5.2 Modelos de regressão linear simples",
    "text": "5.2 Modelos de regressão linear simples\nEm análises de dados, é algo comum querermos investigar se existe relação entre duas ou mais variáveis numéricas. Um exemplo: será que quem gasta mais em sua campanha eleitoral faz mais votos? Com os dados das eleições para governos de estado na base gov, podemos ilustrar essa relação com um gráfico de dispersão:\n\ngov |&gt;\n    ggplot(aes(x = pct_gastos, y = pct_votos)) +\n    geom_point() +\n    labs(x = \"Gastos (%)\", y = \"Votos (%)\")\n\n\n\n\nComo se depreende do gráfico, parece haver uma associação positiva entre gasto de campanha e votos: pontos com maiores valores na variável pct_gastos têm maiores valores em pct_votos, no geral. Essa é uma relação sugestiva, mas quão forte ela é? Será que é algo que aconteceu por acaso?\nAinda que gráficos sejam úteis para nos ajudar a detectar padrões em meio a pontos dispersos, o fato é que eles não servem para responder a questões como as feitas acima. Em vez disso, precisamos de uma ferramenta para estimar, de forma precisa, o efeito predito de gastar mais ou menos na campanha no número de votos obtidos pelas candidaturas. Dito de outro modo, precisamos de um modelo.\nAntes de entrarmos em maiores detalhes, vamos supor que um bom modelo, nesse caso, seja uma reta. Podemos começar traçando uma arbitrariamente nos dados para ver o resultado.\n\n\n\n\n\nFigura 5.1: Relação entre gastos de campanha e votos\n\n\n\n\neste exemplo, usamos a geometria geom_abline para desenhar uma reta a partir dos argumentos slope e intercept, que indicam, respectivamente, a inclinação e o ponto em que a reta cruza o valor de 0 no eixo X. Em termos mais simples: intercept indica qual é o valor de Y (pct_votos) quando X é zero (pct_gastos = 0); slope indica o quanto Y aumenta ou diminui quando X aumenta em uma unidade. No nosso exemplo, a reta que desenhamos tem inclinação de 2.3 e intercepta o eixo Y em -3, indicando que o valor de Y quando X é zero é -3 e que, a cada unidade que X aumenta, Y aumenta 2.3 unidades. Assim, podemos dizer, com base nesse modelo, que candidaturas que gastaram 20% de todas as receitas de campanha no seu estado esperariam, em média, obter 40% dos votos – basta acompanhar a reta para encontrar esses valores, ou fazer a conta:\n\n(-3) + 2.3 * 20\n\n[1] 43\n\n\nA reta que desenhamos parece acompanhar a relação entre gastos de campanha e votos. Candidaturas que gastaram mais tiveram mais votos, no geral, e a inclinação ascendente da reta que traçamos captura essa tendência. De qualquer forma, muitos pontos estão distantes dessa reta arbitrária que criamos e, mais que isso, a disposição dos pontos no gráficos sugere que uma menor inclinação seria melhor. Não é necessário treinamento quantitativo para perceber que não temos um bom modelo.\n\n5.2.1 Mínimos quadrados ordinários\nPara conseguir um modelo melhor, precisamos de uma reta que esteja mais próxima da maioria dos pontos, ou seja, que minimize a distância entre os pontos no gráfico e a reta. Podemos pensar, por exemplo, em um critério simples: calcular a distância vertical entre os pontos e a reta, isto é, a distância de cada ponto no eixo Y em relação à reta que traçamos. Em termos visuais, esse critério equivaleria a avaliar a nossa reta arbitrária da seguinte forma.\n\n\n\n\n\nFigura 5.2: Distância vertical entre pontos e reta\n\n\n\n\nCom esse gráfico, vemos a distância de cada ponto em relação à reta que usamos como nosso modelo, reforçando a visão de que ele não resume adequadamente a relação entre gastos de campanha e votos. Precisamos, portanto, de um método para minimizar essas distâncias. É aqui que entra a regressão por Mínimos Quadrados Ordinários (MQO), que relaciona duas variáveis de forma a encontrar uma reta que minimize a distância entre pontos e a reta encontrada.3\nA ideia central aqui é encontrarmos um intercepto (o valor de Y quando X é igual a 0) e uma inclinação (quanto ela aumenta ou diminui quando andamos uma casa no eixo X) que minimize a distância que vimos entre pontos e reta – na verdade, como o nome do modelo indica (Mínimos Quadrados), ele faz isso calculando a distância de cada ponto no eixo Y em relação à reta ao quadrado, penalizando observações mais distantes na hora de estimar o melhor modelo.\nEm R, a principal função que usaremos para estimar modelos lineares é a lm, de linear model. Ela já vem por padrão em qualquer instalação do R e pode ser usada com apenas dois argumentos: a fórmula do nosso modelo, estipulando qual variável é a dependente (e.g., qual variável queremos predizer) e qual, ou quais, variáveis usaremos para predizer a variação na dependente (às vezes essas variáveis também são chamadas de preditores); e o banco de dados os estão essas variáveis. Vamos ver mais detidamente cada argumento.\nUma fórmula, em primeiro lugar, é o meio que usamos para especificar a relação entre variáveis. No nosso exemplo hipotético da relação entre gastos de campanha e votos, uma fórmula que explicita nosso modelo seria o seguinte:\n\npct_votos ~ pct_gastos\n\nO que pode ser lido como: votos válidos de cada candidato ou candidata é predita pelo quanto ele(a) gastou em sua campanha. Para dizer de outro modo, tudo o que vem depois de ~ serve para explicar o que vem antes. Em R, expressões como estas, que já vimos em outros lugares deste livro, são chamadas de fórmulas e são usadas para especificar modelos de regressão linear simples e múltipla (experimente rodar ?formula para saber mais sobre elas).\nEsse jeito de expressar fórmulas é direto: pct_votos é nossa variável dependente porque ela vem antes do ~; dado que pct_gastos segue depois disso, ela é nossa variável independente. Declarar essa relação dessa maneira tem uma implicação: assumimos uma ordem, com uma variável antecedendo a outra. Com um modelo estimado, dessa forma, conseguimos predizer quantos votos uma candidatura hipotética teria se soubermos quanto ela gastou.\nPara estimar um modelo linear simples usando a função lm, basta passar a fórmula e o banco de dados para a função:\n\nmod &lt;- lm(pct_votos ~ pct_gastos, data = gov)\nmod\n\n\nCall:\nlm(formula = pct_votos ~ pct_gastos, data = gov)\n\nCoefficients:\n(Intercept)   pct_gastos  \n     -5.832        1.255  \n\n\nO output da função, salvo no objeto mod, pode parecer confuso à primeira vista, mas é fácil interpretá-lo. Em primeiro lugar, temos abaixo de Call: uma cópia do código que usamos para estimar nosso modelo, onde podemos ver a fórmula empregada, pct_votos ~ pct_gastos. Em segundo lugar, temos na linha seguinte temos, abaixo de Coefficients:, os valores estimados dos parâmetros do nosso modelo – que é tudo o que precisamos saber para traçarmos uma reta. Nessa parte, podemos ver que o valor indicado por (Intercept) é igual a -5.8317262, sugerindo que o valor predito de votos por um candidato ou candidata que gastou zero reais em campanha é de cerca de -6. De forma similar, o valor estimado do efeito predito de pct_gastos sugere que cada ponto percentual gasto em campanha prediz um retorno médio de cerca de 1 votos válidos.\nA título de ilustração, podemos comparar as retas dos modelos que trabalhamos até aqui: o nosso modelo arbitrário e o estimado pela função lm, em vermelho:\n\n\n\n\n\nFigura 5.3: Comparação entre modelos\n\n\n\n\n\n\n5.2.2 Modelo linear simples\nO modelo do exemplo anterior, com apenas duas variáveis – uma dependente e, a outra, independente – normalmente é chamado de modelo linear simples. Apesar do nome, ele é extremamente flexível e muito utilizado não só em pesquisas, para resumir relações entre duas variáveis, mas também em diversas outras aplicações. Formalmente, estes podem ser descritos por equações da seguinte forma geral:\n\\(Y_{i} = \\alpha + \\beta X_{i} + \\epsilon_{i}\\)\nonde:\n\n\\(i\\) indexa cada observação no banco de dados, \\(i = 1, 2, 3, ... N\\) (onde \\(N\\) indica o total de observações no banco);\n\\(Y_{i}\\) indica nossa variável dependente;\n\\(X_{i}\\) indica nossa variável independente;\n\\(\\epsilon_{i}\\) é um termo de erro (a distância entre o valor predito e o valor real de \\(Y_{i}\\));\n\\(\\alpha\\) é o intercepto do modelo; e\n\\(\\beta\\) é o coeficiente de inclinação, ou slope.\n\nUsando MQO, nosso objetivo é estimar valores para os parâmetros \\(\\alpha\\) e \\(\\beta\\) para encontrar uma reta que melhor se ajuste aos dados. O critério, como vimos, é o de minimizar a distância ao quadrado entre valores preditos e reais de \\(Y_{i}\\). Com isso, achamos estimativas dos parâmetros do modelo, \\(\\hat{\\alpha}\\) e \\(\\hat{\\beta}\\).4 A seguir, veremos alguns desses elementos de um modelo em maior detalhe.\n\n5.2.2.1 Coeficientes\nA primeira informação relevante de um modelo linear, e normalmente a mais usada em pesquisas, são as estimativas de \\(\\alpha\\) e \\(\\beta\\), também chamados de coeficientes. Com elas, identificamos se a relação entre variável independente (e.g., gasto de campanha) e a variável dependente (e.g., votos) é positiva ou negativa e, além disso, sua magnitude. Como salvamos os resultados do nosso modelo no objeto mod, coeficientes podem ser acessados diretamente (o objeto mod é uma espécie de lista, com vários elementos, e coefficients é um deles):\n\nmod$coefficients\n\n(Intercept)  pct_gastos \n  -5.831726    1.255031 \n\n\nO que esses números significam? Novamente, que o aumento de uma unidade de pct_gastos prediz um acréscimo médio de 1.26 unidades de pct_votos. Por sua vez, o intercepto indica que o valor predito de pct_votos quando pct_gastos é zero é de -5.83 – o que não faz sentido, neste caso, dado que não é possível ter um percentual negativo de votos. Isso é algo a se ter em mente: interceptos podem ser interpretados como valores preditos de \\(Y_{i}\\) quando \\(X_{i}\\) é zero, mas nem sempre indicam valores reais.\n\n\n5.2.2.2 Inferência\nNossas estimativas salvas em mod contêm informações adicionais: com elas, podemos fazer inferência, isto é, testar hipóteses sobre a relação entre variáveis. Por exemplo, podemos testar se o efeito predito de pct_gastos é estatisticamente diferente de zero. Podemos obter um resumo dessas e outras informações usando a função summary da seguinte maneira:\n\nsummary(mod)\n\n\nCall:\nlm(formula = pct_votos ~ pct_gastos, data = gov)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-23.9070  -5.5258   0.3822   8.9111  15.3246 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   -5.832      6.517  -0.895    0.388    \npct_gastos     1.255      0.210   5.977 6.44e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.88 on 12 degrees of freedom\nMultiple R-squared:  0.7486,    Adjusted R-squared:  0.7276 \nF-statistic: 35.73 on 1 and 12 DF,  p-value: 6.436e-05\n\n\nA primeira informação que nos interessa, agora, é Std. Error, que indica o erro-padrão de cada coeficiente do nosso modelo. Essa informação pode ser entendida como a variação de nossa estimativa – e quão maior ele for em relação à escala dos nossos coeficientes, menos precisa é nossa estimativa. Por essa razão, estimativas de incerteza são reportadas em pesquisas acadêmicas para que outras pessoas possam avaliar nossas inferências. Nas colunas à direita, temos também os T-values e os p-values de cada coeficiente: o t value é calculado dividindo o valor do coeficiente pelo seu erro-padrão, e o p-value é a probabilidade de obtermos um T-valor igual ou mais extremo do que o observado se a hipótese nula for verdadeira.5 No nosso caso, o p-value de pct_gastos é 6.4360651^{-5}, o que indica que a probabilidade de obtermos um valor igual ou mais extremo do que o observado se a hipótese nula for verdadeira é irrisória. Como esse valor é muito menor que 0.05, normalmente usado como limiar para rejeitar a hipótese nula, não podemos rejeitar a hipótese de que o efeito de pct_gastos é igual a zero. Dizendo de outra forma, dificilmente veríamos a relação entre pct_gastos e pct_votos por fruto de mero acaso.\nCom essas informações do nosso modelo estimado, podemos também calcular intervalos de confiança para nossas estimativas. Obtemos estes intervalos facilmente usando a função confint:6\n\nconfint(mod, , level = 0.95)\n\n                  2.5 %   97.5 %\n(Intercept) -20.0301902 8.366738\npct_gastos    0.7975635 1.712498\n\n\nNo exemplo acima, level = 0.95 estipula que o intervalo de confiança calculado é de 95%, isto é, com probabilidade de 95% de conter o valor real dos nossos parâmetros. Uma vez mais, os resultados desse exercício reforça o que já sabíamos: pct_gastos possui relação com pct_votos, uma vez que seu efeito predito varia de um mínimo de 0.7975635 a um máximo de 1.712498. Desse modo, ainda que possa ser maior ou menor, ele certamente é positivo.\n\n\n5.2.2.3 Predições\nTendo estimado os coeficientes de um modelo, podemos usá-los para fazer predições. Vamos voltar ao nosso modelo estimado, salvo em mod. Para extrair apenas as estimativas dos coeficientes dele, vamos usar agora a função coef, que é uma outra maneira simples de fazer isso.\n\ncoef(mod)\n\n(Intercept)  pct_gastos \n  -5.831726    1.255031 \n\n\nCom essas estimativas, podemos fazer predições para qualquer observação. Aqui, o método consiste no seguinte: precisamos “plugar” as estimativas com valores de x, pct_gastos. Em primeiro lugar, sabemos que quando pct_gastos é zero o valor predito de pct_votos para qualquer observação é igual a -5.8317262, que é o valor do intercepto. Segundo, sabemos que uma unidade a mais de pct_gastos prediz um aumento de 1.2550307 na variável pct_Votos. Dessa forma, plugar esses resultados é uma questão de somar o valor do intercepto e multiplicar o valor de \\(\\hat{\\beta}\\) pelo valor pct_gastos que quisermos predizer. Um exemplo: para predizer quantos votos válidos uma candidatura que gastou 20% de todas as receitas de campanha no seu estado teria, basta fazer a conta:\n\n-5.831726 + 1.255031 * 20\n\n[1] 19.26889\n\n\nO R tem uma função que faz isso automaticamente, predict, que pode ser usada da seguinte forma:\n\ndados_ficticios &lt;- data.frame(pct_gastos = 20)\npredict(mod, newdata = dados_ficticios)\n\n       1 \n19.26889 \n\n\nAqui, o essencial é que criamos um novo banco de dados, salvo em dados_ficticios, com apenas uma observação, pct_gastos = 20 – note que esse banco precisa ter o nome das variáveis que usamos para estimar o modelo, pct_gastos. Com essa base fictícia, passamos o modelo estimado para a função predict e, em seguida, o banco criado para o argumento newdata. O resultado é o mesmo que obtivemos acima, mas a função predict é útil para fazer predições para várias observações de uma só vez. Veja:\n\ndados_ficticios2 &lt;- data.frame(pct_gastos = seq(20, 80, 10))\npredict(mod, newdata = dados_ficticios2)\n\n       1        2        3        4        5        6        7 \n19.26889 31.81920 44.36950 56.91981 69.47012 82.02043 94.57073 \n\n\nComo é possível ver, com apenas uma chamada da função conseguimos usar nosso modelo para predizer quantos votos válidos candidaturas com diferentes percentuais de gastos de campanha teriam.\n\n\n5.2.2.4 Ajuste do modelo\nAlguns modelos são melhores que outros ao explicar a variação de nossa variável dependente, o que afeta diretamente nossa capacidade de fazer predições. Para avaliarmos o desempenho de um modelo isso, temos algumas alternativas. Em primeiro lugar, o objeto do resultado de summary contém uma estatística útil para fazermos isso: o R-quadrado.\n\nresultados &lt;- summary(mod)\nresultados$r.squared\n\n[1] 0.7485839\n\n\nO código anterior retorna uma métrica que varia de 0 a 1, onde 1 indica que nossas variáveis independentes explicam perfeitamente a variação de Y.7 No nosso exemplo, o R-quadrado retornou um número de cerca de 0.7, o que indica que nosso modelo explica boa parcela da variação de pct_votos. Embora não seja uma métrica definitiva, nos dá uma boa ideia geral de desempenho.\nAlém dessa métrica, também podemos usar o resultado do teste F do nosso modelo para avaliá-lo. O que ele faz? Em síntese, ele teste a hipótese nula de que nosso modelo completo, com variáveis independentes, explica a mesma variância do que um modelo modelo sem variáveis (apenas com o intercepto, \\(\\alpha\\)), que seria o mesmo que usar a média de y para predizer seus valores. O P-valor desse teste pode ser acessado na última linha do resultado de summary:\n\nsummary(mod)\n\n\nCall:\nlm(formula = pct_votos ~ pct_gastos, data = gov)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-23.9070  -5.5258   0.3822   8.9111  15.3246 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   -5.832      6.517  -0.895    0.388    \npct_gastos     1.255      0.210   5.977 6.44e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.88 on 12 degrees of freedom\nMultiple R-squared:  0.7486,    Adjusted R-squared:  0.7276 \nF-statistic: 35.73 on 1 and 12 DF,  p-value: 6.436e-05\n\n\nNo caso, como ele é menor que 0.05, rejeitamos a hipótese nula: nosso modelo com pct_gastos é melhor que um modelo sem essa informação.\n\n\n\n5.2.3 Reportando resultados de modelos\nUma vez estimado um modelo, o próximo passo é reportar seus resultados em um artigo ou documento. Para isso, podemos usar a função modelsummary, do pacote de mesmo nome, que já vimos nas seções anteriores. Para usá-lo, basta passar os modelos que queremos reportar para a função:\n\nmodelsummary(mod)\n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\n-5.832\n\n\n\n(6.517)\n\n\npct_gastos\n1.255\n\n\n\n(0.210)\n\n\nNum.Obs.\n14\n\n\nR2\n0.749\n\n\nR2 Adj.\n0.728\n\n\nAIC\n112.9\n\n\nBIC\n114.8\n\n\nLog.Lik.\n-53.429\n\n\nF\n35.730\n\n\nRMSE\n10.99\n\n\n\n\n\n\n\nPor padrão, modelsummary() reporta modelos como colunas e uma tabela nas quais as linhas indicam os coeficientes, como o do intercepto e da variável independente pct_gastos, no caso do nosso exemplo. Além disso, a tabela exportada também indica o erro-padrão de cada coeficiente em parenteses, logo abaixo de cada estimativa. Finalmente, para modelos lineares simples por mínimos quadrados, como o nosso, a tabela uma série de estatísticas, como o R-quadrado, o R-quadrado ajustado (uma medida que penaliza modelos com muitas variáveis independentes), a estatística F e algumas outras medidas de ajustes que podem ser úteis para determinados casos. Para deixar a tabela menor, mantendo apenas informações mais utilizadas, modelsummary() reserva o argumento got_map, que pode ser usado para indicar quais estatísticas queremos reportar. Para manter apenas o R-quadrado e o número de observações utilizadas na estimação do modelo, podemos usar o seguinte:\n\nmodelsummary(mod, gof_map = c(\"nobs\", \"r.squared\"))\n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\n-5.832\n\n\n\n(6.517)\n\n\npct_gastos\n1.255\n\n\n\n(0.210)\n\n\nNum.Obs.\n14\n\n\nR2\n0.749\n\n\n\n\n\n\n\nPara facilitar a leitura da tabela, modelsummary() também permite que renomeemos os coeficientes e estatísticas de um modelo. Para isso, basta passar um vetor com os nomes que queremos usar no lugar dos originais para o argumento coef_map:\n\nnomes &lt;- c(\"(Intercept)\" = \"Intercepto\", \n           \"pct_gastos\" = \"Gastos (%)\",\n           \"Num.Obs.\" = \"Observações\")\nmodelsummary(mod, coef_map = nomes, gof_map = c(\"nobs\", \"r.squared\"))\n\n\n\n\n\n (1)\n\n\n\n\nIntercepto\n-5.832\n\n\n\n(6.517)\n\n\nGastos (%)\n1.255\n\n\n\n(0.210)\n\n\nNum.Obs.\n14\n\n\nR2\n0.749\n\n\n\n\n\n\n\nAssim como fizemos com a função datasummary(), exportar o resultado de modelsummary() pode ser feito com o argumento output:\n\nmodelsummary(mod, coef_map = nomes, gof_map = c(\"nobs\", \"r.squared\"), output = \"tabela.txt\") # Texto\nmodelsummary(mod, coef_map = nomes, gof_map = c(\"nobs\", \"r.squared\"), output = \"tabela.rtf\") # RTF\nmodelsummary(mod, coef_map = nomes, gof_map = c(\"nobs\", \"r.squared\"), output = \"tabela.html\") # HTML"
  },
  {
    "objectID": "05-cap.html#resumo-do-capítulo",
    "href": "05-cap.html#resumo-do-capítulo",
    "title": "5  Análise",
    "section": "5.3 Resumo do capítulo",
    "text": "5.3 Resumo do capítulo\nEste capítulo final introduziu alguns conceitos básicos para análise de dados quantitativos. Começamos com uma breve introdução sobre o que são estatísticas descritivas e vimos como calcular algumas das mais comuns usando tanto funções do tidyverse quanto com modelsummary. Em seguida, introduzimos modelos de regressão linear simples e, usando R, mostramos como obter e interpretar alguns de seus resultados. Por fim, vimos como reportar resultados de modelos de regressão linear simples usando a função modelsummary."
  },
  {
    "objectID": "05-cap.html#indo-além",
    "href": "05-cap.html#indo-além",
    "title": "5  Análise",
    "section": "5.4 Indo além",
    "text": "5.4 Indo além\n\n\n\n\nKellstedt, Paul M, e Guy D Whitten. 2018. The fundamentals of political science research. Cambridge University Press.\n\n\nWooldridge, Jeffrey M. 2010. Econometric analysis of cross section and panel data. MIT press."
  },
  {
    "objectID": "05-cap.html#footnotes",
    "href": "05-cap.html#footnotes",
    "title": "5  Análise",
    "section": "",
    "text": "Usamos o indexador $ para acessar a variável pct_gastos da base gov. Caso tenha dúvidas sobre esse operador, veja a seção correspondente no Capítulo 1.↩︎\nPara saber mais sobre todas as funcionalidades do gt, nossa recomendação é consultar a documentação oficial do pacote em https://gt.rstudio.com.↩︎\nPara uma explicação intuitiva de como funciona o método de MQO, ver Kellstedt e Whitten (2018).↩︎\nA notação com \\(\\hat{}\\) é reservada, neste contexto, para falar de estimativas já feitas.↩︎\nPara mais detalhes sobre o cálculo de T-values e p-values, ver Kellstedt e Whitten (2018).↩︎\nComo não é nosso objetivo cobrir em profundidade o estimador por MQO, não nos deteremos sobre como são calculadas algumas estatísticas que implementaremos no R daqui para frente. Para mais detalhes sobre modelos lineares, ver Wooldridge (2010), por exemplo.↩︎\nParticularmente, o R-quadrado é uma razão entre a soma dos quadrados dos resíduos do modelo (a distância entre os valores preditos e reais de Y) e a soma total dos quadrados (a distância entre os valores reais de Y e a média de Y).Na prática, isso nos dá uma ideia de quanto um modelo linear é melhor do que uma simples média para predizer valores de Y.↩︎"
  },
  {
    "objectID": "referencias.html",
    "href": "referencias.html",
    "title": "Referências",
    "section": "",
    "text": "Aquino, Jakson Alves de. 2014. “R Para Cientistas Sociais.”\nEDITUS-Editora da UESC.\n\n\nDowle, Matt, and Arun Srinivasan. 2023. Data.table: Extension of\n‘Data.frame‘. https://CRAN.R-project.org/package=data.table.\n\n\nKastellec, Jonathan P, and Eduardo L Leoni. 2007. “Using Graphs\nInstead of Tables in Political Science.” Perspectives on\nPolitics 5 (4): 755–71.\n\n\nKellstedt, Paul M, and Guy D Whitten. 2018. The Fundamentals of\nPolitical Science Research. Cambridge University Press.\n\n\nMuhleisen, Hannes, Mark Raasveldt, and DuckDB Contributors. 2020.\nDuckdb: DBI Package for the DuckDB Database Management System.\nhttps://CRAN.R-project.org/package=duckdb.\n\n\nPereira, Rafael H. M., and Rogério J. Barbosa. 2023. Censobr:\nDownload Data from Brazil’s Population Census (version v0.2.0). https://CRAN.R-project.org/package=censobr.\n\n\nSpector, Phil. 2008. Data Manipulation with r. Springer Science\n& Business Media.\n\n\nTufte, Edward R. 1983. “The Visual Display Of.”\nQuantitative Information, 13.\n\n\nWickham, Hadley. 2014. “Tidy Data.” Journal of\nStatistical Software 59 (10): 1–23.\n\n\n———. 2016. Ggplot2: Elegant Graphics for Data Analysis.\nSpringer.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023.\nR for Data Science. \" O’Reilly Media, Inc.\".\n\n\nWilkinson, Leland. 2012. The Grammar of Graphics. Springer.\n\n\nWooldridge, Jeffrey M. 2010. Econometric Analysis of Cross Section\nand Panel Data. MIT press."
  }
]